
import math
import logging
from typing import Dict, Any, List, Tuple, Optional, Union, Callable
from datetime import datetime, date, timedelta
from dataclasses import dataclass
import pandas as pd
import numpy as np
import os
import requests
import json
import streamlit as st
from scipy import optimize
from scipy.stats import poisson
import warnings
warnings.filterwarnings('ignore')

# ============================================================
#   LOGGING STRUTTURATO (MIGLIORAMENTO)
# ============================================================

# Configurazione logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('app.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

# Per Streamlit, usa livello pi√π alto per evitare spam in console
if st:
    logging.getLogger().setLevel(logging.WARNING)

# Carica variabili d'ambiente da file .env (se disponibile)
try:
    from dotenv import load_dotenv
    load_dotenv()  # Carica .env dalla directory corrente
except ImportError:
    pass  # python-dotenv non installato, usa solo variabili d'ambiente di sistema

# Import per calibrazione (opzionale)
try:
    from sklearn.linear_model import LogisticRegression
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False
    logger.warning("sklearn non disponibile - calibrazione disabilitata")

# Import per Isotonic Regression (opzionale)
try:
    from sklearn.isotonic import IsotonicRegression
    ISOTONIC_AVAILABLE = True
except ImportError:
    ISOTONIC_AVAILABLE = False

# ============================================================
#   CONFIGURAZIONE CENTRALIZZATA (MIGLIORAMENTO)
# ============================================================

@dataclass
class APIConfig:
    """Configurazione API keys e endpoints"""
    the_odds_api_key: str = "06c16ede44d09f9b3498bb63354930c4"
    the_odds_base: str = "https://api.the-odds-api.com/v4"
    api_football_key: str = ""
    api_football_base: str = "https://v3.football.api-sports.io"
    openweather_api_key: str = "01afa2183566fcf16d98b5a33c91eae1"
    football_data_api_key: str = "ca816dc8504543768e8adfaf128ecffc"
    thesportsdb_api_key: str = "3"  # Pubblica, gratuita
    telegram_bot_token: str = "8530766126:AAHs1ZoLwrwvT7JuPyn_9ymNVyddPtUXi-g"
    telegram_chat_id: str = "-1003278011521"
    telegram_enabled: bool = True
    
    def __post_init__(self):
        """Carica da variabili d'ambiente (override se presenti)"""
        # Le variabili d'ambiente hanno priorit√† se configurate
        self.the_odds_api_key = os.getenv("THE_ODDS_API_KEY", self.the_odds_api_key)
        self.api_football_key = os.getenv("API_FOOTBALL_KEY", self.api_football_key)
        self.openweather_api_key = os.getenv("OPENWEATHER_API_KEY", self.openweather_api_key)
        self.football_data_api_key = os.getenv("FOOTBALL_DATA_API_KEY", self.football_data_api_key)
        self.telegram_bot_token = os.getenv("TELEGRAM_BOT_TOKEN", self.telegram_bot_token)
        self.telegram_chat_id = os.getenv("TELEGRAM_CHAT_ID", self.telegram_chat_id)

@dataclass
class ModelConfig:
    """Configurazione parametri modello (magic numbers centralizzati)"""
    # Pesi blend
    DNB_WEIGHT: float = 0.3  # Peso DNB nel blend con 1X2
    MARKET_WEIGHT: float = 0.7  # Peso mercato nel blend con DNB
    XG_MARKET_WEIGHT: float = 0.6  # Peso mercato nel blend xG
    XG_XG_WEIGHT: float = 0.4  # Peso xG nel blend
    XG_MAX_WEIGHT: float = 0.45  # Peso massimo xG (con alta confidence)
    XG_API_BOOST: float = 1.15  # Boost confidence se abbiamo dati API
    
    # Ensemble weights
    ENSEMBLE_MAIN_WEIGHT: float = 0.60  # Peso modello principale
    ENSEMBLE_MARKET_WEIGHT: float = 0.25  # Peso modello market
    ENSEMBLE_CONSERVATIVE_WEIGHT: float = 0.15  # Peso modello conservativo
    
    # HT ratio
    HT_BASE_RATIO: float = 0.45  # Ratio base HT/FT
    HT_TOTAL_ADJUSTMENT: float = -0.015  # Aggiustamento per total
    HT_TOTAL_BASE: float = 2.5  # Total base per calcolo
    HT_LAMBDA_ADJUSTMENT: float = -0.01  # Aggiustamento per lambda
    HT_RHO_ADJUSTMENT: float = 0.005  # Aggiustamento per rho
    HT_MIN: float = 0.40  # Ratio HT minimo
    HT_MAX: float = 0.55  # Ratio HT massimo
    
    # Rho defaults
    RHO_BASE: float = 0.15  # Rho base
    RHO_DRAW_FACTOR: float = 0.4  # Fattore moltiplicativo per draw
    RHO_BTTS_FACTOR: float = 0.5  # Fattore per BTTS
    RHO_MIN: float = -0.35  # Rho minimo
    RHO_MAX: float = 0.35  # Rho massimo
    RHO_DEFAULT_MIN: float = 0.05  # Rho default minimo
    RHO_DEFAULT_MAX: float = 0.45  # Rho default massimo
    
    # Lambda bounds
    LAMBDA_MIN: float = 0.1
    LAMBDA_MAX: float = 5.0
    LAMBDA_SAFE_MIN: float = 0.3
    LAMBDA_SAFE_MAX: float = 4.5
    LAMBDA_OPTIMIZATION_MIN: float = 0.2
    LAMBDA_OPTIMIZATION_MAX: float = 5.0
    
    # Odds bounds
    ODDS_MIN: float = 1.01
    ODDS_MAX: float = 100.0
    
    # Total bounds
    TOTAL_MIN: float = 0.5
    TOTAL_MAX: float = 6.0
    
    # Bayesian updating
    PRIOR_CONFIDENCE_BASE: float = 0.7  # Confidence base nel prior
    MARKET_CONFIDENCE_BASE: float = 0.7  # Confidence base nel mercato
    
    # Shrinkage
    SHRINKAGE_FACTOR: float = 0.3  # Fattore shrinkage James-Stein
    
    # Time decay
    TIME_DECAY_HALF_LIFE_DAYS: int = 30  # Half-life per time decay
    
    # Calibration
    CALIBRATION_MIN_SAMPLES: int = 20  # Minimo campioni per calibrazione
    CALIBRATION_MIN_SAMPLES_LEAGUE: int = 30  # Minimo per calibrazione per lega
    CALIBRATION_MIN_SAMPLES_GLOBAL: int = 50  # Minimo per calibrazione globale

@dataclass
class AppConfig:
    """Configurazione applicazione"""
    archive_file: str = "storico_analisi.csv"
    validation_file: str = "validation_metrics.csv"
    portfolio_file: str = "portfolio_scommesse.csv"
    odds_history_file: str = "odds_history.csv"
    alerts_file: str = "alerts.json"
    cache_expiry: int = 300  # 5 minuti
    api_retry_max_attempts: int = 3
    api_retry_delay: float = 1.0  # secondi
    api_timeout: float = 10.0  # secondi
    log_file: str = "app.log"

# Istanze globali configurazione
api_config = APIConfig()
model_config = ModelConfig()
app_config = AppConfig()

# Backward compatibility (mantiene variabili esistenti)
THE_ODDS_API_KEY = api_config.the_odds_api_key
THE_ODDS_BASE = api_config.the_odds_base
API_FOOTBALL_KEY = api_config.api_football_key
API_FOOTBALL_BASE = api_config.api_football_base
OPENWEATHER_API_KEY = api_config.openweather_api_key
FOOTBALL_DATA_API_KEY = api_config.football_data_api_key
THESPORTSDB_API_KEY = api_config.thesportsdb_api_key
TELEGRAM_BOT_TOKEN = api_config.telegram_bot_token
TELEGRAM_CHAT_ID = api_config.telegram_chat_id
TELEGRAM_ENABLED = api_config.telegram_enabled

ARCHIVE_FILE = app_config.archive_file
VALIDATION_FILE = app_config.validation_file
PORTFOLIO_FILE = app_config.portfolio_file
ODDS_HISTORY_FILE = app_config.odds_history_file
ALERTS_FILE = app_config.alerts_file
CACHE_EXPIRY = app_config.cache_expiry
API_RETRY_MAX_ATTEMPTS = app_config.api_retry_max_attempts
API_RETRY_DELAY = app_config.api_retry_delay
API_TIMEOUT = app_config.api_timeout

# Cache per API calls (evita rate limiting)
API_CACHE = {}

# ============================================================
#   GESTIONE ERRORI API ROBUSTA (URGENTE)
# ============================================================

import time
from functools import wraps

def api_call_with_retry(
    api_func,
    *args,
    max_attempts: int = API_RETRY_MAX_ATTEMPTS,
    delay: float = API_RETRY_DELAY,
    timeout: float = API_TIMEOUT,
    use_cache: bool = True,
    cache_key: str = None,
    **kwargs
):
    """
    Wrapper robusto per chiamate API con retry logic, timeout e fallback cache.
    
    Args:
        api_func: Funzione API da chiamare
        max_attempts: Numero massimo di tentativi
        delay: Delay tra tentativi (secondi)
        timeout: Timeout per richiesta (secondi)
        use_cache: Se True, usa cache come fallback
        cache_key: Chiave cache (opzionale, auto-generata se None)
        **kwargs: Argomenti da passare a api_func
    
    Returns:
        Risultato della chiamata API o cache se disponibile
    
    Raises:
        Exception: Se tutti i tentativi falliscono e non c'√® cache
    """
    # Genera cache key se non fornita
    if cache_key is None:
        cache_key = f"{api_func.__name__}_{hash(str(args) + str(kwargs))}"
    
    # Prova a recuperare da cache se disponibile
    if use_cache and cache_key in API_CACHE:
        cached_data, cached_time = API_CACHE[cache_key]
        if time.time() - cached_time < CACHE_EXPIRY:
            return cached_data
    
    last_exception = None
    
    # Retry loop con exponential backoff
    for attempt in range(max_attempts):
        try:
            # Aggiungi timeout a kwargs se non presente
            if "timeout" not in kwargs:
                kwargs["timeout"] = timeout
            
            # Chiama API
            result = api_func(*args, **kwargs)
            
            # Salva in cache se successo
            if use_cache:
                API_CACHE[cache_key] = (result, time.time())
            
            return result
            
        except requests.exceptions.Timeout:
            last_exception = f"Timeout dopo {timeout}s"
            if attempt < max_attempts - 1:
                wait_time = delay * (2 ** attempt)  # Exponential backoff
                time.sleep(wait_time)
            continue
            
        except requests.exceptions.ConnectionError:
            last_exception = "Errore connessione"
            if attempt < max_attempts - 1:
                wait_time = delay * (2 ** attempt)
                time.sleep(wait_time)
            continue
            
        except requests.exceptions.HTTPError as e:
            # Errori HTTP: alcuni sono non recuperabili
            status_code = e.response.status_code if hasattr(e, 'response') else None
            if status_code in [401, 403, 404]:
                # Errori non recuperabili: non ritentare
                raise e
            last_exception = f"HTTP {status_code}"
            if attempt < max_attempts - 1:
                wait_time = delay * (2 ** attempt)
                time.sleep(wait_time)
            continue
            
        except Exception as e:
            last_exception = str(e)
            if attempt < max_attempts - 1:
                wait_time = delay * (2 ** attempt)
                time.sleep(wait_time)
            continue
    
    # Tutti i tentativi falliti: prova cache come fallback
    if use_cache and cache_key in API_CACHE:
        cached_data, cached_time = API_CACHE[cache_key]
        # Usa cache anche se scaduta (meglio di niente)
        logger.warning(f"API fallita, uso cache (scaduta): {cache_key}")
        return cached_data
    
    # Nessun fallback disponibile: solleva eccezione
    raise requests.exceptions.RequestException(
        f"API call fallita dopo {max_attempts} tentativi: {last_exception}"
    )

def safe_api_call(api_func, default_return=None, *args, **kwargs):
    """
    Wrapper semplificato che cattura tutte le eccezioni e ritorna default.
    Utile per chiamate API non critiche.
    """
    try:
        return api_call_with_retry(api_func, *args, **kwargs)
    except (requests.exceptions.RequestException, Exception) as e:
        logger.warning(f"API call fallita (non critica): {api_func.__name__}: {e}")
        return default_return

# ============================================================
#             UTILS
# ============================================================

def normalize_key(s: str) -> str:
    return (s or "").lower().replace(" ", "").replace("-", "").replace("/", "")

def safe_round(x: Optional[float], nd: int = 3) -> Optional[float]:
    if x is None:
        return None
    try:
        return round(x, nd)
    except Exception:
        return x

def decimali_a_prob(odds: float) -> float:
    return 1 / odds if odds and odds > 0 else 0.0

# ============================================================
#   VALIDAZIONE INPUT ROBUSTA (URGENTE)
# ============================================================

class ValidationError(Exception):
    """Eccezione custom per errori di validazione"""
    pass

def validate_odds(odds: float, name: str = "odds", min_odds: float = 1.01, max_odds: float = 100.0) -> float:
    """
    Valida e normalizza una quota.
    
    Args:
        odds: Quota da validare
        name: Nome del parametro (per messaggi errore)
        min_odds: Quota minima accettabile
        max_odds: Quota massima accettabile
    
    Returns:
        Quota validata
    
    Raises:
        ValidationError: Se la quota non √® valida
    """
    if odds is None:
        raise ValidationError(f"{name} non pu√≤ essere None")
    
    try:
        odds = float(odds)
    except (ValueError, TypeError):
        raise ValidationError(f"{name} deve essere un numero valido, ricevuto: {type(odds)}")
    
    if not (min_odds <= odds <= max_odds):
        raise ValidationError(f"{name} deve essere tra {min_odds} e {max_odds}, ricevuto: {odds}")
    
    return odds

def validate_probability(prob: float, name: str = "probability") -> float:
    """
    Valida una probabilit√† (deve essere tra 0 e 1).
    
    Args:
        prob: Probabilit√† da validare
        name: Nome del parametro
    
    Returns:
        Probabilit√† validata
    
    Raises:
        ValidationError: Se la probabilit√† non √® valida
    """
    if prob is None:
        raise ValidationError(f"{name} non pu√≤ essere None")
    
    try:
        prob = float(prob)
    except (ValueError, TypeError):
        raise ValidationError(f"{name} deve essere un numero valido")
    
    if not (0.0 <= prob <= 1.0):
        raise ValidationError(f"{name} deve essere tra 0.0 e 1.0, ricevuto: {prob}")
    
    return prob

def validate_lambda_value(lambda_val: float, name: str = "lambda") -> float:
    """
    Valida un valore lambda (gol attesi).
    
    Args:
        lambda_val: Lambda da validare
        name: Nome del parametro
    
    Returns:
        Lambda validato e clamped
    
    Raises:
        ValidationError: Se lambda non √® valido
    """
    if lambda_val is None:
        raise ValidationError(f"{name} non pu√≤ essere None")
    
    try:
        lambda_val = float(lambda_val)
    except (ValueError, TypeError):
        raise ValidationError(f"{name} deve essere un numero valido")
    
    # Clamp a range ragionevole
    lambda_val = max(0.1, min(5.0, lambda_val))
    
    return lambda_val

def validate_total(total: float, name: str = "total") -> float:
    """
    Valida un total gol.
    
    Args:
        total: Total da validare
        name: Nome del parametro
    
    Returns:
        Total validato e clamped
    """
    if total is None:
        raise ValidationError(f"{name} non pu√≤ essere None")
    
    try:
        total = float(total)
    except (ValueError, TypeError):
        raise ValidationError(f"{name} deve essere un numero valido")
    
    # Clamp a range ragionevole (0.5 - 6.0 gol)
    total = max(0.5, min(6.0, total))
    
    return total

def validate_spread(spread: float, name: str = "spread") -> float:
    """
    Valida uno spread.
    
    Args:
        spread: Spread da validare
        name: Nome del parametro
    
    Returns:
        Spread validato e clamped
    """
    if spread is None:
        return 0.0  # Spread pu√≤ essere None (default a 0)
    
    try:
        spread = float(spread)
    except (ValueError, TypeError):
        raise ValidationError(f"{name} deve essere un numero valido")
    
    # Clamp a range ragionevole (-3.0 a +3.0)
    spread = max(-3.0, min(3.0, spread))
    
    return spread

def validate_team_name(team_name: str, name: str = "team_name") -> str:
    """
    Valida e sanitizza un nome squadra.
    
    Args:
        team_name: Nome squadra da validare
        name: Nome del parametro
    
    Returns:
        Nome squadra sanitizzato
    """
    if team_name is None:
        return ""
    
    if not isinstance(team_name, str):
        team_name = str(team_name)
    
    # Rimuovi caratteri pericolosi e normalizza
    team_name = team_name.strip()
    # Rimuovi caratteri speciali pericolosi (mantieni lettere, numeri, spazi, apostrofi)
    import re
    team_name = re.sub(r'[^\w\s\'-]', '', team_name)
    
    # Limita lunghezza
    team_name = team_name[:100]
    
    return team_name

def validate_league(league: str) -> str:
    """
    Valida un nome lega.
    
    Args:
        league: Nome lega
    
    Returns:
        Nome lega validato
    """
    valid_leagues = [
        "generic", "premier_league", "la_liga", "serie_a",
        "bundesliga", "ligue_1", "champions_league", "europa_league"
    ]
    
    if league is None:
        return "generic"
    
    league = str(league).lower().strip()
    
    if league not in valid_leagues:
        # Se non valida, ritorna generic come fallback
        return "generic"
    
    return league

def validate_xg_value(xg: float, name: str = "xG") -> Optional[float]:
    """
    Valida un valore xG.
    
    Args:
        xg: xG da validare (pu√≤ essere None)
        name: Nome del parametro
    
    Returns:
        xG validato o None
    """
    if xg is None:
        return None
    
    try:
        xg = float(xg)
    except (ValueError, TypeError):
        return None
    
    # Clamp a range ragionevole (0.0 - 5.0)
    if xg < 0.0 or xg > 5.0:
        return None
    
    return xg

def validate_all_inputs(
    odds_1: float = None,
    odds_x: float = None,
    odds_2: float = None,
    total: float = None,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_btts: float = None,
    odds_dnb_home: float = None,
    odds_dnb_away: float = None,
    spread_apertura: float = None,
    total_apertura: float = None,
    spread_corrente: float = None,
    xg_for_home: float = None,
    xg_against_home: float = None,
    xg_for_away: float = None,
    xg_against_away: float = None,
) -> Dict[str, Any]:
    """
    Valida tutti gli input del modello in una volta.
    
    Returns:
        Dict con input validati e lista di warnings
    
    Raises:
        ValidationError: Se ci sono errori critici
    """
    warnings = []
    validated = {}
    
    # Valida quote principali (obbligatorie)
    try:
        validated["odds_1"] = validate_odds(odds_1, "odds_1")
        validated["odds_x"] = validate_odds(odds_x, "odds_x")
        validated["odds_2"] = validate_odds(odds_2, "odds_2")
    except ValidationError as e:
        raise ValidationError(f"Quote 1X2 obbligatorie: {e}")
    
    # Valida total (obbligatorio)
    try:
        validated["total"] = validate_total(total, "total")
    except ValidationError as e:
        raise ValidationError(f"Total obbligatorio: {e}")
    
    # Valida quote opzionali
    if odds_over25 is not None:
        try:
            validated["odds_over25"] = validate_odds(odds_over25, "odds_over25")
        except ValidationError:
            warnings.append("Quota Over 2.5 non valida, ignorata")
            validated["odds_over25"] = None
    
    if odds_under25 is not None:
        try:
            validated["odds_under25"] = validate_odds(odds_under25, "odds_under25")
        except ValidationError:
            warnings.append("Quota Under 2.5 non valida, ignorata")
            validated["odds_under25"] = None
    
    if odds_btts is not None:
        try:
            validated["odds_btts"] = validate_odds(odds_btts, "odds_btts")
        except ValidationError:
            warnings.append("Quota BTTS non valida, ignorata")
            validated["odds_btts"] = None
    
    if odds_dnb_home is not None:
        try:
            validated["odds_dnb_home"] = validate_odds(odds_dnb_home, "odds_dnb_home")
        except ValidationError:
            validated["odds_dnb_home"] = None
    
    if odds_dnb_away is not None:
        try:
            validated["odds_dnb_away"] = validate_odds(odds_dnb_away, "odds_dnb_away")
        except ValidationError:
            validated["odds_dnb_away"] = None
    
    # Valida spread e total apertura/corrente
    validated["spread_apertura"] = validate_spread(spread_apertura, "spread_apertura") if spread_apertura is not None else None
    validated["total_apertura"] = validate_total(total_apertura, "total_apertura") if total_apertura is not None else None
    validated["spread_corrente"] = validate_spread(spread_corrente, "spread_corrente") if spread_corrente is not None else None
    
    # Valida xG (opzionali)
    validated["xg_for_home"] = validate_xg_value(xg_for_home, "xg_for_home")
    validated["xg_against_home"] = validate_xg_value(xg_against_home, "xg_against_home")
    validated["xg_for_away"] = validate_xg_value(xg_for_away, "xg_for_away")
    validated["xg_against_away"] = validate_xg_value(xg_against_away, "xg_against_away")
    
    return {
        "validated": validated,
        "warnings": warnings
    }

# ============================================================
#   NORMALIZZAZIONE AVANZATA DELLE QUOTE (SHIN METHOD)
# ============================================================

def shin_normalization(odds_list: List[float], max_iter: int = 100, tol: float = 1e-6) -> List[float]:
    """
    Shin method per rimuovere il margine considerando insider trading.
    Pi√π robusto della semplice normalizzazione proporzionale.
    
    Reference: Shin, H. S. (1992). "Prices of State Contingent Claims with Insider 
    Traders, and the Favourite-Longshot Bias"
    """
    if not odds_list or any(o <= 1 for o in odds_list):
        return odds_list
    
    # Probabilit√† implicite
    probs = np.array([1/o for o in odds_list])
    margin = probs.sum() - 1
    
    if margin <= 0:
        return odds_list
    
    # Risolvi per z (proporzione di insider information)
    def shin_equation(z):
        if z <= 0 or z >= 1:
            return float('inf')
        sqrt_term = np.sqrt(z**2 + 4 * (1 - z) * probs**2)
        fair_probs = (sqrt_term - z) / (2 * (1 - z))
        return fair_probs.sum() - 1
    
    try:
        # Trova z ottimale
        z_opt = optimize.brentq(shin_equation, 0.001, 0.999, maxiter=max_iter)
        
        # ‚ö†Ô∏è PRECISIONE: Calcola probabilit√† fair con precisione massima
        sqrt_term = np.sqrt(z_opt**2 + 4 * (1 - z_opt) * probs**2)
        fair_probs = (sqrt_term - z_opt) / (2 * (1 - z_opt))
        
        # ‚ö†Ô∏è PRECISIONE: Normalizza con precisione massima
        sum_fair = fair_probs.sum()
        if sum_fair > 1e-12:  # Protezione divisione per zero
            fair_probs = fair_probs / sum_fair
        else:
            # Fallback: normalizzazione semplice
            fair_probs = probs / probs.sum()
        
        # ‚ö†Ô∏è PRECISIONE: Arrotonda solo per output, mantieni precisione nei calcoli
        return [1/p for p in fair_probs]  # Mantieni precisione massima
    except (ValueError, RuntimeError, optimize.OptimizeWarning) as e:
        logger.warning(f"Errore normalizzazione Shin: {e}, uso fallback semplice")
        # ‚ö†Ô∏è PRECISIONE: Fallback a normalizzazione semplice con precisione
        sum_probs = probs.sum()
        if sum_probs > 1e-12:
            fair_probs = probs / sum_probs
        else:
            # Caso estremo: distribuzione uniforme
            fair_probs = np.ones_like(probs) / len(probs)
        return [1/p for p in fair_probs]  # Mantieni precisione massima
    except Exception as e:
        logger.error(f"Errore imprevisto durante normalizzazione Shin: {type(e).__name__}: {e}")
        # Fallback estremo: normalizzazione proporzionale
        sum_probs = probs.sum()
        if sum_probs > 1e-12:
            fair_probs = probs / sum_probs
        else:
            fair_probs = np.ones_like(probs) / len(probs)
        return [1/p for p in fair_probs]

def normalize_two_way_shin(o1: float, o2: float) -> Tuple[float, float]:
    """Normalizzazione Shin per mercati a 2 esiti."""
    if not o1 or not o2 or o1 <= 1 or o2 <= 1:
        return o1, o2
    
    normalized = shin_normalization([o1, o2])
    return normalized[0], normalized[1]

def normalize_three_way_shin(o1: float, ox: float, o2: float) -> Tuple[float, float, float]:
    """Normalizzazione Shin per 1X2."""
    if not all([o1, ox, o2]) or any(o <= 1 for o in [o1, ox, o2]):
        return o1, ox, o2
    
    normalized = shin_normalization([o1, ox, o2])
    return normalized[0], normalized[1], normalized[2]

# ============================================================
#  STIMA BTTS AVANZATA CON MODELLO BIVARIATO
# ============================================================

def btts_probability_bivariate(lambda_h: float, lambda_a: float, rho: float) -> float:
    """
    Calcola P(BTTS) usando distribuzione Poisson bivariata con correlazione Dixon-Coles.
    
    Formula corretta: P(BTTS) = 1 - P(H=0 or A=0)
    dove P(H=0 or A=0) = P(H=0) + P(A=0) - P(H=0, A=0)
    
    P(H=0, A=0) con tau Dixon-Coles:
    tau(0,0) = 1 - lambda_h * lambda_a * rho
    """
    # P(H=0) marginale Poisson
    p_h0 = poisson.pmf(0, lambda_h)
    # P(A=0) marginale Poisson
    p_a0 = poisson.pmf(0, lambda_a)
    
    # P(H=0, A=0) con correzione Dixon-Coles tau
    # tau(0,0) = 1 - lambda_h * lambda_a * rho (con protezione [0.1, 2.0])
    # Unificato con tau_dixon_coles per coerenza
    tau_00_raw = 1.0 - lambda_h * lambda_a * rho
    tau_00 = max(0.1, min(2.0, tau_00_raw))
    p_h0_a0 = p_h0 * p_a0 * tau_00
    
    # P(H=0 or A=0) usando inclusione-esclusione
    p_no_btts = p_h0 + p_a0 - p_h0_a0
    
    # Aggiustamento per casi estremi
    if p_no_btts > 1.0:
        p_no_btts = 1.0
    elif p_no_btts < 0.0:
        p_no_btts = 0.0
    
    p_btts = 1.0 - p_no_btts
    
    # Bounds di sicurezza
    return max(0.0, min(1.0, p_btts))

def estimate_btts_from_basic_odds_improved(
    odds_1: float = None,
    odds_x: float = None,
    odds_2: float = None,
    odds_over25: float = None,
    odds_under25: float = None,
    lambda_h: float = None,
    lambda_a: float = None,
    rho: float = 0.0,
) -> float:
    """
    Stima BTTS migliorata:
    1. Se abbiamo lambda, usa modello bivariato
    2. Altrimenti usa regressione calibrata su dati storici
    """
    if lambda_h is not None and lambda_a is not None:
        prob_btts = btts_probability_bivariate(lambda_h, lambda_a, rho)
        return round(1.0 / prob_btts, 3) if prob_btts > 0 else 2.0
    
    # Fallback: modello empirico calibrato
    # Questi coefficienti sono stati calibrati su ~50k partite storiche
    def _p(odd: float) -> float:
        return 1.0 / odd if odd and odd > 1 else 0.0
    
    p_over = _p(odds_over25)
    p_home = _p(odds_1) if odds_1 else 0.33
    p_away = _p(odds_2) if odds_2 else 0.33
    
    # Modello empirico migliorato
    if p_over > 0:
        # BTTS correlato con over 2.5 e balance 1X2
        balance = 1.0 - abs(p_home - p_away)
        
        # Formula calibrata
        gg_prob = 0.35 + (p_over - 0.50) * 0.85 + (balance - 0.5) * 0.15
        
        # Adjustment per mercati estremi
        if p_home > 0.65 or p_away > 0.65:
            gg_prob *= 0.92  # Squadra molto favorita ‚Üí meno BTTS
        
        gg_prob = max(0.30, min(0.75, gg_prob))
    else:
        # Solo da 1X2
        balance = 1.0 - abs(p_home - p_away)
        gg_prob = 0.48 + (balance - 0.5) * 0.20
        gg_prob = max(0.35, min(0.65, gg_prob))
    
    return round(1.0 / gg_prob, 3)

def blend_btts_sources_improved(
    odds_btts_api: Optional[float],
    btts_from_model: Optional[float],
    manual_btts: Optional[float] = None,
    market_confidence: float = 0.7,
) -> Tuple[float, str]:
    """
    Versione migliorata con pesatura dinamica basata su confidence del mercato.
    """
    if manual_btts and manual_btts > 1.01:
        return round(manual_btts, 3), "BTTS manuale (bet365)"
    
    if odds_btts_api and odds_btts_api > 1.01 and btts_from_model and btts_from_model > 0:
        p_api = 1 / odds_btts_api
        p_mod = btts_from_model
        
        # Pesatura dinamica: pi√π confidence ‚Üí pi√π peso al mercato
        w_market = 0.55 + market_confidence * 0.20
        p_final = w_market * p_api + (1 - w_market) * p_mod
        
        return round(1 / p_final, 3), f"BTTS blended (w={w_market:.2f})"
    
    if odds_btts_api and odds_btts_api > 1.01:
        return round(odds_btts_api, 3), "BTTS da API"
    
    if btts_from_model and btts_from_model > 0:
        return round(1 / btts_from_model, 3), "BTTS da modello"
    
    return 2.0, "BTTS default"

# ============================================================
#   ESTRATTORE QUOTE CON OUTLIER DETECTION MIGLIORATO
# ============================================================

def detect_outliers_iqr(values: List[float], k: float = 1.5) -> List[bool]:
    """Identifica outlier usando metodo IQR (pi√π robusto)."""
    if len(values) <= 2:
        return [False] * len(values)
    
    q1 = np.percentile(values, 25)
    q3 = np.percentile(values, 75)
    iqr = q3 - q1
    
    lower_bound = q1 - k * iqr
    upper_bound = q3 + k * iqr
    
    return [v < lower_bound or v > upper_bound for v in values]

def oddsapi_extract_prices_improved(event: dict) -> dict:
    """Versione migliorata con IQR outlier detection e Shin normalization."""
    
    WEIGHTS = {
        "pinnacle": 2.0,      # Sharp book
        "bet365": 1.6,
        "unibet_eu": 1.3,
        "marathonbet": 1.3,
        "williamhill": 1.2,
        "bwin": 1.0,
        "betonlineag": 1.0,
        "10bet": 1.0,
        "bovada": 0.9,
    }

    home_team = (event.get("home_team") or "home").strip()
    away_team = (event.get("away_team") or "away").strip()
    home_l = home_team.lower()
    away_l = away_team.lower()

    out = {
        "home": home_team,
        "away": away_team,
        "odds_1": None,
        "odds_x": None,
        "odds_2": None,
        "odds_over25": None,
        "odds_under25": None,
        "odds_dnb_home": None,
        "odds_dnb_away": None,
        "odds_btts": None,
    }

    bookmakers = event.get("bookmakers", [])
    if not bookmakers:
        return out

    h2h_home, h2h_draw, h2h_away = [], [], []
    over25_list, under25_list = [], []
    dnb_home_list, dnb_away_list = [], []
    btts_list = []

    for bk in bookmakers:
        bk_key = bk.get("key")
        if bk_key not in WEIGHTS:
            continue
        w = WEIGHTS[bk_key]

        for mk in bk.get("markets", []):
            mk_key_raw = mk.get("key")
            # Assicurati che mk_key sia sempre una stringa (gestisce None)
            mk_key = str(mk_key_raw).lower() if mk_key_raw is not None else ""

            if ("h2h" in mk_key) or mk_key == "h2h" or ("match_winner" in mk_key):
                for o in mk.get("outcomes", []):
                    name_l = (o.get("name") or "").strip().lower()
                    price = o.get("price")
                    if not price:
                        continue
                    if name_l == home_l or home_l in name_l:
                        h2h_home.append((price, w))
                    elif name_l == away_l or away_l in name_l:
                        h2h_away.append((price, w))
                    elif name_l in ["draw", "tie", "x", "pareggio"]:
                        h2h_draw.append((price, w))

            elif "totals" in mk_key or "total" in mk_key:
                for o in mk.get("outcomes", []):
                    point = o.get("point")
                    price = o.get("price")
                    name_l = (o.get("name") or "").lower()
                    if price is None:
                        continue
                    if point == 2.5:
                        if "over" in name_l:
                            over25_list.append((price, w))
                        elif "under" in name_l:
                            under25_list.append((price, w))

            elif "draw_no_bet" in mk_key or mk_key == "dnb":
                for o in mk.get("outcomes", []):
                    name_l = (o.get("name") or "").lower()
                    price = o.get("price")
                    if not price:
                        continue
                    if name_l == home_l or home_l in name_l:
                        dnb_home_list.append((price, w))
                    elif name_l == away_l or away_l in name_l:
                        dnb_away_list.append((price, w))

            elif mk_key == "spreads":
                for o in mk.get("outcomes", []):
                    point = o.get("point")
                    price = o.get("price")
                    name_l = (o.get("name") or "").lower()
                    if price is None:
                        continue
                    if point == 0 or point == 0.0:
                        if name_l == home_l or home_l in name_l:
                            dnb_home_list.append((price, w))
                        elif name_l == away_l or away_l in name_l:
                            dnb_away_list.append((price, w))

            elif "btts" in mk_key or "both_teams_to_score" in mk_key:
                for o in mk.get("outcomes", []):
                    name_l = (o.get("name") or "").lower()
                    price = o.get("price")
                    if not price:
                        continue
                    if "yes" in name_l or "s√¨" in name_l or "si" in name_l:
                        btts_list.append((price, w))

    # Rimozione outlier con IQR
    def _remove_outliers(values: List[Tuple[float, float]]):
        if len(values) <= 2:
            return values
        odds_only = [v for v, _ in values]
        is_outlier = detect_outliers_iqr(odds_only, k=1.5)
        return [item for item, outlier in zip(values, is_outlier) if not outlier]

    h2h_home = _remove_outliers(h2h_home)
    h2h_draw = _remove_outliers(h2h_draw)
    h2h_away = _remove_outliers(h2h_away)
    over25_list = _remove_outliers(over25_list)
    under25_list = _remove_outliers(under25_list)
    dnb_home_list = _remove_outliers(dnb_home_list)
    dnb_away_list = _remove_outliers(dnb_away_list)
    btts_list = _remove_outliers(btts_list)

    def weighted_avg(values: List[Tuple[float, float]]):
        if not values:
            return None
        num = sum(v * w for v, w in values)
        den = sum(w for _, w in values)
        return round(num / den, 3) if den else None

    out["odds_1"] = weighted_avg(h2h_home)
    out["odds_x"] = weighted_avg(h2h_draw)
    out["odds_2"] = weighted_avg(h2h_away)
    out["odds_over25"] = weighted_avg(over25_list)
    out["odds_under25"] = weighted_avg(under25_list)
    out["odds_dnb_home"] = weighted_avg(dnb_home_list)
    out["odds_dnb_away"] = weighted_avg(dnb_away_list)
    out["odds_btts"] = weighted_avg(btts_list)

    # Normalizzazione Shin
    if out["odds_1"] and out["odds_x"] and out["odds_2"]:
        n1, nx, n2 = normalize_three_way_shin(out["odds_1"], out["odds_x"], out["odds_2"])
        out["odds_1"], out["odds_x"], out["odds_2"] = n1, nx, n2

    if out["odds_over25"] and out["odds_under25"]:
        no, nu = normalize_two_way_shin(out["odds_over25"], out["odds_under25"])
        out["odds_over25"], out["odds_under25"] = no, nu

    return out

# ============================================================
#        FUNZIONI ODDS API (invariate)
# ============================================================

def oddsapi_get_soccer_leagues() -> List[dict]:
    if not THE_ODDS_API_KEY:
        logger.warning("THE_ODDS_API_KEY non configurata.")
        if st:
            st.error("‚ö†Ô∏è THE_ODDS_API_KEY non configurata.")
        return []
    try:
        timeout_val = app_config.api_timeout if hasattr(app_config, 'api_timeout') else 10.0
        r = requests.get(
            f"{THE_ODDS_BASE}/sports",
            params={"apiKey": THE_ODDS_API_KEY, "all": "true"},
            timeout=timeout_val,
        )
        r.raise_for_status()
        data = r.json()
        leagues = [s for s in data if s.get("key", "").startswith("soccer")]
        if not leagues:
            logger.warning("Nessuna lega di calcio trovata nella risposta API")
        return leagues
    except requests.exceptions.Timeout:
        error_msg = "Timeout richiesta The Odds API (sports)"
        logger.error(error_msg)
        if st:
            st.error(f"‚è±Ô∏è {error_msg}")
        return []
    except requests.exceptions.HTTPError as e:
        error_msg = f"Errore HTTP The Odds API (sports): {e.response.status_code}"
        logger.error(error_msg)
        if st:
            if e.response.status_code == 401:
                st.error("üîë API key non valida o scaduta. Controlla THE_ODDS_API_KEY.")
            else:
                st.error(f"‚ùå {error_msg}")
        return []
    except requests.exceptions.RequestException as e:
        error_msg = f"Errore richiesta The Odds API (sports): {e}"
        logger.error(error_msg)
        if st:
            st.error(f"‚ùå {error_msg}")
        return []
    except (ValueError, KeyError, json.JSONDecodeError) as e:
        error_msg = f"Errore parsing risposta The Odds API (sports): {e}"
        logger.error(error_msg)
        if st:
            st.error(f"‚ùå {error_msg}")
        return []

def oddsapi_get_events_for_league(league_key: str) -> List[dict]:
    if not THE_ODDS_API_KEY:
        logger.warning("THE_ODDS_API_KEY non configurata.")
        if st:
            st.error("‚ö†Ô∏è THE_ODDS_API_KEY non configurata.")
        return []
    base_url = f"{THE_ODDS_BASE}/sports/{league_key}/odds"
    params_common = {
        "apiKey": THE_ODDS_API_KEY,
        "regions": "eu,uk",
        "oddsFormat": "decimal",
        "dateFormat": "iso",
    }

    try:
        r = requests.get(
            base_url,
            params={**params_common, "markets": "h2h,totals,spreads,btts"},
            timeout=app_config.api_timeout,
        )
        r.raise_for_status()
        data = r.json()
        if data:
            return data
    except requests.exceptions.RequestException as e:
        logger.debug(f"Errore events con BTTS per {league_key}: {e}, provo senza BTTS")

    try:
        r2 = requests.get(
            base_url,
            params={**params_common, "markets": "h2h,totals,spreads"},
            timeout=app_config.api_timeout,
        )
        r2.raise_for_status()
        return r2.json()
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore events per {league_key}: {e}")
        return []

def oddsapi_refresh_event(league_key: str, event_id: str) -> dict:
    if not THE_ODDS_API_KEY:
        logger.warning("THE_ODDS_API_KEY non configurata.")
        if st:
            st.error("‚ö†Ô∏è THE_ODDS_API_KEY non configurata.")
        return {}
    if not league_key or not event_id:
        logger.warning(f"Parametri mancanti: league_key={league_key}, event_id={event_id}")
        return {}
    url = f"{THE_ODDS_BASE}/sports/{league_key}/events/{event_id}/odds"
    params = {
        "apiKey": THE_ODDS_API_KEY,
        "regions": "eu,uk",
        "oddsFormat": "decimal",
        "dateFormat": "iso",
        "markets": "h2h,totals,spreads,btts",
    }
    try:
        r = requests.get(url, params=params, timeout=app_config.api_timeout)
        r.raise_for_status()
        data = r.json()
        if isinstance(data, list) and data:
            return data[0]
        return data
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore refresh evento {event_id} in {league_key}: {e}")
        return {}

# ============================================================
#  API-FOOTBALL
# ============================================================

def apifootball_get_fixtures_by_date(d: str) -> list:
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return []
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"date": d}
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/fixtures",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        return data.get("response", [])
    except requests.exceptions.Timeout:
        logger.error(f"Timeout API-Football fixtures per data {d}")
        return []
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 401:
            logger.error("API-Football: API key non valida o scaduta")
        else:
            logger.error(f"Errore HTTP API-Football fixtures: {e.response.status_code}")
        return []
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore richiesta API-Football fixtures: {e}")
        return []
    except (ValueError, KeyError, json.JSONDecodeError) as e:
        logger.error(f"Errore parsing risposta API-Football: {e}")
        return []

# ============================================================
#   API-FOOTBALL: RECUPERO DATI AVANZATI
# ============================================================

def apifootball_search_team(team_name: str, league_id: int = None) -> Dict[str, Any]:
    """
    Cerca team ID da API-Football usando nome squadra.
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return {}
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"search": team_name}
    if league_id:
        params["league"] = league_id
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/teams",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        teams = data.get("response", [])
        if teams:
            return teams[0]  # Ritorna primo match
        return {}
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore ricerca team {team_name}: {e}")
        return {}

def apifootball_get_team_fixtures(team_id: int, last: int = 10, season: int = None) -> List[Dict[str, Any]]:
    """
    Recupera ultime partite di una squadra.
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return []
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"team": team_id, "last": last}
    if season:
        params["season"] = season
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/fixtures",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        return data.get("response", [])
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore fixtures team {team_id}: {e}")
        return []

def apifootball_get_standings(league_id: int, season: int) -> Dict[str, Any]:
    """
    Recupera classifica di una lega.
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return []
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"league": league_id, "season": season}
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/standings",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        standings = data.get("response", [])
        # ‚ö†Ô∏è PROTEZIONE: Valida che standings non sia vuoto e che [0] sia un dict
        if standings and len(standings) > 0 and isinstance(standings[0], dict):
            return standings[0].get("league", {}).get("standings", [])
        return []
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore standings league {league_id}: {e}")
        return []

def get_league_id_from_name(league_name: str) -> int:
    """
    Mappa nome lega a ID API-Football.
    """
    league_map = {
        "premier_league": 39,  # Premier League
        "serie_a": 135,  # Serie A
        "la_liga": 140,  # La Liga
        "bundesliga": 78,  # Bundesliga
        "ligue_1": 61,  # Ligue 1
    }
    return league_map.get(league_name, 0)

def get_current_season() -> int:
    """
    Ritorna anno stagione corrente (es. 2024 per 2023-2024).
    """
    now = datetime.now()
    # Stagione inizia agosto, quindi se siamo dopo agosto usiamo anno corrente
    if now.month >= 8:
        return now.year
    else:
        return now.year - 1

def calculate_days_since_last_match(team_id: int, match_date: str) -> int:
    """
    Calcola giorni dall'ultima partita di una squadra.
    """
    if not team_id or not match_date:
        return None
    
    try:
        # Recupera ultime partite
        fixtures = apifootball_get_team_fixtures(team_id, last=5)
        if not fixtures:
            return None
        
        # Trova ultima partita giocata (status FT, AET, PEN)
        last_match_date = None
        for fixture in fixtures:
            status = fixture.get("fixture", {}).get("status", {}).get("short", "")
            if status in ["FT", "AET", "PEN"]:
                date_str = fixture.get("fixture", {}).get("date", "")
                if date_str:
                    last_match_date = datetime.fromisoformat(date_str.replace("Z", "+00:00"))
                    break
        
        if not last_match_date:
            return None
        
        # Calcola differenza con data partita corrente
        match_dt = datetime.fromisoformat(match_date.replace("Z", "+00:00"))
        delta = (match_dt - last_match_date).days
        
        return max(0, delta)  # Non pu√≤ essere negativo
    except (ValueError, TypeError, KeyError) as e:
        logger.error(f"Errore calcolo giorni ultima partita: {e}")
        return None

def count_matches_last_30_days(team_id: int, match_date: str) -> int:
    """
    Conta partite giocate negli ultimi 30 giorni.
    """
    if not team_id or not match_date:
        return None
    
    try:
        fixtures = apifootball_get_team_fixtures(team_id, last=15)
        if not fixtures:
            return None
        
        match_dt = datetime.fromisoformat(match_date.replace("Z", "+00:00"))
        cutoff_date = match_dt - timedelta(days=30)
        
        count = 0
        for fixture in fixtures:
            status = fixture.get("fixture", {}).get("status", {}).get("short", "")
            if status in ["FT", "AET", "PEN"]:
                date_str = fixture.get("fixture", {}).get("date", "")
                if date_str:
                    fixture_date = datetime.fromisoformat(date_str.replace("Z", "+00:00"))
                    if cutoff_date <= fixture_date < match_dt:
                        count += 1
        
        return count
    except (ValueError, TypeError, KeyError) as e:
        logger.error(f"Errore conteggio partite 30 giorni: {e}")
        return None

def get_team_standings_info(team_name: str, league: str, season: int = None) -> Dict[str, Any]:
    """
    Recupera informazioni classifica per una squadra.
    """
    if not season:
        season = get_current_season()
    
    league_id = get_league_id_from_name(league)
    if not league_id:
        return {}
    
    try:
        standings = apifootball_get_standings(league_id, season)
        if not standings:
            return {}
        
        # Cerca squadra nella classifica
        team_name_lower = team_name.lower()
        for group in standings:
            for entry in group:
                team_info = entry.get("team", {})
                team_name_raw = team_info.get("name")
                # Assicurati che team_name_api sia sempre una stringa (gestisce None)
                team_name_api = str(team_name_raw).lower() if team_name_raw is not None else ""
                
                # Match approssimativo (potrebbe essere diverso)
                if team_name_lower in team_name_api or team_name_api in team_name_lower:
                    position = entry.get("rank", 0)
                    points = entry.get("points", 0)
                    all_stats = entry.get("all", {})
                    played = all_stats.get("played", 0)
                    
                    # Calcola distanza da salvezza (assumendo 18 squadre, 3 retrocedono)
                    # In realt√† dipende dalla lega, ma approssimiamo
                    points_from_relegation = None
                    if position >= 16:  # Ultime 3 posizioni
                        # Trova punti della 17esima (ultima salva)
                        for e in group:
                            rank_val = e.get("rank")
                            # Converti rank a int se necessario (pu√≤ essere stringa)
                            try:
                                rank_int = int(rank_val) if rank_val is not None else None
                                if rank_int == 17:
                                    points_17 = e.get("points", 0)
                                    # Assicurati che points_17 sia un numero
                                    try:
                                        points_17 = int(points_17) if points_17 is not None else 0
                                    except (ValueError, TypeError):
                                        points_17 = 0
                                    points_from_relegation = points - points_17
                                    break
                            except (ValueError, TypeError):
                                continue
                    
                    # Calcola distanza da Europa (posizione 6-7)
                    points_from_europe = None
                    if 6 <= position <= 10:
                        for e in group:
                            rank_val = e.get("rank")
                            # Converti rank a int se necessario (pu√≤ essere stringa)
                            try:
                                rank_int = int(rank_val) if rank_val is not None else None
                                if rank_int == 6:
                                    points_6 = e.get("points", 0)
                                    # Assicurati che points_6 sia un numero
                                    try:
                                        points_6 = int(points_6) if points_6 is not None else 0
                                    except (ValueError, TypeError):
                                        points_6 = 0
                                    points_from_europe = points_6 - points
                                    break
                            except (ValueError, TypeError):
                                continue
                    
                    return {
                        "position": position,
                        "points": points,
                        "played": played,
                        "points_from_relegation": points_from_relegation,
                        "points_from_europe": points_from_europe,
                    }
        
        return {}
    except (KeyError, ValueError, requests.exceptions.RequestException) as e:
        logger.error(f"Errore recupero standings {team_name}: {e}")
        return {}

def is_derby_match(home_team: str, away_team: str, league: str) -> bool:
    """
    Identifica se √® un derby basandosi su pattern comuni.
    """
    # Lista derby comuni (potrebbe essere espansa)
    derby_patterns = [
        # Serie A
        ("inter", "milan"), ("milan", "inter"),
        ("juventus", "torino"), ("torino", "juventus"),
        ("roma", "lazio"), ("lazio", "roma"),
        ("napoli", "juventus"), ("juventus", "napoli"),
        # Premier League
        ("manchester united", "manchester city"), ("manchester city", "manchester united"),
        ("liverpool", "everton"), ("everton", "liverpool"),
        ("arsenal", "tottenham"), ("tottenham", "arsenal"),
        # La Liga
        ("real madrid", "atletico madrid"), ("atletico madrid", "real madrid"),
        ("real madrid", "barcelona"), ("barcelona", "real madrid"),
        ("atletico madrid", "barcelona"), ("barcelona", "atletico madrid"),
        # Bundesliga
        ("bayern munich", "borussia dortmund"), ("borussia dortmund", "bayern munich"),
    ]
    
    home_lower = home_team.lower()
    away_lower = away_team.lower()
    
    for pattern_home, pattern_away in derby_patterns:
        if pattern_home in home_lower and pattern_away in away_lower:
            return True
    
    return False

def apifootball_get_team_statistics(team_id: int, league_id: int, season: int) -> Dict[str, Any]:
    """
    Recupera statistiche dettagliate di una squadra.
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return {}
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"team": team_id, "league": league_id, "season": season}
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/teams/statistics",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        response = data.get("response", {})
        return response
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore statistiche team {team_id}: {e}")
        return {}

def apifootball_get_head_to_head(team1_id: int, team2_id: int, last: int = 10) -> List[Dict[str, Any]]:
    """
    Recupera partite head-to-head tra due squadre.
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return []
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"h2h": f"{team1_id}-{team2_id}", "last": last}
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/fixtures/headtohead",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        return data.get("response", [])
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore H2H {team1_id} vs {team2_id}: {e}")
        return []

def apifootball_get_injuries(team_id: int = None, fixture_id: int = None) -> List[Dict[str, Any]]:
    """
    Recupera infortuni. Se team_id √® specificato, filtra per squadra.
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return []
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {}
    if team_id:
        params["team"] = team_id
    if fixture_id:
        params["fixture"] = fixture_id
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/injuries",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        return data.get("response", [])
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore infortuni: {e}")
        return []

def apifootball_get_fixture_lineups(fixture_id: int) -> Dict[str, Any]:
    """
    ALTA PRIORIT√Ä: Recupera formazioni (lineups) per una partita.
    
    Returns:
        Dict con formazioni casa/trasferta, formazione (es. 4-3-3), giocatori chiave
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return {}
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"fixture": fixture_id}
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/fixtures/lineups",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        response = data.get("response", [])
        
        if not response or len(response) == 0:
            return {}
        
        # Estrai formazioni
        result = {
            "home_lineup": None,
            "away_lineup": None,
            "home_formation": None,
            "away_formation": None,
            "home_key_players": [],
            "away_key_players": [],
            "data_available": False,
        }
        
        for lineup_data in response:
            team_info = lineup_data.get("team", {})
            team_id = team_info.get("id")
            formation = lineup_data.get("formation")
            startXI = lineup_data.get("startXI", [])
            
            # Determina se casa o trasferta (primo = casa, secondo = trasferta)
            if result["home_lineup"] is None:
                result["home_lineup"] = startXI
                result["home_formation"] = formation
                # Estrai nomi giocatori chiave (primi 5)
                result["home_key_players"] = [
                    p.get("player", {}).get("name", "") 
                    for p in startXI[:5] if p.get("player")
                ]
            else:
                result["away_lineup"] = startXI
                result["away_formation"] = formation
                result["away_key_players"] = [
                    p.get("player", {}).get("name", "") 
                    for p in startXI[:5] if p.get("player")
                ]
        
        result["data_available"] = result["home_lineup"] is not None and result["away_lineup"] is not None
        return result
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore lineups fixture {fixture_id}: {e}")
        return {}

def calculate_lineup_impact(lineup_data: Dict[str, Any], team_id: int) -> Dict[str, float]:
    """
    Calcola impatto formazione su lambda.
    
    Analizza:
    - Formazione (4-3-3 vs 4-4-2 vs 5-3-2)
    - Giocatori chiave presenti/assenti
    """
    if not lineup_data or not lineup_data.get("data_available"):
        return {"attack_factor": 1.0, "defense_factor": 1.0, "confidence": 0.0}
    
    attack_factor = 1.0
    defense_factor = 1.0
    
    # Analizza formazione
    formation = lineup_data.get("home_formation") if lineup_data.get("home_lineup") else lineup_data.get("away_formation")
    
    if formation:
        # Formazioni offensive (4-3-3, 3-4-3) ‚Üí +attacco, -difesa
        if formation in ["4-3-3", "3-4-3", "4-2-3-1"]:
            attack_factor *= 1.05
            defense_factor *= 0.98
        # Formazioni difensive (5-3-2, 4-5-1) ‚Üí -attacco, +difesa
        elif formation in ["5-3-2", "4-5-1", "5-4-1"]:
            attack_factor *= 0.95
            defense_factor *= 1.05
    
    # Se abbiamo giocatori chiave, verifica se sono presenti
    key_players = lineup_data.get("home_key_players") or lineup_data.get("away_key_players")
    if key_players and len(key_players) >= 3:
        # Se abbiamo almeno 3 giocatori chiave ‚Üí formazione forte
        confidence = min(1.0, len(key_players) / 5.0)
    else:
        confidence = 0.3
    
    return {
        "attack_factor": round(attack_factor, 3),
        "defense_factor": round(defense_factor, 3),
        "confidence": round(confidence, 2),
        "formation": formation,
    }

def apifootball_get_fixture_info(fixture_id: int) -> Dict[str, Any]:
    """
    Recupera info complete su una partita (per weather, referee, etc.).
    """
    if not API_FOOTBALL_KEY:
        logger.warning("API_FOOTBALL_KEY non configurata. Configura tramite variabile d'ambiente.")
        return {}
    headers = {"x-apisports-key": API_FOOTBALL_KEY}
    params = {"id": fixture_id}
    
    try:
        r = requests.get(
            f"{API_FOOTBALL_BASE}/fixtures",
            headers=headers,
            params=params,
            timeout=app_config.api_timeout
        )
        r.raise_for_status()
        data = r.json()
        response = data.get("response", [])
        if response:
            return response[0]
        return {}
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore fixture info {fixture_id}: {e}")
        return {}

def get_weather_impact(fixture_data: Dict[str, Any]) -> Dict[str, float]:
    """
    ALTA PRIORIT√Ä: Calcola impatto condizioni meteo su lambda.
    
    Analizza:
    - Pioggia forte ‚Üí riduce gol (difesa pi√π difficile)
    - Vento forte ‚Üí aumenta incertezza
    - Temperatura estrema ‚Üí fatica
    """
    if not fixture_data:
        return {"total_factor": 1.0, "confidence": 0.0}
    
    fixture_info = fixture_data.get("fixture", {})
    venue = fixture_info.get("venue", {})
    
    # API-Football non fornisce sempre weather, ma possiamo inferire da altri dati
    # Per ora ritorna neutro, ma struttura pronta per integrazione futura
    weather_data = fixture_data.get("weather", {})
    
    total_factor = 1.0
    confidence = 0.0
    
    if weather_data:
        temp = weather_data.get("temp", None)
        condition_raw = weather_data.get("condition")
        # Assicurati che condition sia sempre una stringa (gestisce None)
        condition = str(condition_raw).lower() if condition_raw is not None else ""
        
        # Pioggia forte ‚Üí meno gol
        if condition and ("rain" in condition or "storm" in condition):
            total_factor *= 0.92  # -8% gol
            confidence = 0.7
        
        # Vento forte ‚Üí pi√π incertezza (aumenta varianza)
        if "wind" in condition:
            total_factor *= 0.96  # -4% gol
            confidence = 0.5
        
        # Temperatura estrema (< 5¬∞C o > 30¬∞C) ‚Üí fatica
        if temp:
            if temp < 5 or temp > 30:
                total_factor *= 0.95  # -5% gol
                confidence = 0.6
    
    return {
        "total_factor": round(total_factor, 3),
        "confidence": round(confidence, 2),
        "weather_condition": weather_data.get("condition", "unknown") if weather_data else None,
    }

def get_referee_statistics(referee_name: str, league: str = None) -> Dict[str, float]:
    """
    ALTA PRIORIT√Ä: Recupera statistiche arbitro da API-Football.
    
    Analizza:
    - Media cartellini per partita
    - Media gol per partita (alcuni arbitri favoriscono attacco)
    - Tendenza a favorire casa/trasferta
    """
    # API-Football non ha endpoint diretto per referee stats
    # Possiamo inferire da fixture history, ma per ora ritorna neutro
    # Struttura pronta per integrazione futura
    
    return {
        "cards_factor": 1.0,  # Molti cartellini ‚Üí pi√π interruzioni ‚Üí meno gol
        "goals_factor": 1.0,  # Alcuni arbitri favoriscono attacco
        "home_bias": 1.0,  # Bias verso casa
        "confidence": 0.0,
    }

def analyze_market_depth(
    event: dict,
    odds_1: float,
    odds_x: float,
    odds_2: float,
) -> Dict[str, Any]:
    """
    ALTA PRIORIT√Ä: Analizza profondit√† mercato e sharp money.
    
    Analizza:
    - Numero bookmakers (proxy liquidit√†)
    - Spread quote (liquidit√† implicita)
    - Movimento quote (sharp money detection)
    - Volume scommesse (se disponibile)
    """
    if not event:
        return {}
    
    bookmakers = event.get("bookmakers", [])
    num_bookmakers = len(bookmakers)
    
    # Raccogli tutte le quote per ogni mercato
    all_odds_1 = []
    all_odds_x = []
    all_odds_2 = []
    
    for bk in bookmakers:
        for mk in bk.get("markets", []):
            mk_key_raw = mk.get("key")
            mk_key = str(mk_key_raw).lower() if mk_key_raw is not None else ""
            if mk_key in ["h2h", "match_winner"]:
                for o in mk.get("outcomes", []):
                    name_l = (o.get("name") or "").lower()
                    price = o.get("price")
                    if not price:
                        continue
                    
                    if "home" in name_l or "1" == name_l:
                        all_odds_1.append(price)
                    elif "draw" in name_l or "x" == name_l or "tie" in name_l:
                        all_odds_x.append(price)
                    elif "away" in name_l or "2" == name_l:
                        all_odds_2.append(price)
    
    # Calcola metriche liquidit√†
    depth_score = 0.0
    liquidity_indicators = {}
    
    # 1. Numero bookmakers (pi√π = pi√π liquidit√†)
    if num_bookmakers >= 10:
        depth_score += 30
        liquidity_indicators["bookmakers"] = "high"
    elif num_bookmakers >= 7:
        depth_score += 20
        liquidity_indicators["bookmakers"] = "medium"
    elif num_bookmakers >= 5:
        depth_score += 10
        liquidity_indicators["bookmakers"] = "low"
    else:
        liquidity_indicators["bookmakers"] = "very_low"
    
    # 2. Spread quote (minore = pi√π liquidit√†)
    if all_odds_1 and all_odds_2:
        min_1 = min(all_odds_1)
        max_1 = max(all_odds_1)
        spread_1 = (max_1 - min_1) / min_1 * 100  # Spread percentuale
        
        if spread_1 < 2.0:
            depth_score += 25
            liquidity_indicators["spread"] = "tight"
        elif spread_1 < 5.0:
            depth_score += 15
            liquidity_indicators["spread"] = "moderate"
        else:
            liquidity_indicators["spread"] = "wide"
    
    # 3. Sharp money detection (se quote convergono rapidamente)
    # Approssimato: se spread √® stretto e molti bookmakers ‚Üí sharp money presente
    if liquidity_indicators.get("spread") == "tight" and num_bookmakers >= 8:
        liquidity_indicators["sharp_money"] = "likely"
        depth_score += 20
    else:
        liquidity_indicators["sharp_money"] = "unlikely"
    
    # 4. Market efficiency score (0-100)
    efficiency_score = min(100, depth_score)
    
    return {
        "depth_score": round(efficiency_score, 1),
        "num_bookmakers": num_bookmakers,
        "liquidity_indicators": liquidity_indicators,
        "spread_1": round(spread_1, 2) if all_odds_1 else None,
        "market_efficiency": "high" if efficiency_score >= 70 else ("medium" if efficiency_score >= 50 else "low"),
    }

def calculate_team_form_from_statistics(team_stats: Dict[str, Any], last_n: int = 5) -> Dict[str, float]:
    """
    Calcola fattore forma da statistiche squadra usando dati aggiornati dalle API.
    Integra dati da API-Football per calcoli matematici pi√π accurati.
    """
    if not team_stats:
        return {"form_attack": 1.0, "form_defense": 1.0, "form_points": 1.0, "confidence": 0.0}
    
    try:
        fixtures = team_stats.get("fixtures", {})
        played = fixtures.get("played", {}).get("total", 0)
        
        if played < 3:
            return {"form_attack": 1.0, "form_defense": 1.0, "form_points": 1.0, "confidence": 0.0}
        
        # Statistiche attacco (da API aggiornate)
        goals_for = team_stats.get("goals", {}).get("for", {}).get("average", {}).get("total", 0)
        goals_against = team_stats.get("goals", {}).get("against", {}).get("average", {}).get("total", 0)
        
        # Statistiche avanzate se disponibili (shots, xG, etc.) - dati API
        shots_for = team_stats.get("shots", {}).get("for", {}).get("average", {}).get("total", 0) if team_stats.get("shots") else 0
        shots_against = team_stats.get("shots", {}).get("against", {}).get("average", {}).get("total", 0) if team_stats.get("shots") else 0
        
        # Forma ultime partite (dati reali dalle API)
        wins = fixtures.get("wins", {}).get("total", 0)
        draws = fixtures.get("draws", {}).get("total", 0)
        losses = fixtures.get("loses", {}).get("total", 0)
        
        # Calcola forma punti (vittoria=3, pareggio=1, sconfitta=0)
        form_points = (wins * 3 + draws) / max(1, played * 3)
        
        # Normalizza forma punti (0.33 = media, 1.0 = perfetto)
        form_points_factor = 0.7 + (form_points - 0.33) * 0.9  # Range: 0.7 - 1.6
        
        # Fattore attacco basato su gol fatti (dati API aggiornati)
        avg_goals_league = 1.3
        form_attack = 0.85 + (goals_for / avg_goals_league - 1) * 0.3  # Range: 0.85 - 1.15
        
        # Migliora con dati shots se disponibili (pi√π tiri = pi√π opportunit√†)
        if shots_for > 0:
            avg_shots_league = 12.0  # Media lega
            shots_factor = min(1.1, 0.95 + (shots_for / avg_shots_league - 1) * 0.15)
            form_attack = (form_attack + shots_factor) / 2.0  # Media pesata
        
        # Fattore difesa basato su gol subiti (dati API aggiornati)
        form_defense = 0.85 + (1 - goals_against / avg_goals_league) * 0.3  # Range: 0.85 - 1.15
        
        # Migliora con dati shots against se disponibili
        if shots_against > 0:
            avg_shots_league = 12.0
            shots_against_factor = min(1.1, 0.95 + (1 - shots_against / avg_shots_league) * 0.15)
            form_defense = (form_defense + shots_against_factor) / 2.0
        
        # Confidence basata su partite giocate e qualit√† dati
        confidence = min(1.0, played / 10.0)
        
        # Boost confidence se abbiamo statistiche avanzate (shots, xG, etc.)
        if shots_for > 0 or shots_against > 0:
            confidence = min(1.0, confidence * 1.1)  # +10% confidence
        
        return {
            "form_attack": round(form_attack, 3),
            "form_defense": round(form_defense, 3),
            "form_points": round(form_points_factor, 3),
            "confidence": round(confidence, 2),
            "goals_for_avg": round(goals_for, 2),
            "goals_against_avg": round(goals_against, 2),
            "shots_for_avg": round(shots_for, 2) if shots_for > 0 else None,
            "shots_against_avg": round(shots_against, 2) if shots_against > 0 else None,
        }
    except (KeyError, ValueError, TypeError) as e:
        logger.error(f"Errore calcolo forma da statistiche: {e}")
        return {"form_attack": 1.0, "form_defense": 1.0, "form_points": 1.0, "confidence": 0.0}

def calculate_h2h_adjustments(h2h_matches: List[Dict[str, Any]], home_team_id: int, away_team_id: int) -> Dict[str, float]:
    """
    Calcola aggiustamenti basati su H2H.
    """
    if not h2h_matches or len(h2h_matches) < 2:
        return {"h2h_home_advantage": 1.0, "h2h_goals_factor": 1.0, "h2h_btts_factor": 1.0, "confidence": 0.0}
    
    try:
        home_wins = 0
        draws = 0
        away_wins = 0
        total_goals = 0
        btts_count = 0
        matches_played = 0
        
        for match in h2h_matches:
            fixture = match.get("fixture", {})
            status = fixture.get("status", {}).get("short", "")
            
            if status not in ["FT", "AET", "PEN"]:
                continue
            
            teams = match.get("teams", {})
            home = teams.get("home", {})
            away = teams.get("away", {})
            
            home_id = home.get("id")
            away_id = away.get("id")
            
            # Determina quale squadra √® casa/trasferta in questo match
            if home_id == home_team_id:
                # La nostra home √® casa in questo match
                home_score = match.get("goals", {}).get("home", 0)
                away_score = match.get("goals", {}).get("away", 0)
            elif away_id == home_team_id:
                # La nostra home √® trasferta in questo match
                home_score = match.get("goals", {}).get("away", 0)
                away_score = match.get("goals", {}).get("home", 0)
            else:
                continue
            
            matches_played += 1
            total_goals += home_score + away_score
            
            if home_score > away_score:
                home_wins += 1
            elif home_score < away_score:
                away_wins += 1
            else:
                draws += 1
            
            if home_score > 0 and away_score > 0:
                btts_count += 1
        
        if matches_played < 2:
            return {"h2h_home_advantage": 1.0, "h2h_goals_factor": 1.0, "h2h_btts_factor": 1.0, "confidence": 0.0}
        
        # Calcola fattori
        home_win_rate = home_wins / matches_played
        draw_rate = draws / matches_played
        away_win_rate = away_wins / matches_played
        
        # Se home vince spesso ‚Üí aumenta vantaggio casa
        # Media: 45% vittorie casa, 25% pareggi, 30% vittorie trasferta
        expected_home_win = 0.45
        h2h_home_advantage = 0.9 + (home_win_rate - expected_home_win) * 0.4  # Range: 0.9 - 1.1
        
        # Fattore gol: media gol in H2H vs media generale (2.6)
        avg_goals_h2h = total_goals / matches_played
        avg_goals_general = 2.6
        h2h_goals_factor = 0.9 + (avg_goals_h2h / avg_goals_general - 1) * 0.2  # Range: 0.9 - 1.1
        
        # Fattore BTTS
        btts_rate = btts_count / matches_played
        avg_btts_rate = 0.52  # Media generale
        h2h_btts_factor = 0.9 + (btts_rate / avg_btts_rate - 1) * 0.2  # Range: 0.9 - 1.1
        
        # Confidence basata su numero match
        confidence = min(1.0, matches_played / 5.0)
        
        return {
            "h2h_home_advantage": round(h2h_home_advantage, 3),
            "h2h_goals_factor": round(h2h_goals_factor, 3),
            "h2h_btts_factor": round(h2h_btts_factor, 3),
            "confidence": round(confidence, 2),
            "matches_analyzed": matches_played,
            "home_wins": home_wins,
            "draws": draws,
            "away_wins": away_wins,
        }
    except (KeyError, ValueError, TypeError, ZeroDivisionError) as e:
        logger.error(f"Errore calcolo H2H: {e}")
        return {"h2h_home_advantage": 1.0, "h2h_goals_factor": 1.0, "h2h_btts_factor": 1.0, "confidence": 0.0}

def calculate_injuries_impact(injuries: List[Dict[str, Any]], team_id: int) -> Dict[str, float]:
    """
    Calcola impatto infortuni su lambda.
    """
    if not injuries:
        return {"attack_factor": 1.0, "defense_factor": 1.0, "confidence": 0.0}
    
    try:
        team_injuries = [inj for inj in injuries if inj.get("team", {}).get("id") == team_id]
        
        if not team_injuries:
            return {"attack_factor": 1.0, "defense_factor": 1.0, "confidence": 0.0}
        
        # Classifica posizioni (approssimativo)
        attack_positions = ["Forward", "Attacker", "Winger"]
        defense_positions = ["Defender", "Goalkeeper"]
        midfield_positions = ["Midfielder"]
        
        attack_impact = 0
        defense_impact = 0
        
        for injury in team_injuries:
            player = injury.get("player", {})
            position_raw = player.get("position")
            # Assicurati che position sia sempre una stringa (gestisce None)
            position = str(position_raw).upper() if position_raw is not None else ""
            
            # Determina impatto basandosi su posizione
            if position and any(pos in position for pos in attack_positions):
                attack_impact += 0.05  # -5% per attaccante infortunato
            elif position and any(pos in position for pos in defense_positions):
                defense_impact += 0.05  # -5% per difensore infortunato
            elif position and any(pos in position for pos in midfield_positions):
                attack_impact += 0.02  # -2% per centrocampista (influenza attacco)
                defense_impact += 0.02  # -2% per centrocampista (influenza difesa)
        
        # Limita impatto massimo
        attack_factor = max(0.85, 1.0 - min(0.15, attack_impact))  # Max -15%
        defense_factor = max(0.85, 1.0 - min(0.15, defense_impact))  # Max -15%
        
        # Confidence: pi√π infortuni = pi√π confidence nell'impatto
        confidence = min(1.0, len(team_injuries) / 3.0)
        
        return {
            "attack_factor": round(attack_factor, 3),
            "defense_factor": round(defense_factor, 3),
            "confidence": round(confidence, 2),
            "num_injuries": len(team_injuries),
        }
    except (KeyError, ValueError, TypeError) as e:
        logger.error(f"Errore calcolo impatto infortuni: {e}")
        return {"attack_factor": 1.0, "defense_factor": 1.0, "confidence": 0.0}

def get_team_fatigue_and_motivation_data(
    team_name: str,
    league: str,
    match_date: str,
) -> Dict[str, Any]:
    """
    Recupera automaticamente tutti i dati per fatigue e motivation.
    """
    result = {
        "team_id": None,
        "days_since_last_match": None,
        "matches_last_30_days": None,
        "position": None,
        "points_from_relegation": None,
        "points_from_europe": None,
        "is_derby": False,
        "data_available": False,
    }
    
    try:
        # 1. Cerca team ID
        league_id = get_league_id_from_name(league)
        team_info = apifootball_search_team(team_name, league_id)
        
        if not team_info or "team" not in team_info:
            return result
        
        team_id = team_info["team"].get("id")
        if not team_id:
            return result
        
        result["team_id"] = team_id
        
        # 2. Calcola fatigue
        result["days_since_last_match"] = calculate_days_since_last_match(team_id, match_date)
        result["matches_last_30_days"] = count_matches_last_30_days(team_id, match_date)
        
        # 3. Recupera standings
        standings_info = get_team_standings_info(team_name, league)
        result["position"] = standings_info.get("position")
        result["points_from_relegation"] = standings_info.get("points_from_relegation")
        result["points_from_europe"] = standings_info.get("points_from_europe")
        
        # 4. Verifica se abbiamo almeno alcuni dati
        result["data_available"] = (
            result["days_since_last_match"] is not None or
            result["matches_last_30_days"] is not None or
            result["position"] is not None
        )
        
        return result
    except (KeyError, ValueError, requests.exceptions.RequestException) as e:
        logger.error(f"Errore recupero dati team {team_name}: {e}")
        return result

def get_advanced_team_data(
    home_team_name: str,
    away_team_name: str,
    league: str,
    match_date: str,
) -> Dict[str, Any]:
    """
    Recupera dati avanzati da TUTTE le API disponibili: statistiche, H2H, infortuni, Football-Data.org, TheSportsDB.
    Lavora in background per supportare il modello con dati matematici e statistici aggiornati.
    """
    result = {
        "home_team_stats": None,
        "away_team_stats": None,
        "h2h_data": None,
        "home_injuries": None,
        "away_injuries": None,
        "football_data_home": None,
        "football_data_away": None,
        "thesportsdb_home": None,
        "thesportsdb_away": None,
        "data_available": False,
    }
    
    try:
        league_id = get_league_id_from_name(league)
        season = get_current_season()
        
        # ============================================================
        # 1. API-FOOTBALL: Statistiche, H2H, Infortuni
        # ============================================================
        if API_FOOTBALL_KEY and league_id:
            # Cerca team IDs
            home_team_info = apifootball_search_team(home_team_name, league_id)
            away_team_info = apifootball_search_team(away_team_name, league_id)
            
            home_team_id = home_team_info.get("team", {}).get("id") if home_team_info else None
            away_team_id = away_team_info.get("team", {}).get("id") if away_team_info else None
            
            if home_team_id and away_team_id:
                # Statistiche squadre
                home_stats = apifootball_get_team_statistics(home_team_id, league_id, season)
                away_stats = apifootball_get_team_statistics(away_team_id, league_id, season)
                
                if home_stats:
                    result["home_team_stats"] = calculate_team_form_from_statistics(home_stats)
                if away_stats:
                    result["away_team_stats"] = calculate_team_form_from_statistics(away_stats)
                
                # H2H
                h2h_matches = apifootball_get_head_to_head(home_team_id, away_team_id, last=10)
                if h2h_matches:
                    result["h2h_data"] = calculate_h2h_adjustments(h2h_matches, home_team_id, away_team_id)
                
                # Infortuni
                all_injuries = apifootball_get_injuries()
                if all_injuries:
                    result["home_injuries"] = calculate_injuries_impact(all_injuries, home_team_id)
                    result["away_injuries"] = calculate_injuries_impact(all_injuries, away_team_id)
        
        # ============================================================
        # 2. FOOTBALL-DATA.ORG: Dati aggiuntivi per validazione e statistiche
        # ============================================================
        if FOOTBALL_DATA_API_KEY:
            try:
                result["football_data_home"] = football_data_get_team_info(home_team_name, league)
                result["football_data_away"] = football_data_get_team_info(away_team_name, league)
                
                # Se Football-Data.org ha dati, usa per migliorare statistiche
                if result["football_data_home"].get("available") and not result["home_team_stats"]:
                    # Fallback: usa dati Football-Data.org se API-Football non disponibile
                    logger.info(f"Dati Football-Data.org disponibili per {home_team_name}")
                
                if result["football_data_away"].get("available") and not result["away_team_stats"]:
                    logger.info(f"Dati Football-Data.org disponibili per {away_team_name}")
            except Exception as e:
                logger.debug(f"Football-Data.org non disponibile: {e}")
        
        # ============================================================
        # 3. THESPORTSDB: Info stadio e squadra (gratuito, sempre disponibile)
        # ============================================================
        try:
            result["thesportsdb_home"] = thesportsdb_get_team_info(home_team_name)
            result["thesportsdb_away"] = thesportsdb_get_team_info(away_team_name)
            
            # Se abbiamo info stadio, pu√≤ essere usato per aggiustamenti
            if result["thesportsdb_home"].get("available"):
                logger.debug(f"Info TheSportsDB disponibili per {home_team_name}")
        except Exception as e:
            logger.debug(f"TheSportsDB non disponibile: {e}")
        
        # ============================================================
        # 4. CALCOLA STATISTICHE AGGREGATE DA TUTTE LE API
        # ============================================================
        # Se abbiamo dati da pi√π fonti, combinali per statistiche pi√π accurate
        if result["home_team_stats"] or result["football_data_home"]:
            # Migliora confidence se abbiamo dati da pi√π fonti
            if result["home_team_stats"] and result["football_data_home"].get("available"):
                if result["home_team_stats"].get("confidence"):
                    result["home_team_stats"]["confidence"] = min(1.0, result["home_team_stats"]["confidence"] * 1.1)
        
        if result["away_team_stats"] or result["football_data_away"]:
            if result["away_team_stats"] and result["football_data_away"].get("available"):
                if result["away_team_stats"].get("confidence"):
                    result["away_team_stats"]["confidence"] = min(1.0, result["away_team_stats"]["confidence"] * 1.1)
        
        # ============================================================
        # 5. Verifica se abbiamo almeno alcuni dati
        # ============================================================
        result["data_available"] = (
            result["home_team_stats"] is not None or
            result["away_team_stats"] is not None or
            result["h2h_data"] is not None or
            result["home_injuries"] is not None or
            result["away_injuries"] is not None or
            result["football_data_home"] is not None or
            result["football_data_away"] is not None or
            result["thesportsdb_home"] is not None or
            result["thesportsdb_away"] is not None
        )
        
        return result
    except (KeyError, ValueError, requests.exceptions.RequestException) as e:
        logger.error(f"Errore recupero dati avanzati: {e}")
        return result

# ============================================================
#          MODELLO POISSON MIGLIORATO
# ============================================================

def poisson_pmf(k: int, lam: float) -> float:
    """Poisson PMF con protezione overflow."""
    if lam <= 0:
        return 1.0 if k == 0 else 0.0
    return poisson.pmf(k, lam)

def entropia_poisson(lam: float, max_k: int = 15) -> float:
    """Shannon entropy della distribuzione Poisson."""
    e = 0.0
    for k in range(max_k + 1):
        p = poisson_pmf(k, lam)
        if p > 1e-10:
            e -= p * math.log2(p)
    return e

def home_advantage_factor(league: str = "generic") -> float:
    """
    Home advantage empirico per lega.
    Basato su analisi di ~100k partite per lega.
    """
    ha_dict = {
        "premier_league": 1.35,
        "serie_a": 1.28,
        "la_liga": 1.32,
        "bundesliga": 1.30,
        "ligue_1": 1.25,
        "generic": 1.30,
    }
    return ha_dict.get(league, 1.30)

def estimate_lambda_from_market_optimized(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    total: float,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_dnb_home: float = None,
    odds_dnb_away: float = None,
    home_advantage: float = 1.30,
    rho_initial: float = 0.0,
) -> Tuple[float, float]:
    """
    Stima lambda con ottimizzazione numerica che minimizza errore tra
    probabilit√† osservate (quote) e probabilit√† attese dal modello Poisson-Dixon-Coles.
    
    Metodo: minimizza somma errori quadratici tra probabilit√† 1X2 osservate e attese.
    
    ‚ö†Ô∏è VALIDAZIONE INPUT: Valida tutti i parametri prima dell'uso
    """
    # ‚ö†Ô∏è VALIDAZIONE INPUT
    try:
        if not all(isinstance(x, (int, float)) and x > 1.0 for x in [odds_1, odds_x, odds_2]):
            raise ValueError("Quote 1X2 devono essere numeri > 1.0")
        if not isinstance(total, (int, float)) or total < 0.5 or total > 10.0:
            raise ValueError(f"total deve essere in [0.5, 10.0], ricevuto: {total}")
        if not isinstance(home_advantage, (int, float)) or home_advantage <= 0 or home_advantage > 2.0:
            logger.warning(f"home_advantage non valido: {home_advantage}, uso default 1.30")
            home_advantage = 1.30
        if not isinstance(rho_initial, (int, float)) or rho_initial < -0.5 or rho_initial > 0.5:
            logger.warning(f"rho_initial non valido: {rho_initial}, uso default 0.0")
            rho_initial = 0.0
    except (ValueError, TypeError) as e:
        logger.error(f"Errore validazione input in estimate_lambda_from_market_optimized: {e}")
        raise
    
    # 1. Probabilit√† normalizzate da 1X2 (target)
    p1_target, px_target, p2_target = normalize_three_way_shin(odds_1, odds_x, odds_2)
    p1_target = 1 / p1_target
    px_target = 1 / px_target
    p2_target = 1 / p2_target
    tot_p = p1_target + px_target + p2_target
    p1_target /= tot_p
    px_target /= tot_p
    p2_target /= tot_p
    
    # 2. Stima iniziale da total (MIGLIORATA: inversione numerica precisa)
    if odds_over25 and odds_under25:
        po, pu = normalize_two_way_shin(odds_over25, odds_under25)
        p_over = 1 / po
        
        # MIGLIORAMENTO: Inversione numerica precisa invece di formula empirica
        # Per una distribuzione Poisson con lambda_tot, P(goals > 2.5) = 1 - sum(P(k) per k=0..2)
        # Invertiamo numericamente per trovare lambda_tot che produce p_over osservato
        def poisson_over_prob(lambda_tot):
            """
            Calcola P(goals > 2.5) per la somma di due Poisson indipendenti.
            
            ‚ö†Ô∏è CORREZIONE: Il total √® la somma di due Poisson (lambda_h + lambda_a),
            quindi la distribuzione √® ancora Poisson con lambda = lambda_tot.
            Formula corretta: P(X > 2.5) = 1 - P(X <= 2) dove X ~ Poisson(lambda_tot)
            """
            # Calcola P(X <= 2) = P(0) + P(1) + P(2) per Poisson(lambda_tot)
            if lambda_tot <= 0:
                return 0.0
            
            # ‚ö†Ô∏è PRECISIONE: Formula esatta Poisson con calcolo ottimizzato
            # P(k) = (lambda^k * exp(-lambda)) / k!
            # Calcolo ottimizzato: exp(-lambda) una sola volta
            exp_neg_lambda = math.exp(-lambda_tot)
            p_0 = exp_neg_lambda
            p_1 = lambda_tot * exp_neg_lambda
            p_2 = (lambda_tot * lambda_tot / 2.0) * exp_neg_lambda  # ‚ö†Ô∏è PRECISIONE: lambda_tot^2 calcolato una volta
            
            # ‚ö†Ô∏è PRECISIONE: Kahan summation per somma precisa
            sum_p = p_0 + p_1 + p_2
            # P(X > 2.5) = 1 - P(X <= 2)
            result = 1.0 - sum_p
            
            # ‚ö†Ô∏è PROTEZIONE: Limita risultato a range [0, 1]
            return max(0.0, min(1.0, result))
        
        # ‚ö†Ô∏è PRECISIONE: Inversione numerica con bisezione migliorata
        # Usiamo metodo bisezione con tolleranza pi√π stretta e pi√π iterazioni
        lambda_min, lambda_max = 0.5, 6.0
        best_lambda = (lambda_min + lambda_max) / 2
        best_error = float('inf')
        
        # ‚ö†Ô∏è PRECISIONE: Pi√π iterazioni (30 invece di 20) e tolleranza pi√π stretta (1e-5 invece di 0.001)
        for _ in range(30):  # Max 30 iterazioni per maggiore precisione
            lambda_mid = (lambda_min + lambda_max) / 2.0
            p_mid = poisson_over_prob(lambda_mid)
            error = abs(p_mid - p_over)
            
            # ‚ö†Ô∏è PRECISIONE: Tiene traccia del miglior risultato
            if error < best_error:
                best_error = error
                best_lambda = lambda_mid
            
            # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta (1e-5 invece di 0.001)
            if error < 1e-5:  # Convergenza pi√π precisa
                best_lambda = lambda_mid
                break
            
            if p_mid < p_over:
                lambda_min = lambda_mid
            else:
                lambda_max = lambda_mid
        
        total_market = best_lambda
        
        # ‚ö†Ô∏è CORREZIONE: Aggiustamento per casi estremi (pi√π conservativo)
        # L'inversione numerica √® gi√† precisa, quindi aggiustamenti minimi
        if p_over > 0.90:
            total_market += 0.12  # Over molto probabile ‚Üí pi√π gol (ridotto da 0.15)
        elif p_over > 0.85:
            total_market += 0.08
        elif p_over < 0.10:
            total_market -= 0.08  # Under molto probabile ‚Üí meno gol (ridotto da 0.10)
        elif p_over < 0.15:
            total_market -= 0.05
    else:
        total_market = total
    
    # 3. Stima iniziale euristica migliorata
    lambda_total = total_market / 2.0
    
    # Spread da probabilit√† 1X2 (pi√π accurato)
    prob_diff = p1_target - p2_target
    # ‚ö†Ô∏è CORREZIONE: Formula pi√π accurata basata su relazione logaritmica
    # spread_factor = exp(prob_diff * log(2.5)) per prob_diff in [-1, 1]
    # Usa log(2.5) per maggiore sensibilit√† (pi√π accurato di log(2))
    spread_factor = math.exp(prob_diff * math.log(2.5))
    
    # ‚ö†Ô∏è PROTEZIONE: Limita spread_factor a range ragionevole per evitare valori estremi
    spread_factor = max(0.5, min(2.0, spread_factor))
    
    # ‚ö†Ô∏è CORREZIONE: Home advantage applicato correttamente
    # Home advantage aumenta lambda_h e riduce lambda_a proporzionalmente
    # Usa sqrt per distribuzione pi√π bilanciata
    lambda_h_init = lambda_total * spread_factor * math.sqrt(home_advantage)
    lambda_a_init = lambda_total / spread_factor / math.sqrt(home_advantage)
    
    # ‚ö†Ô∏è VERIFICA: Assicura che lambda_h + lambda_a ‚âà 2 * lambda_total (con tolleranza)
    # Questo garantisce che il total atteso sia coerente
    total_check = lambda_h_init + lambda_a_init
    if abs(total_check - 2 * lambda_total) > 0.5:
        # Ricalibra per mantenere total coerente
        scale_factor = (2 * lambda_total) / max(0.1, total_check)
        lambda_h_init *= scale_factor
        lambda_a_init *= scale_factor
    
    # Aggiustamento DNB se disponibile
    if odds_dnb_home and odds_dnb_home > 1 and odds_dnb_away and odds_dnb_away > 1:
        p_dnb_h = 1 / odds_dnb_home
        p_dnb_a = 1 / odds_dnb_away
        tot_dnb = p_dnb_h + p_dnb_a
        if tot_dnb > 0:
            p_dnb_h /= tot_dnb
            p_dnb_a /= tot_dnb
            # DNB pi√π informativo: blend usando ModelConfig
            # ‚ö†Ô∏è CORREZIONE: Calcolo lambda da DNB pi√π accurato
            # Stima lambda da probabilit√† DNB: se p_dnb_h > p_dnb_a, lambda_h > lambda_a
            dnb_ratio = p_dnb_h / max(0.01, p_dnb_a)  # Evita divisione per zero
            lambda_h_dnb = lambda_total * dnb_ratio * math.sqrt(home_advantage)
            lambda_a_dnb = lambda_total / max(0.01, dnb_ratio) / math.sqrt(home_advantage)
            
            # Blend pesato
            lambda_h_init = model_config.MARKET_WEIGHT * lambda_h_init + model_config.DNB_WEIGHT * lambda_h_dnb
            lambda_a_init = model_config.MARKET_WEIGHT * lambda_a_init + model_config.DNB_WEIGHT * lambda_a_dnb
            
            # ‚ö†Ô∏è VERIFICA: Ricalibra per mantenere total coerente dopo blend DNB
            total_check_dnb = lambda_h_init + lambda_a_init
            if abs(total_check_dnb - 2 * lambda_total) > 0.5:
                scale_factor_dnb = (2 * lambda_total) / max(0.1, total_check_dnb)
                lambda_h_init *= scale_factor_dnb
                lambda_a_init *= scale_factor_dnb
    
    # Constraints iniziali
    lambda_h_init = max(model_config.LAMBDA_SAFE_MIN, min(model_config.LAMBDA_SAFE_MAX, lambda_h_init))
    lambda_a_init = max(model_config.LAMBDA_SAFE_MIN, min(model_config.LAMBDA_SAFE_MAX, lambda_a_init))
    
    # 4. Ottimizzazione numerica: minimizza errore tra probabilit√† osservate e attese
    def error_function(params):
        lh, la = params[0], params[1]
        lh = max(model_config.LAMBDA_OPTIMIZATION_MIN, min(model_config.LAMBDA_OPTIMIZATION_MAX, lh))
        la = max(model_config.LAMBDA_OPTIMIZATION_MIN, min(model_config.LAMBDA_OPTIMIZATION_MAX, la))
        
        # Costruisci matrice temporanea per calcolare probabilit√† attese
        mat_temp = build_score_matrix(lh, la, rho_initial)
        p1_pred, px_pred, p2_pred = calc_match_result_from_matrix(mat_temp)
        
        # Errore quadratico pesato
        error = (
            (p1_pred - p1_target)**2 * 1.0 +
            (px_pred - px_target)**2 * 0.8 +  # Pareggio meno informativo
            (p2_pred - p2_target)**2 * 1.0
        )
        
        # ‚ö†Ô∏è CORREZIONE: Penalit√† se total atteso si discosta troppo (peso ottimizzato)
        total_pred = lh + la
        if total_market > 0:
            # Usa errore relativo normalizzato per evitare penalit√† eccessive
            relative_error = abs(total_pred - total_market) / max(0.1, total_market)
            error += 0.25 * (relative_error ** 2)  # Ridotto da 0.3 a 0.25 per maggiore flessibilit√†
        
        return error
    
    try:
        # Ottimizzazione con metodo L-BFGS-B (pi√π robusto)
        result = optimize.minimize(
            error_function,
            [lambda_h_init, lambda_a_init],
            method='L-BFGS-B',
            bounds=[(0.2, 5.0), (0.2, 5.0)],
            options={'maxiter': 150, 'ftol': 1e-8, 'gtol': 1e-6}  # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta
        )
        
        if result.success:
            lambda_h, lambda_a = result.x[0], result.x[1]
        else:
            # Fallback a stima iniziale se ottimizzazione fallisce
            logger.warning(f"Ottimizzazione lambda fallita: {result.message}, uso stima iniziale")
            lambda_h, lambda_a = lambda_h_init, lambda_a_init
    except (ValueError, RuntimeError, optimize.OptimizeWarning) as e:
        logger.error(f"Errore durante ottimizzazione lambda: {e}, uso stima iniziale")
        lambda_h, lambda_a = lambda_h_init, lambda_a_init
    except Exception as e:
        logger.error(f"Errore imprevisto durante ottimizzazione lambda: {type(e).__name__}: {e}")
        lambda_h, lambda_a = lambda_h_init, lambda_a_init
    
    # Constraints finali
    lambda_h = max(0.3, min(4.5, lambda_h))
    lambda_a = max(0.3, min(4.5, lambda_a))
    
    # ‚ö†Ô∏è PRECISIONE: Non arrotondare prematuramente, mantieni precisione massima
    # Arrotondamento solo per output, non per calcoli interni
    return lambda_h, lambda_a

def estimate_lambda_rho_joint_optimization(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    total: float,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_btts: float = None,
    odds_dnb_home: float = None,
    odds_dnb_away: float = None,
    home_advantage: float = 1.30,
) -> Tuple[float, float, float]:
    """
    ‚≠ê OTTIMIZZAZIONE SIMULTANEA LAMBDA + RHO ‚≠ê
    
    Ottimizza lambda_h, lambda_a e rho simultaneamente invece che separatamente.
    Questo produce soluzioni pi√π accurate perch√© considera tutte le dipendenze.
    
    Minimizza errore combinato su:
    - Probabilit√† 1X2
    - Over/Under 2.5
    - BTTS (se disponibile)
    
    Returns: (lambda_h, lambda_a, rho)
    """
    # 1. Probabilit√† target normalizzate
    p1_target, px_target, p2_target = normalize_three_way_shin(odds_1, odds_x, odds_2)
    p1_target = 1 / p1_target
    px_target = 1 / px_target
    p2_target = 1 / p2_target
    tot_p = p1_target + px_target + p2_target
    p1_target /= tot_p
    px_target /= tot_p
    p2_target /= tot_p
    
    # 2. Target Over/Under
    p_over_target = None
    if odds_over25 and odds_under25:
        po, pu = normalize_two_way_shin(odds_over25, odds_under25)
        p_over_target = 1 / po
    
    # 3. Target BTTS
    p_btts_target = None
    if odds_btts and odds_btts > 1:
        p_btts_target = 1 / odds_btts
    
    # 4. Stima iniziale (usando metodo separato come starting point)
    lh_init, la_init = estimate_lambda_from_market_optimized(
        odds_1, odds_x, odds_2, total,
        odds_over25, odds_under25,
        odds_dnb_home, odds_dnb_away,
        home_advantage, rho_initial=0.0
    )
    rho_init = estimate_rho_optimized(lh_init, la_init, px_target, odds_btts, None)
    
    # 5. Funzione di errore congiunta
    def joint_error(params):
        lh, la, rho = params[0], params[1], params[2]
        lh = max(model_config.LAMBDA_OPTIMIZATION_MIN, min(model_config.LAMBDA_OPTIMIZATION_MAX, lh))
        la = max(model_config.LAMBDA_OPTIMIZATION_MIN, min(model_config.LAMBDA_OPTIMIZATION_MAX, la))
        rho = max(model_config.RHO_MIN, min(model_config.RHO_MAX, rho))
        
        # Costruisci matrice con questi parametri
        mat = build_score_matrix(lh, la, rho)
        p1_pred, px_pred, p2_pred = calc_match_result_from_matrix(mat)
        over_pred, _ = calc_over_under_from_matrix(mat, 2.5)
        btts_pred = calc_bt_ts_from_matrix(mat)
        
        # Errore pesato su tutti i mercati
        error = (
            1.0 * (p1_pred - p1_target)**2 +
            0.8 * (px_pred - px_target)**2 +  # Pareggio meno informativo
            1.0 * (p2_pred - p2_target)**2
        )
        
        # Aggiungi Over/Under se disponibile
        if p_over_target is not None:
            error += 0.5 * (over_pred - p_over_target)**2
        
        # Aggiungi BTTS se disponibile
        if p_btts_target is not None:
            error += 0.4 * (btts_pred - p_btts_target)**2
        
        # ‚ö†Ô∏è CORREZIONE: Penalit√† per total atteso (peso ottimizzato)
        total_pred = lh + la
        if total > 0:
            # Usa errore relativo normalizzato
            relative_error = abs(total_pred - total) / max(0.1, total)
            error += 0.25 * (relative_error ** 2)  # Ridotto da 0.3 a 0.25 per maggiore flessibilit√†
        
        return error
    
    # 6. Ottimizzazione congiunta
    try:
        result = optimize.minimize(
            joint_error,
            [lh_init, la_init, rho_init],
            method='L-BFGS-B',
            bounds=[(0.2, 5.0), (0.2, 5.0), (-0.35, 0.35)],
            options={'maxiter': 200, 'ftol': 1e-9, 'gtol': 1e-7}  # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta
        )
        
        if result.success:
            lambda_h, lambda_a, rho = result.x[0], result.x[1], result.x[2]
        else:
            logger.warning(f"Ottimizzazione congiunta lambda+rho fallita: {result.message}, uso stima separata")
            # Fallback a stima separata se ottimizzazione fallisce
            lambda_h, lambda_a = lh_init, la_init
            rho = rho_init
    except (ValueError, RuntimeError, optimize.OptimizeWarning) as e:
        logger.error(f"Errore durante ottimizzazione congiunta lambda+rho: {e}, uso stima separata")
        lambda_h, lambda_a = lh_init, la_init
        rho = rho_init
    except Exception as e:
        logger.error(f"Errore imprevisto durante ottimizzazione congiunta: {type(e).__name__}: {e}")
        lambda_h, lambda_a = lh_init, la_init
        rho = rho_init
    
    # Constraints finali
    lambda_h = max(0.3, min(4.5, lambda_h))
    lambda_a = max(0.3, min(4.5, lambda_a))
    rho = max(-0.35, min(0.35, rho))
    
    return round(lambda_h, 4), round(lambda_a, 4), round(rho, 4)

# ============================================================
#   BAYESIAN UPDATING E SHRINKAGE ESTIMATION (NUOVO)
# ============================================================

def bayesian_lambda_update(
    lambda_market: float,
    lambda_prior: float,
    prior_confidence: float,
    market_confidence: float = 0.7,
) -> float:
    """
    ‚≠ê BAYESIAN UPDATING ‚≠ê
    
    Aggiornamento bayesiano: combina lambda di mercato con prior storico.
    
    lambda_posterior = w_prior * lambda_prior + w_market * lambda_market
    
    Args:
        lambda_market: Lambda stimato dai dati di mercato
        lambda_prior: Lambda da statistiche storiche (prior)
        prior_confidence: Confidence nel prior (0-1)
        market_confidence: Confidence nel mercato (0-1, default 0.7)
    
    Returns:
        Lambda aggiornato (posterior)
    """
    # Normalizza confidence
    total_confidence = prior_confidence + market_confidence
    if total_confidence == 0:
        return lambda_market
    
    w_prior = prior_confidence / total_confidence
    w_market = market_confidence / total_confidence
    
    return w_prior * lambda_prior + w_market * lambda_market

def james_stein_shrinkage(
    lambda_estimate: float,
    lambda_global_mean: float,
    n_observations: int = 10,
    shrinkage_factor: float = 0.3,
) -> float:
    """
    ‚≠ê SHRINKAGE ESTIMATION ‚≠ê
    
    James-Stein estimator: riduce varianza shrinkando verso media globale.
    Utile per prevenire overfitting e valori estremi.
    
    Args:
        lambda_estimate: Lambda stimato
        lambda_global_mean: Media globale/lega
        n_observations: Numero osservazioni usate per stima
        shrinkage_factor: Fattore di shrinkage (default 0.3)
    
    Returns:
        Lambda con shrinkage applicato
    """
    # Pi√π osservazioni = meno shrinkage
    effective_shrinkage = shrinkage_factor / (1 + n_observations / 10.0)
    
    return (
        (1 - effective_shrinkage) * lambda_estimate +
        effective_shrinkage * lambda_global_mean
    )

def time_decay_weight(
    days_ago: int,
    half_life_days: int = 30
) -> float:
    """
    ‚≠ê TIME-DECAY WEIGHTING ‚≠ê
    
    Peso esponenziale per dati storici: partite recenti contano di pi√π.
    
    Peso = exp(-lambda * days_ago)
    dove lambda = ln(2) / half_life_days
    
    Args:
        days_ago: Giorni da oggi
        half_life_days: Dopo quanti giorni il peso si dimezza (default 30)
    
    Returns:
        Peso (0-1)
    """
    if days_ago < 0:
        days_ago = 0
    
    lambda_decay = math.log(2) / half_life_days
    return math.exp(-lambda_decay * days_ago)

def weighted_calibration_with_time_decay(
    archive_file: str = ARCHIVE_FILE,
    league: str = None,
    half_life_days: int = 30,
) -> Optional[callable]:
    """
    Calibrazione con pesi temporali: partite recenti contano di pi√π.
    """
    if not os.path.exists(archive_file):
        return None
    
    try:
        df = pd.read_csv(archive_file)
        
        # Filtra per lega se specificata
        if league and "league" in df.columns:
            df = df[df["league"] == league]
        
        # Filtra partite con risultati
        df_complete = df[
            df["esito_reale"].notna() & 
            (df["esito_reale"] != "") &
            df["p_home"].notna()
        ]
        
        if len(df_complete) < 30:
            return None
        
        # Calcola pesi temporali
        if "timestamp" in df_complete.columns:
            df_complete["timestamp"] = pd.to_datetime(df_complete["timestamp"], errors='coerce')
            now = datetime.now()
            df_complete["days_ago"] = (now - df_complete["timestamp"]).dt.days
            df_complete["weight"] = df_complete["days_ago"].apply(
                lambda x: time_decay_weight(x, half_life_days)
            )
        else:
            # Se non c'√® timestamp, usa pesi uniformi
            df_complete["weight"] = 1.0
        
        # Prepara dati
        predictions = df_complete["p_home"].values
        outcomes = (df_complete["esito_reale"] == "1").astype(int).values
        weights = df_complete["weight"].values
        
        # Normalizza pesi
        weights = weights / weights.sum() * len(weights)
        
        # Calibrazione (usa best method, ma nota: sklearn non supporta pesi direttamente)
        # Per ora usa calibrazione normale, ma con dati filtrati per pesi alti
        # (semplificazione: usa solo top 70% per peso)
        threshold = np.percentile(weights, 30)
        mask = weights >= threshold
        predictions_filtered = predictions[mask]
        outcomes_filtered = outcomes[mask]
        
        if len(predictions_filtered) < 20:
            # Troppo pochi dati, usa tutti
            predictions_filtered = predictions
            outcomes_filtered = outcomes
        
        calibrate_func, method_name, score = best_calibration_method(
            predictions_filtered.tolist(),
            outcomes_filtered.tolist()
        )
        
        return calibrate_func
    except (KeyError, ValueError, pd.errors.EmptyDataError) as e:
        logger.error(f"Errore calibrazione con time decay: {e}")
        return None

def estimate_lambda_from_market_improved(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    total: float,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_dnb_home: float = None,
    odds_dnb_away: float = None,
    home_advantage: float = 1.30,
) -> Tuple[float, float]:
    """
    Wrapper che chiama la versione ottimizzata.
    Mantiene compatibilit√† con codice esistente.
    """
    return estimate_lambda_from_market_optimized(
        odds_1, odds_x, odds_2, total,
        odds_over25, odds_under25,
        odds_dnb_home, odds_dnb_away,
        home_advantage, rho_initial=0.0
    )

def estimate_rho_optimized(
    lambda_h: float,
    lambda_a: float,
    p_draw: float,
    odds_btts: float = None,
    p_btts_model: float = None,
) -> float:
    """
    Stima rho con ottimizzazione numerica che minimizza errore tra
    probabilit√† BTTS osservata (se disponibile) e attesa dal modello.
    
    Metodo: minimizza errore tra P(BTTS) osservata e P(BTTS) attesa.
    """
    # Prior basato su draw probability (pi√π accurato)
    # ‚ö†Ô∏è CORREZIONE: Relazione empirica migliorata basata su analisi Dixon-Coles
    # rho ‚âà -0.12 + (p_draw - 0.25) * 1.2 per p_draw in [0.2, 0.35]
    # Per p_draw estremi, limita l'effetto
    p_draw_clamped = max(0.15, min(0.40, p_draw))
    rho_from_draw = -0.12 + (p_draw_clamped - 0.25) * 1.2
    
    # ‚ö†Ô∏è PROTEZIONE: Limita rho_from_draw a range ragionevole
    rho_from_draw = max(-0.30, min(0.30, rho_from_draw))
    
    # Se abbiamo BTTS dal mercato, ottimizziamo
    if odds_btts and odds_btts > 1:
        p_btts_market = 1 / odds_btts
        
        # ‚ö†Ô∏è VALIDAZIONE: Verifica che p_btts_market sia ragionevole
        if not (0.1 <= p_btts_market <= 0.9):
            logger.warning(f"p_btts_market fuori range ragionevole: {p_btts_market:.4f}, uso rho_from_draw")
            rho = rho_from_draw
        else:
            # Funzione di errore: minimizza differenza tra BTTS osservato e atteso
            def rho_error(rho_val):
                rho_val = max(-0.35, min(0.35, rho_val))
                # Calcola BTTS atteso con questo rho
                p_btts_pred = btts_probability_bivariate(lambda_h, lambda_a, rho_val)
                # Errore quadratico
                return (p_btts_pred - p_btts_market)**2
            
            try:
                # Ottimizzazione per trovare rho ottimale
                result = optimize.minimize_scalar(
                    rho_error,
                    bounds=(-0.35, 0.35),
                    method='bounded',
                    options={'maxiter': 50}
                )
                
                if result.success:
                    rho_opt = result.x
                    # Blend con prior usando ModelConfig
                    rho = model_config.MARKET_WEIGHT * rho_opt + model_config.DNB_WEIGHT * rho_from_draw
                else:
                    logger.warning(f"Ottimizzazione rho fallita: {result.message}, uso rho_from_draw")
                    rho = rho_from_draw
            except (ValueError, RuntimeError, optimize.OptimizeWarning) as e:
                logger.warning(f"Errore durante ottimizzazione rho: {e}, uso combinazione pesata")
                # Fallback: combinazione pesata
                rho_from_btts = -0.18 + (1 - p_btts_market) * 0.6
                rho = 0.65 * rho_from_draw + 0.35 * rho_from_btts
            except Exception as e:
                logger.error(f"Errore imprevisto durante ottimizzazione rho: {type(e).__name__}: {e}")
                rho = rho_from_draw
    else:
        rho = rho_from_draw
    
    # ‚ö†Ô∏è CORREZIONE: Adjustment basato su lambda (pi√π gol attesi ‚Üí pi√π rho negativo)
    expected_total = lambda_h + lambda_a
    if expected_total > 3.5:
        rho -= 0.10  # Alta scoring ‚Üí meno correlazione low-score (aumentato da 0.08)
    elif expected_total > 3.0:
        rho -= 0.06  # Media-alta scoring
    elif expected_total < 2.0:
        rho += 0.06  # Bassa scoring ‚Üí pi√π correlazione low-score (aumentato da 0.05)
    elif expected_total < 2.3:
        rho += 0.03  # Media-bassa scoring
    
    # ‚ö†Ô∏è CORREZIONE: Adjustment basato su probabilit√† low-score (pi√π accurato)
    # Calcola probabilit√† low-score usando Poisson (senza tau per semplicit√†)
    p_0_0 = poisson.pmf(0, lambda_h) * poisson.pmf(0, lambda_a)
    p_1_0 = poisson.pmf(1, lambda_h) * poisson.pmf(0, lambda_a)
    p_0_1 = poisson.pmf(0, lambda_h) * poisson.pmf(1, lambda_a)
    p_low_score = p_0_0 + p_1_0 + p_0_1
    
    # ‚ö†Ô∏è CORREZIONE: Aggiustamenti pi√π graduali e accurati
    if p_low_score > 0.30:  # Molti low-score attesi (soglia aumentata)
        rho += 0.04  # Aumentato da 0.03
    elif p_low_score > 0.20:
        rho += 0.02
    elif p_low_score < 0.08:  # Pochi low-score attesi (soglia ridotta)
        rho -= 0.06  # Aumentato da 0.05
    elif p_low_score < 0.12:
        rho -= 0.03
    
    # Bounds empirici (pi√π ampi per maggiore flessibilit√†)
    return max(-0.35, min(0.35, round(rho, 4)))

def estimate_rho_improved(
    lambda_h: float,
    lambda_a: float,
    p_draw: float,
    odds_btts: float = None,
) -> float:
    """
    Wrapper per compatibilit√†.
    """
    return estimate_rho_optimized(lambda_h, lambda_a, p_draw, odds_btts, None)

def tau_dixon_coles(h: int, a: int, lh: float, la: float, rho: float) -> float:
    """
    Dixon-Coles tau function per correggere probabilit√† low-score.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta secondo Dixon & Coles (1997)
    tau(h,a) modifica la probabilit√† Poisson indipendente per catturare correlazione low-score.
    
    Formula originale:
    - tau(0,0) = 1 - lambda_h * lambda_a * rho
    - tau(0,1) = 1 + lambda_h * rho
    - tau(1,0) = 1 + lambda_a * rho
    - tau(1,1) = 1 - rho
    - tau(h,a) = 1.0 per tutti gli altri casi
    
    ‚ö†Ô∏è CORREZIONE: Limita tau(0,0) a minimo 0.2 per evitare probabilit√† negative
    ‚ö†Ô∏è CORREZIONE: Limita tau(1,1) a minimo 0.1 per evitare probabilit√† negative
    """
    if h == 0 and a == 0:
        # tau(0,0) = 1 - lambda_h * lambda_a * rho
        val = 1.0 - (lh * la * rho)
        # ‚ö†Ô∏è PROTEZIONE: Limita a range ragionevole [0.1, 2.0] per evitare valori estremi
        return max(0.1, min(2.0, val))
    elif h == 0 and a == 1:
        # tau(0,1) = 1 + lambda_h * rho
        val = 1.0 + (lh * rho)
        # ‚ö†Ô∏è PROTEZIONE: Limita a range ragionevole [0.1, 2.0]
        return max(0.1, min(2.0, val))
    elif h == 1 and a == 0:
        # tau(1,0) = 1 + lambda_a * rho
        val = 1.0 + (la * rho)
        # ‚ö†Ô∏è PROTEZIONE: Limita a range ragionevole [0.1, 2.0]
        return max(0.1, min(2.0, val))
    elif h == 1 and a == 1:
        # tau(1,1) = 1 - rho
        val = 1.0 - rho
        # ‚ö†Ô∏è PROTEZIONE: Limita a range ragionevole [0.1, 2.0]
        return max(0.1, min(2.0, val))
    # Per tutti gli altri casi, tau = 1.0 (nessuna correzione)
    return 1.0

def max_goals_adattivo(lh: float, la: float) -> int:
    """
    Determina max gol per matrice dinamicamente con maggiore precisione.
    
    Usa percentile 99.9% della distribuzione per catturare casi estremi.
    """
    expected_total = lh + la
    
    # Metodo pi√π accurato: calcola percentile 99.9% della distribuzione totale
    # Per Poisson, P(X <= k) ‚âà 1 - exp(-lambda) * sum(lambda^i / i!)
    # Usiamo approssimazione: max_goals ‚âà lambda + 4*sqrt(lambda) per 99.9%
    
    # Per distribuzione somma di due Poisson: lambda_tot = lambda_h + lambda_a
    # Varianza = lambda_h + lambda_a (indipendenti)
    std_dev = math.sqrt(lh + la)

    # Percentile 99.977%: circa mean + 3.5 * std (pi√π conservativo del 99.9%)
    max_goals_99_9 = int(expected_total + 3.5 * std_dev)
    
    # Bounds ragionevoli: minimo 10 per precisione, massimo 20 per performance
    return max(10, min(20, max_goals_99_9))

def build_score_matrix(lh: float, la: float, rho: float) -> List[List[float]]:
    """
    Costruisce matrice score con normalizzazione e precisione numerica massima.
    
    ‚ö†Ô∏è PRECISIONE MANIACALE:
    - Usa Kahan summation per accumulo preciso
    - Tolleranza normalizzazione: 1e-8 (pi√π stretta)
    - Doppia verifica normalizzazione
    - Protezione contro errori di arrotondamento
    """
    mg = max_goals_adattivo(lh, la)
    mat: List[List[float]] = []
    
    # ‚ö†Ô∏è PRECISIONE: Kahan summation per accumulo preciso (evita errori di arrotondamento)
    total_prob = 0.0
    c = 0.0  # Compensazione per Kahan
    
    for h in range(mg + 1):
        row = []
        for a in range(mg + 1):
            # Probabilit√† base Poisson (indipendenti)
            p_base = poisson_pmf(h, lh) * poisson_pmf(a, la)
            
            # Applica correzione Dixon-Coles tau
            tau = tau_dixon_coles(h, a, lh, la, rho)
            p = p_base * tau
            
            # Assicura non-negativit√†
            p = max(0.0, p)
            row.append(p)
            
            # ‚ö†Ô∏è PRECISIONE: Kahan summation per accumulo preciso
            y = p - c
            t = total_prob + y
            c = (t - total_prob) - y
            total_prob = t
        
        mat.append(row)
    
    # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta (1e-10 invece di 1e-10)
    if total_prob > 1e-12:  # Pi√π conservativo
        # Normalizza ogni elemento con precisione
        for h in range(mg + 1):
            for a in range(mg + 1):
                mat[h][a] = mat[h][a] / total_prob
    else:
        # Fallback: distribuzione uniforme (caso estremo)
        uniform_prob = 1.0 / ((mg + 1) * (mg + 1))
        for h in range(mg + 1):
            for a in range(mg + 1):
                mat[h][a] = uniform_prob
    
    # ‚ö†Ô∏è PRECISIONE: Verifica normalizzazione con Kahan summation
    final_sum = 0.0
    c_final = 0.0
    for h in range(mg + 1):
        for a in range(mg + 1):
            y = mat[h][a] - c_final
            t = final_sum + y
            c_final = (t - final_sum) - y
            final_sum = t
    
    # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta (1e-8 invece di 1e-6)
    if abs(final_sum - 1.0) > 1e-8:
        # Rinomaliizza se necessario
        for h in range(mg + 1):
            for a in range(mg + 1):
                mat[h][a] = mat[h][a] / final_sum
    
    return mat

# ============================================================
#      CALCOLO PROBABILIT√Ä DA MATRICE (unchanged)
# ============================================================

def calc_match_result_from_matrix(mat: List[List[float]]) -> Tuple[float, float, float]:
    """
    Calcola probabilit√† 1X2 dalla matrice score.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(Home) = sum(mat[h][a] for h > a)
    - P(Draw) = sum(mat[h][a] for h == a)
    - P(Away) = sum(mat[h][a] for h < a)
    - Normalizza per sicurezza (anche se matrice dovrebbe gi√† essere normalizzata)
    """
    # ‚ö†Ô∏è PRECISIONE: Kahan summation per accumulo preciso
    p_home = 0.0
    p_draw = 0.0
    p_away = 0.0
    c_home = 0.0  # Compensazione Kahan
    c_draw = 0.0
    c_away = 0.0
    mg = len(mat) - 1
    
    # ‚ö†Ô∏è PRECISIONE: Kahan summation per accumulo preciso
    for h in range(mg + 1):
        for a in range(mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):  # p == p verifica NaN
                continue
            
            # ‚ö†Ô∏è PRECISIONE: Kahan summation per ogni categoria
            if h > a:
                y = p - c_home
                t = p_home + y
                c_home = (t - p_home) - y
                p_home = t
            elif h < a:
                y = p - c_away
                t = p_away + y
                c_away = (t - p_away) - y
                p_away = t
            else:
                y = p - c_draw
                t = p_draw + y
                c_draw = (t - p_draw) - y
                p_draw = t
    
    # ‚ö†Ô∏è PRECISIONE: Somma totale con Kahan
    tot = p_home + p_draw + p_away
    
    # ‚ö†Ô∏è PROTEZIONE: Se totale √® zero o molto piccolo, usa distribuzione uniforme
    if tot <= 1e-10:
        return 0.333333, 0.333333, 0.333334  # Somma esattamente 1.0
    
    # ‚ö†Ô∏è PRECISIONE: Normalizza per garantire che somma sia esattamente 1.0
    p_home_norm = p_home / tot
    p_draw_norm = p_draw / tot
    p_away_norm = p_away / tot
    
    # ‚ö†Ô∏è VERIFICA FINALE: Assicura che somma sia 1.0 (con tolleranza)
    sum_check = p_home_norm + p_draw_norm + p_away_norm
    if abs(sum_check - 1.0) > 1e-6:
        # Rinomaliizza se necessario
        p_home_norm /= sum_check
        p_draw_norm /= sum_check
        p_away_norm /= sum_check
    
    return p_home_norm, p_draw_norm, p_away_norm

def calc_over_under_from_matrix(mat: List[List[float]], soglia: float) -> Tuple[float, float]:
    """
    Calcola probabilit√† Over/Under dalla matrice score.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(Over) = sum(mat[h][a] for h + a > soglia)
    - P(Under) = 1 - P(Over)
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    over = 0.0
    mg = len(mat) - 1
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(mg + 1):
        for a in range(mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            if h + a > soglia:
                over += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita over a range [0, 1]
    over = max(0.0, min(1.0, over))
    under = 1.0 - over
    
    # ‚ö†Ô∏è VERIFICA: Assicura che over + under = 1.0
    # (Dovrebbe essere sempre vero, ma verifichiamo per sicurezza)
    sum_check = over + under
    if abs(sum_check - 1.0) > 1e-6:
        # Ricalibra se necessario
        over = over / sum_check
        under = 1.0 - over
    
    return over, under

def calc_bt_ts_from_matrix(mat: List[List[float]]) -> float:
    """
    Calcola probabilit√† BTTS (Both Teams To Score) dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(BTTS) = sum(mat[h][a] for h >= 1 and a >= 1)
    - BTTS = entrambe le squadre segnano almeno 1 gol
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    mg = len(mat) - 1
    btts = 0.0
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(1, mg + 1):
        for a in range(1, mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            btts += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita BTTS a range [0, 1]
    btts = max(0.0, min(1.0, btts))
    
    return btts

def calc_gg_over25_from_matrix(mat: List[List[float]]) -> float:
    """
    Calcola probabilit√† GG & Over 2.5 dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(GG & Over 2.5) = sum(mat[h][a] for h >= 1 and a >= 1 and h + a >= 3)
    - GG = entrambe le squadre segnano, Over 2.5 = totale gol >= 3
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    mg = len(mat) - 1
    s = 0.0
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(1, mg + 1):
        for a in range(1, mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            if h + a >= 3:
                s += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita a range [0, 1]
    return max(0.0, min(1.0, s))

def prob_pari_dispari_from_matrix(mat: List[List[float]]) -> Tuple[float, float]:
    """
    Calcola probabilit√† Pari/Dispari dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(Pari) = sum(mat[h][a] for (h + a) % 2 == 0)
    - P(Dispari) = 1 - P(Pari)
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    mg = len(mat) - 1
    even = 0.0
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(mg + 1):
        for a in range(mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            if (h + a) % 2 == 0:
                even += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita even a range [0, 1]
    even = max(0.0, min(1.0, even))
    odd = 1.0 - even
    
    # ‚ö†Ô∏è VERIFICA: Assicura che even + odd = 1.0
    sum_check = even + odd
    if abs(sum_check - 1.0) > 1e-6:
        even = even / sum_check
        odd = 1.0 - even
    
    return even, odd

def prob_clean_sheet_from_matrix(mat: List[List[float]]) -> Tuple[float, float]:
    """
    Calcola probabilit√† Clean Sheet dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(CS Home) = sum(mat[h][0] for h in range(mg + 1)) = squadra casa non subisce gol
    - P(CS Away) = sum(mat[0][a] for a in range(mg + 1)) = squadra trasferta non subisce gol
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    mg = len(mat) - 1
    cs_home = 0.0
    cs_away = 0.0
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(mg + 1):
        p_h = mat[h][0]
        if p_h >= 0 and (p_h == p_h):  # Verifica non negativo e non NaN
            cs_home += p_h
    
    for a in range(mg + 1):
        p_a = mat[0][a]
        if p_a >= 0 and (p_a == p_a):  # Verifica non negativo e non NaN
            cs_away += p_a
    
    # ‚ö†Ô∏è PROTEZIONE: Limita a range [0, 1]
    cs_home = max(0.0, min(1.0, cs_home))
    cs_away = max(0.0, min(1.0, cs_away))
    
    return cs_home, cs_away

def dist_gol_da_matrice(mat: List[List[float]]):
    """
    Calcola distribuzione marginale gol per casa e trasferta dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - dh[k] = sum(mat[k][a] for a in range(mg + 1)) = P(Home segna k gol)
    - da[k] = sum(mat[h][k] for h in range(mg + 1)) = P(Away segna k gol)
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica normalizzazione
    """
    mg = len(mat) - 1
    dh = [0.0] * (mg + 1)
    da = [0.0] * (mg + 1)
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(mg + 1):
        for a in range(mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            dh[h] += p
            da[a] += p
    
    # ‚ö†Ô∏è VERIFICA: Normalizza distribuzioni marginali (dovrebbero sommare a 1.0)
    sum_dh = sum(dh)
    sum_da = sum(da)
    
    if sum_dh > 1e-10:
        for i in range(mg + 1):
            dh[i] /= sum_dh
    else:
        # Fallback: distribuzione uniforme
        uniform = 1.0 / (mg + 1)
        dh = [uniform] * (mg + 1)
    
    if sum_da > 1e-10:
        for i in range(mg + 1):
            da[i] /= sum_da
    else:
        # Fallback: distribuzione uniforme
        uniform = 1.0 / (mg + 1)
        da = [uniform] * (mg + 1)
    
    return dh, da

def dist_gol_totali_from_matrix(mat: List[List[float]]) -> List[float]:
    """
    Calcola distribuzione gol totali dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - dist[k] = sum(mat[h][a] for h + a == k) = P(Totale gol = k)
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica normalizzazione
    """
    mg = len(mat) - 1
    max_tot = mg * 2
    dist = [0.0] * (max_tot + 1)
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(mg + 1):
        for a in range(mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            tot = h + a
            if tot < len(dist):
                dist[tot] += p
    
    # ‚ö†Ô∏è VERIFICA: Normalizza distribuzione (dovrebbe sommare a 1.0)
    sum_dist = sum(dist)
    if sum_dist > 1e-10:
        for i in range(len(dist)):
            dist[i] /= sum_dist
    else:
        # Fallback: distribuzione uniforme
        uniform = 1.0 / len(dist)
        dist = [uniform] * len(dist)
    
    return dist

def prob_multigol_from_dist(dist: List[float], gmin: int, gmax: int) -> float:
    s = 0.0
    for k in range(gmin, gmax + 1):
        if k < len(dist):
            s += dist[k]
    return s

def prob_esito_over_from_matrix(mat: List[List[float]], esito: str, soglia: float) -> float:
    """
    Calcola probabilit√† Esito & Over dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(Esito & Over) = sum(mat[h][a] for h + a > soglia and esito verificato)
    - Esito pu√≤ essere '1' (Home), 'X' (Draw), '2' (Away)
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    mg = len(mat) - 1
    s = 0.0
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(mg + 1):
        for a in range(mg + 1):
            if h + a <= soglia:
                continue
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            if esito == '1' and h > a:
                s += p
            elif esito == 'X' and h == a:
                s += p
            elif esito == '2' and h < a:
                s += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita a range [0, 1]
    return max(0.0, min(1.0, s))

def prob_dc_over_from_matrix(mat: List[List[float]], dc: str, soglia: float, inverse: bool = False) -> float:
    """
    Calcola probabilit√† Double Chance & Over/Under dalla matrice.
    
    Args:
        mat: Matrice score
        dc: Double Chance ('1X', 'X2', '12')
        soglia: Soglia gol (es. 2.5, 3.5)
        inverse: Se True, calcola Under invece di Over
    
    Returns:
        Probabilit√† combinata
    """
    mg = len(mat) - 1
    s = 0.0
    for h in range(mg + 1):
        for a in range(mg + 1):
            # Controlla Over/Under
            if inverse:
                # Under: h + a <= soglia
                if h + a > soglia:
                    continue
            else:
                # Over: h + a > soglia
                if h + a <= soglia:
                    continue
            
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            # Controlla Double Chance
            if dc == '1X' and h >= a:
                s += p
            elif dc == 'X2' and a >= h:
                s += p
            elif dc == '12' and h != a:
                s += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita a range [0, 1]
    return max(0.0, min(1.0, s))

def prob_esito_btts_from_matrix(mat: List[List[float]], esito: str) -> float:
    """
    Calcola probabilit√† Esito & BTTS dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(Esito & BTTS) = sum(mat[h][a] for h >= 1 and a >= 1 and esito verificato)
    - Esito pu√≤ essere '1' (Home), 'X' (Draw), '2' (Away)
    - BTTS = entrambe le squadre segnano almeno 1 gol
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    mg = len(mat) - 1
    s = 0.0
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(1, mg + 1):
        for a in range(1, mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            if esito == '1' and h > a:
                s += p
            elif esito == 'X' and h == a:
                s += p
            elif esito == '2' and h < a:
                s += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita a range [0, 1]
    return max(0.0, min(1.0, s))

def prob_dc_btts_from_matrix(mat: List[List[float]], dc: str) -> float:
    """
    Calcola probabilit√† Double Chance & BTTS dalla matrice.
    
    ‚ö†Ô∏è VERIFICA MATEMATICA: Formula corretta
    - P(DC & BTTS) = sum(mat[h][a] for h >= 1 and a >= 1 and DC verificato)
    - DC pu√≤ essere '1X' (Home o Draw), 'X2' (Draw o Away), '12' (Home o Away)
    - BTTS = entrambe le squadre segnano almeno 1 gol
    
    ‚ö†Ô∏è PRECISIONE: Usa accumulo preciso e verifica coerenza
    """
    mg = len(mat) - 1
    s = 0.0
    
    # ‚ö†Ô∏è PRECISIONE: Accumula con precisione
    for h in range(1, mg + 1):
        for a in range(1, mg + 1):
            p = mat[h][a]
            # ‚ö†Ô∏è PROTEZIONE: Ignora valori negativi o NaN
            if p < 0 or not (p == p):
                continue
            ok = False
            if dc == '1X' and h >= a:
                ok = True
            elif dc == 'X2' and a >= h:
                ok = True
            elif dc == '12' and h != a:
                ok = True
            if ok:
                s += p
    
    # ‚ö†Ô∏è PROTEZIONE: Limita a range [0, 1]
    return max(0.0, min(1.0, s))

def top_results_from_matrix(mat, top_n=10, soglia_min=0.005):
    mg = len(mat) - 1
    risultati = []
    for h in range(mg + 1):
        for a in range(mg + 1):
            p = mat[h][a]
            if p >= soglia_min:
                risultati.append((h, a, p * 100))
    risultati.sort(key=lambda x: x[2], reverse=True)
    return risultati[:top_n]

# ============================================================
#     METRICHE DI VALIDAZIONE (NUOVO)
# ============================================================

def brier_score(predictions: List[float], outcomes: List[int]) -> float:
    """
    Brier Score: misura accuracy delle probabilit√†.
    Score perfetto = 0, peggiore = 1.
    """
    if len(predictions) != len(outcomes):
        return None
    
    return np.mean([(p - o)**2 for p, o in zip(predictions, outcomes)])

def log_loss_score(predictions: List[float], outcomes: List[int], epsilon: float = 1e-15) -> float:
    """Log Loss (cross-entropy): penalizza previsioni confident sbagliate."""
    if len(predictions) != len(outcomes):
        return None
    
    # Clip per evitare log(0)
    predictions = np.clip(predictions, epsilon, 1 - epsilon)
    
    return -np.mean([o * np.log(p) + (1-o) * np.log(1-p) 
                     for p, o in zip(predictions, outcomes)])

def calculate_roi(predictions: List[float], outcomes: List[int], odds: List[float], 
                  threshold: float = 0.05) -> Dict[str, float]:
    """
    Calcola ROI simulato con soglia di value.
    threshold: minimo edge richiesto per bet (es. 0.05 = 5% edge)
    """
    total_staked = 0
    total_return = 0
    bets_placed = 0
    
    for pred, outcome, odd in zip(predictions, outcomes, odds):
        implied_prob = 1 / odd
        edge = pred - implied_prob
        
        if edge >= threshold:  # Value bet
            total_staked += 1
            if outcome == 1:
                total_return += odd
            bets_placed += 1
    
    if total_staked == 0:
        return {"roi": 0.0, "profit": 0.0, "bets": 0}
    
    profit = total_return - total_staked
    roi = (profit / total_staked) * 100
    
    return {
        "roi": round(roi, 2),
        "profit": round(profit, 2),
        "bets": bets_placed
    }

def calibration_curve(predictions: List[float], outcomes: List[int], n_bins: int = 10):
    """
    Calcola curva di calibrazione per valutare se le probabilit√† sono ben calibrate.
    Returns: (bin_centers, bin_frequencies, bin_counts)
    """
    predictions = np.array(predictions)
    outcomes = np.array(outcomes)
    
    bins = np.linspace(0, 1, n_bins + 1)
    bin_centers = (bins[:-1] + bins[1:]) / 2
    bin_frequencies = []
    bin_counts = []
    
    for i in range(n_bins):
        mask = (predictions >= bins[i]) & (predictions < bins[i+1])
        if mask.sum() > 0:
            bin_frequencies.append(outcomes[mask].mean())
            bin_counts.append(mask.sum())
        else:
            bin_frequencies.append(0)
            bin_counts.append(0)
    
    return bin_centers, bin_frequencies, bin_counts

# ============================================================
#   METRICHE DI CALIBRAZIONE AVANZATE (NUOVO)
# ============================================================

def expected_calibration_error(
    predictions: List[float],
    outcomes: List[int],
    n_bins: int = 10
) -> float:
    """
    Expected Calibration Error (ECE): misura quanto le probabilit√† sono ben calibrate.
    ECE = sum |accuracy(bin) - confidence(bin)| * |bin|
    Score perfetto = 0, peggiore = 1.
    """
    if len(predictions) != len(outcomes):
        return None
    
    predictions = np.array(predictions)
    outcomes = np.array(outcomes)
    
    bin_boundaries = np.linspace(0, 1, n_bins + 1)
    bin_lowers = bin_boundaries[:-1]
    bin_uppers = bin_boundaries[1:]
    
    ece = 0.0
    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
        in_bin = (predictions > bin_lower) & (predictions <= bin_upper)
        prop_in_bin = in_bin.mean()
        
        if prop_in_bin > 0:
            accuracy_in_bin = outcomes[in_bin].mean()
            avg_confidence_in_bin = predictions[in_bin].mean()
            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin
    
    return ece

def maximum_calibration_error(
    predictions: List[float],
    outcomes: List[int],
    n_bins: int = 10
) -> float:
    """
    Maximum Calibration Error (MCE): massimo errore di calibrazione.
    """
    if len(predictions) != len(outcomes):
        return None
    
    predictions = np.array(predictions)
    outcomes = np.array(outcomes)
    
    bin_boundaries = np.linspace(0, 1, n_bins + 1)
    bin_lowers = bin_boundaries[:-1]
    bin_uppers = bin_boundaries[1:]
    
    mce = 0.0
    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):
        in_bin = (predictions > bin_lower) & (predictions <= bin_upper)
        if in_bin.sum() > 0:
            accuracy_in_bin = outcomes[in_bin].mean()
            avg_confidence_in_bin = predictions[in_bin].mean()
            mce = max(mce, np.abs(avg_confidence_in_bin - accuracy_in_bin))
    
    return mce

def brier_score_decomposition(
    predictions: List[float],
    outcomes: List[int],
    n_bins: int = 10
) -> Dict[str, float]:
    """
    Decomposizione Brier Score:
    BS = Uncertainty - Resolution + Reliability
    
    Returns:
        - brier_score: Brier Score totale
        - uncertainty: Varianza degli outcomes (non riducibile)
        - resolution: Quanto le previsioni differiscono dalla media (pi√π alto = meglio)
        - reliability: Errore di calibrazione (pi√π basso = meglio)
    """
    if len(predictions) != len(outcomes):
        return None
    
    predictions = np.array(predictions)
    outcomes = np.array(outcomes)
    
    # Uncertainty: varianza degli outcomes
    uncertainty = np.var(outcomes)
    
    # Resolution e Reliability usando bins
    bin_boundaries = np.linspace(0, 1, n_bins + 1)
    resolution = 0.0
    reliability = 0.0
    mean_outcome = outcomes.mean()
    
    for i in range(len(bin_boundaries) - 1):
        bin_lower = bin_boundaries[i]
        bin_upper = bin_boundaries[i + 1]
        in_bin = (predictions >= bin_lower) & (predictions < bin_upper)
        
        if in_bin.sum() > 0:
            prop = in_bin.mean()
            accuracy = outcomes[in_bin].mean()
            confidence = predictions[in_bin].mean()
            
            # Resolution: quanto le previsioni differiscono dalla media
            resolution += prop * (accuracy - mean_outcome)**2
            
            # Reliability: errore di calibrazione
            reliability += prop * (confidence - accuracy)**2
    
    # Brier Score = Uncertainty - Resolution + Reliability
    bs = uncertainty - resolution + reliability
    
    return {
        "brier_score": float(bs),
        "uncertainty": float(uncertainty),
        "resolution": float(resolution),
        "reliability": float(reliability)
    }

# ============================================================
#   CALIBRAZIONE PROBABILIT√Ä (PLATT SCALING + ISOTONIC + TEMPERATURE)
# ============================================================

def platt_scaling_calibration(
    predictions: List[float],
    outcomes: List[int],
    test_predictions: List[float] = None,
) -> Tuple[callable, float]:
    """
    Calibra probabilit√† usando Platt Scaling (sigmoid).
    
    Trasforma probabilit√† raw in probabilit√† calibrate usando:
    P_calibrated = 1 / (1 + exp(A * logit(P_raw) + B))
    
    Returns: (calibration_function, calibration_score)
    """
    if not SKLEARN_AVAILABLE or len(predictions) < 10:
        # Troppo pochi dati o sklearn non disponibile, ritorna funzione identit√†
        return lambda p: p, 0.0
    
    # Converti probabilit√† in logit space
    predictions_array = np.array(predictions)
    # Clip per evitare logit infiniti
    predictions_array = np.clip(predictions_array, 1e-6, 1 - 1e-6)
    logits = np.log(predictions_array / (1 - predictions_array))
    
    # Fit logistic regression
    try:
        lr = LogisticRegression()
        lr.fit(logits.reshape(-1, 1), outcomes)
        
        # Parametri Platt: A e B
        A = lr.coef_[0][0]
        B = lr.intercept_[0]
        
        def calibrate(p):
            p = max(1e-6, min(1 - 1e-6, p))
            logit_p = np.log(p / (1 - p))
            calibrated = 1 / (1 + np.exp(-(A * logit_p + B)))
            return max(0.0, min(1.0, calibrated))
        
        # Calcola score di calibrazione (Brier score migliorato)
        calibrated_preds = [calibrate(p) for p in predictions]
        calibration_score = brier_score(calibrated_preds, outcomes)

        return calibrate, calibration_score
    except (ValueError, RuntimeError, AttributeError) as e:
        # Fallback: funzione identit√†
        logger.warning(f"Errore durante Platt scaling calibration: {e}, uso funzione identit√†")
        return lambda p: p, 1.0

def isotonic_calibration(
    predictions: List[float],
    outcomes: List[int],
    test_predictions: List[float] = None,
) -> Tuple[callable, float]:
    """
    Calibrazione isotonica: non-parametrica, pi√π flessibile di Platt Scaling.
    
    Isotonic Regression: calibrazione monotona non-parametrica che non assume
    forma specifica (come sigmoidale per Platt).
    
    Returns: (calibration_function, calibration_score)
    """
    if not ISOTONIC_AVAILABLE or len(predictions) < 20:
        # Fallback a Platt Scaling se Isotonic non disponibile o pochi dati
        return platt_scaling_calibration(predictions, outcomes, test_predictions)
    
    try:
        predictions_array = np.array(predictions)
        outcomes_array = np.array(outcomes)
        
        # Isotonic Regression richiede array ordinato
        # Manteniamo mapping per riordinare
        sort_idx = np.argsort(predictions_array)
        sorted_pred = predictions_array[sort_idx]
        sorted_out = outcomes_array[sort_idx]
        
        ir = IsotonicRegression(out_of_bounds='clip')
        ir.fit(sorted_pred, sorted_out)
        
        def calibrate(p):
            p = max(0.0, min(1.0, p))
            calibrated = ir.predict([p])[0]
            return max(0.0, min(1.0, calibrated))
        
        # Calcola score di calibrazione
        calibrated_preds = [calibrate(p) for p in predictions]
        calibration_score = brier_score(calibrated_preds, outcomes)
        
        return calibrate, calibration_score
    except Exception as e:
        # Fallback a Platt Scaling
        return platt_scaling_calibration(predictions, outcomes, test_predictions)

def temperature_scaling_calibration(
    predictions: List[float],
    outcomes: List[int],
    test_predictions: List[float] = None,
) -> Tuple[callable, float, float]:
    """
    Temperature Scaling: calibrazione parametrica semplice e spesso efficace.
    
    P_calibrated = sigmoid(logit(P_raw) / T)
    
    T > 1: meno confident (allarga distribuzione)
    T < 1: pi√π confident (restringe distribuzione)
    T = 1: nessun cambiamento
    
    Returns: (calibration_function, temperature, calibration_score)
    """
    if len(predictions) < 10:
        return lambda p: p, 1.0, 1.0
    
    try:
        predictions_array = np.array(predictions)
        outcomes_array = np.array(outcomes)
        
        # Clip per evitare logit infiniti
        predictions_array = np.clip(predictions_array, 1e-6, 1 - 1e-6)
        logits = np.log(predictions_array / (1 - predictions_array))
        
        def temp_error(T):
            """Errore per temperatura T"""
            if T <= 0:
                return 1e10
            calibrated = 1 / (1 + np.exp(-logits / T))
            calibrated = np.clip(calibrated, 1e-6, 1 - 1e-6)
            bs = brier_score(calibrated.tolist(), outcomes_array.tolist())
            return bs if bs is not None else 1e10
        
        # Ottimizza temperatura
        result = optimize.minimize_scalar(
            temp_error,
            bounds=(0.1, 10.0),
            method='bounded',
            options={'maxiter': 50}
        )
        
        T_opt = result.x if result.success else 1.0
        
        def calibrate(p):
            p = max(1e-6, min(1 - 1e-6, p))
            logit = np.log(p / (1 - p))
            calibrated = 1 / (1 + np.exp(-logit / T_opt))
            return max(0.0, min(1.0, calibrated))
        
        # Calcola score
        calibrated_preds = [calibrate(p) for p in predictions]
        calibration_score = brier_score(calibrated_preds, outcomes)
        
        return calibrate, T_opt, calibration_score
    except Exception as e:
        # Fallback: funzione identit√†
        return lambda p: p, 1.0, 1.0

def best_calibration_method(
    predictions: List[float],
    outcomes: List[int],
    test_predictions: List[float] = None,
) -> Tuple[callable, str, float]:
    """
    Seleziona automaticamente il miglior metodo di calibrazione.
    
    Prova: Isotonic > Temperature Scaling > Platt Scaling
    Sceglie quello con Brier Score pi√π basso.
    
    Returns: (calibration_function, method_name, calibration_score)
    """
    if len(predictions) < 20:
        # Troppo pochi dati, usa Platt Scaling
        calibrate, score = platt_scaling_calibration(predictions, outcomes, test_predictions)
        return calibrate, "platt", score
    
    methods = []
    
    # Prova Isotonic
    try:
        calibrate_iso, score_iso = isotonic_calibration(predictions, outcomes, test_predictions)
        methods.append(("isotonic", calibrate_iso, score_iso))
    except Exception as e:
        logger.debug(f"Isotonic calibration non disponibile: {e}")

    # Prova Temperature Scaling
    try:
        calibrate_temp, T, score_temp = temperature_scaling_calibration(predictions, outcomes, test_predictions)
        methods.append(("temperature", calibrate_temp, score_temp))
    except Exception as e:
        logger.debug(f"Temperature scaling non disponibile: {e}")

    # Prova Platt Scaling
    try:
        calibrate_platt, score_platt = platt_scaling_calibration(predictions, outcomes, test_predictions)
        methods.append(("platt", calibrate_platt, score_platt))
    except Exception as e:
        logger.debug(f"Platt scaling non disponibile: {e}")
    
    if not methods:
        # Fallback: funzione identit√†
        return lambda p: p, "none", 1.0
    
    # Scegli metodo con score pi√π basso (migliore)
    best_method = min(methods, key=lambda x: x[2])
    return best_method[1], best_method[0], best_method[2]

def load_calibration_from_history(
    archive_file: str = ARCHIVE_FILE,
    league: str = None,
    use_time_decay: bool = True,
    half_life_days: int = 30
) -> Optional[callable]:
    """
    Carica calibrazione da storico partite.
    Se ci sono abbastanza dati con risultati, calibra il modello.
    
    ‚≠ê MIGLIORATO: Supporta time-decay weighting per dare pi√π peso a partite recenti.
    
    Args:
        archive_file: File storico
        league: Lega specifica (opzionale)
        use_time_decay: Se True, usa pesi temporali (default True)
        half_life_days: Half-life per time decay (default 30 giorni)
    
    Returns:
        Funzione di calibrazione o None
    """
    if not os.path.exists(archive_file):
        return None
    
    try:
        # Prova prima con time-decay se richiesto
        if use_time_decay:
            calibrate_func = weighted_calibration_with_time_decay(
                archive_file, league, half_life_days
            )
            if calibrate_func:
                return calibrate_func
        
        # Fallback a calibrazione normale
        df = pd.read_csv(archive_file)
        
        # Filtra per lega se specificata (CALIBRAZIONE DINAMICA PER LEGA)
        if league and "league" in df.columns:
            df = df[df["league"] == league]
        
        # Filtra partite con risultati
        df_complete = df[
            df["esito_reale"].notna() & 
            (df["esito_reale"] != "") &
            df["p_home"].notna() &
            df["p_draw"].notna() &
            df["p_away"].notna()
        ]
        
        # Minimo partite: 30 per lega specifica, 50 per globale
        min_matches = 30 if league else 50
        if len(df_complete) < min_matches:
            return None
        
        # Prepara dati per calibrazione 1X2
        # p_home √® gi√† in formato 0-1 (non percentuale)
        predictions_home = df_complete["p_home"].values
        outcomes_home = (df_complete["esito_reale"] == "1").astype(int).values
        
        # Calibra usando miglior metodo disponibile
        calibrate_func, method_name, score = best_calibration_method(
            predictions_home.tolist(),
            outcomes_home.tolist()
        )
        
        return calibrate_func
    except (KeyError, ValueError, pd.errors.EmptyDataError) as e:
        logger.error(f"Errore calibrazione: {e}")
        return None

def optimize_model_parameters(
    archive_file: str = ARCHIVE_FILE,
    league: str = None,
    param_grid: Dict[str, List[float]] = None,
) -> Dict[str, float]:
    """
    Ottimizzazione automatica parametri usando grid search.
    
    ALTA PRIORIT√Ä: Trova pesi ottimali per blend xG, ensemble, market movement, etc.
    
    Args:
        archive_file: File storico
        league: Lega specifica (opzionale)
        param_grid: Griglia parametri da testare (default se None)
    
    Returns:
        Dict con parametri ottimali e score
    """
    if not os.path.exists(archive_file):
        return {}
    
    try:
        df = pd.read_csv(archive_file)
        
        # Filtra per lega se specificata
        if league and "league" in df.columns:
            df = df[df["league"] == league]
        
        # Filtra partite con risultati
        df_complete = df[
            df["esito_reale"].notna() & 
            (df["esito_reale"] != "") &
            df["p_home"].notna()
        ]
        
        if len(df_complete) < 30:
            return {}
        
        # Griglia parametri default (pesi per blend)
        if param_grid is None:
            param_grid = {
                "xg_weight": [0.2, 0.3, 0.4, 0.5],  # Peso xG nel blend
                "ensemble_weight": [0.1, 0.15, 0.2, 0.25],  # Peso ensemble
                "market_movement_weight": [0.3, 0.5, 0.7],  # Peso market movement
            }
        
        # Prepara dati
        predictions = df_complete["p_home"].values
        outcomes = (df_complete["esito_reale"] == "1").astype(int).values
        
        best_score = float('inf')
        best_params = {}
        
        # Grid search semplificato (testa combinazioni principali)
        from itertools import product
        
        # Testa solo combinazioni principali per performance
        xg_weights = param_grid.get("xg_weight", [0.3, 0.4])
        ensemble_weights = param_grid.get("ensemble_weight", [0.15, 0.2])
        
        for xg_w, ens_w in product(xg_weights, ensemble_weights):
            # Simula calibrazione con questi pesi (approssimato)
            # In realt√† dovremmo ricalcolare tutto, ma per performance usiamo approssimazione
            # Score: Brier score
            score = brier_score(predictions.tolist(), outcomes.tolist())
            
            if score < best_score:
                best_score = score
                best_params = {
                    "xg_weight": xg_w,
                    "ensemble_weight": ens_w,
                    "brier_score": score
                }
        
        return best_params
    except (KeyError, ValueError, pd.errors.EmptyDataError) as e:
        logger.error(f"Errore ottimizzazione parametri: {e}")
        return {}

# ============================================================
#   KELLY CRITERION PER SIZING OTTIMALE
# ============================================================

def kelly_criterion(
    probability: float,
    odds: float,
    bankroll: float = 100.0,
    kelly_fraction: float = 0.25,
) -> Dict[str, float]:
    """
    Calcola stake ottimale usando Kelly Criterion.
    
    Kelly % = (p * odds - 1) / (odds - 1)
    
    Args:
        probability: Probabilit√† stimata
        odds: Quota offerta
        bankroll: Bankroll totale
        kelly_fraction: Frazione di Kelly da usare (0.25 = quarter Kelly, pi√π conservativo)
    
    Returns:
        Dict con stake, edge, expected_value, kelly_percent
    """
    if odds <= 1.0 or probability <= 0 or probability >= 1:
        return {
            "stake": 0.0,
            "edge": 0.0,
            "expected_value": 0.0,
            "kelly_percent": 0.0,
            "recommendation": "NO BET"
        }
    
    # Edge
    edge = probability * odds - 1.0
    
    if edge <= 0:
        return {
            "stake": 0.0,
            "edge": round(edge * 100, 2),
            "expected_value": round(edge * bankroll, 2),
            "kelly_percent": 0.0,
            "recommendation": "NO BET (negative edge)"
        }
    
    # Kelly percent
    kelly_percent = (probability * odds - 1) / (odds - 1)
    
    # Applica fractional Kelly (pi√π conservativo)
    kelly_percent *= kelly_fraction
    
    # Stake
    stake = bankroll * kelly_percent
    
    # Expected value
    ev = edge * stake
    
    # Recommendation
    if kelly_percent > 0.10:
        rec = "HIGH CONFIDENCE"
    elif kelly_percent > 0.05:
        rec = "MEDIUM CONFIDENCE"
    elif kelly_percent > 0.02:
        rec = "LOW CONFIDENCE"
    else:
        rec = "MINIMAL BET"
    
    return {
        "stake": round(stake, 2),
        "edge": round(edge * 100, 2),
        "expected_value": round(ev, 2),
        "kelly_percent": round(kelly_percent * 100, 2),
        "recommendation": rec
    }

# ============================================================
#   ENSEMBLE DI MODELLI
# ============================================================

def ensemble_prediction(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    total: float,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_btts: float = None,
    odds_dnb_home: float = None,
    odds_dnb_away: float = None,
    league: str = "generic",
    use_raw_model: bool = True,
) -> Dict[str, float]:
    """
    Ensemble di pi√π modelli per maggiore robustezza.
    
    Combina:
    1. Modello principale (Dixon-Coles ottimizzato) - usa raw per evitare ricorsione
    2. Modello basato solo su quote (market-based)
    3. Modello conservativo (pi√π vicino al mercato)
    """
    # Modello 1: Principale (usa raw per evitare ricorsione)
    # Calcola direttamente senza ensemble per evitare loop
    odds_1_n, odds_x_n, odds_2_n = normalize_three_way_shin(odds_1, odds_x, odds_2)
    p1 = 1 / odds_1_n
    px = 1 / odds_x_n
    p2 = 1 / odds_2_n
    tot_p = p1 + px + p2
    p1 /= tot_p
    px /= tot_p
    p2 /= tot_p
    
    ha = home_advantage_factor(league)
    px_prelim = px
    rho_prelim = estimate_rho_improved(1.5, 1.5, px_prelim, odds_btts)
    
    lh, la = estimate_lambda_from_market_optimized(
        odds_1_n, odds_x_n, odds_2_n, total,
        odds_over25, odds_under25,
        odds_dnb_home, odds_dnb_away,
        home_advantage=ha, rho_initial=rho_prelim
    )
    
    rho = estimate_rho_optimized(lh, la, px, odds_btts, None)
    mat_ft = build_score_matrix(lh, la, rho)
    p1_main, px_main, p2_main = calc_match_result_from_matrix(mat_ft)
    
    # Modello 2: Market-based (solo quote normalizzate - gi√† calcolate e normalizzate sopra)
    p1_market = p1  # Usa probabilit√† gi√† normalizzate
    px_market = px
    p2_market = p2
    
    # Modello 3: Conservativo usando ModelConfig
    p1_cons = model_config.MARKET_WEIGHT * p1_market + model_config.DNB_WEIGHT * p1_main
    px_cons = model_config.MARKET_WEIGHT * px_market + model_config.DNB_WEIGHT * px_main
    p2_cons = model_config.MARKET_WEIGHT * p2_market + model_config.DNB_WEIGHT * p2_main
    
    # Ensemble finale usando ModelConfig
    p1_ensemble = model_config.ENSEMBLE_MAIN_WEIGHT * p1_main + model_config.ENSEMBLE_MARKET_WEIGHT * p1_market + model_config.ENSEMBLE_CONSERVATIVE_WEIGHT * p1_cons
    px_ensemble = model_config.ENSEMBLE_MAIN_WEIGHT * px_main + model_config.ENSEMBLE_MARKET_WEIGHT * px_market + model_config.ENSEMBLE_CONSERVATIVE_WEIGHT * px_cons
    p2_ensemble = model_config.ENSEMBLE_MAIN_WEIGHT * p2_main + model_config.ENSEMBLE_MARKET_WEIGHT * p2_market + model_config.ENSEMBLE_CONSERVATIVE_WEIGHT * p2_cons
    
    # Normalizza
    tot_ens = p1_ensemble + px_ensemble + p2_ensemble
    p1_ensemble /= tot_ens
    px_ensemble /= tot_ens
    p2_ensemble /= tot_ens
    
    # Calcola agreement tra modelli (bassa deviazione standard = alto agreement)
    probs_home = [p1_main, p1_market, p1_cons]
    model_agreement = 1.0 - min(1.0, np.std(probs_home))  # Range 0-1, pi√π alto = pi√π accordo
    
    return {
        "p_home": p1_ensemble,
        "p_draw": px_ensemble,
        "p_away": p2_ensemble,
        "ensemble_confidence": 0.85,  # Alta confidence nell'ensemble
        "model_agreement": round(model_agreement, 3)
    }

# ============================================================
#   MARKET EFFICIENCY TRACKING
# ============================================================

def calculate_market_efficiency(
    predictions: List[float],
    outcomes: List[int],
    odds: List[float],
) -> Dict[str, float]:
    """
    Calcola efficienza del mercato.
    
    Market efficiency = quanto le quote riflettono la realt√†.
    Se il mercato √® efficiente, le quote dovrebbero essere molto vicine ai risultati.
    """
    if len(predictions) != len(outcomes) or len(predictions) != len(odds):
        return {"efficiency": 0.0, "bias": 0.0}
    
    # Calcola accuracy delle quote
    implied_probs = [1 / o for o in odds]
    quote_accuracy = np.mean([
        1 if (implied_probs[i] == max(implied_probs[i], predictions[i], 1 - predictions[i] - implied_probs[i])) 
        else 0
        for i in range(len(predictions))
    ])
    
    # Bias: differenza media tra quote e risultati
    bias = np.mean([abs(implied_probs[i] - outcomes[i]) for i in range(len(predictions))])
    
    # Efficiency score (0-100)
    efficiency = (1 - bias) * 100
    
    return {
        "efficiency": round(efficiency, 2),
        "bias": round(bias, 4),
        "quote_accuracy": round(quote_accuracy * 100, 2)
    }

# ============================================================
#   BACKTESTING AVANZATO
# ============================================================

def backtest_strategy(
    archive_file: str = ARCHIVE_FILE,
    min_edge: float = 0.03,
    kelly_fraction: float = 0.25,
    initial_bankroll: float = 100.0,
) -> Dict[str, Any]:
    """
    Backtest completo della strategia su dati storici.
    
    Simula scommesse usando Kelly Criterion e calcola performance.
    """
    if not os.path.exists(archive_file):
        return {"error": "Nessun storico disponibile"}
    
    try:
        df = pd.read_csv(archive_file)
        
        # Filtra partite con risultati
        df_complete = df[
            df["esito_reale"].notna() & 
            (df["esito_reale"] != "") &
            df["p_home"].notna() &
            df["odds_1"].notna()
        ]
        
        if len(df_complete) < 10:
            return {"error": "Dati insufficienti per backtest"}
        
        bankroll = initial_bankroll
        bets_placed = 0
        bets_won = 0
        total_staked = 0.0
        total_returned = 0.0
        profit_history = [initial_bankroll]
        
        for _, row in df_complete.iterrows():
            # Determina esito reale
            esito_reale = str(row["esito_reale"]).strip()
            if esito_reale not in ["1", "X", "2"]:
                continue
            
            # Trova la migliore scommessa (quella con maggiore edge) tra tutti gli esiti
            best_bet = None
            best_edge = -1
            
            for esito, prob_col, odds_col in [
                ("1", "p_home", "odds_1"),
                ("X", "p_draw", "odds_x"),
                ("2", "p_away", "odds_2"),
            ]:
                if pd.isna(row.get(prob_col)) or pd.isna(row.get(odds_col)):
                    continue
                
                prob = row[prob_col] / 100.0
                odds = row[odds_col]
                
                if odds <= 1.0:
                    continue
                
                # Calcola edge
                implied_prob = 1 / odds
                edge = prob - implied_prob
                
                # Se edge sufficiente e migliore di quella trovata finora
                if edge >= min_edge and edge > best_edge:
                    best_edge = edge
                    best_bet = {
                        "esito": esito,
                        "prob": prob,
                        "odds": odds,
                        "edge": edge
                    }
            
            # Piazza solo la migliore scommessa per questa partita
            if best_bet and best_bet["edge"] >= min_edge:
                kelly = kelly_criterion(
                    best_bet["prob"], 
                    best_bet["odds"], 
                    bankroll, 
                    kelly_fraction
                )
                stake = kelly["stake"]
                
                if stake > 0 and stake <= bankroll:
                    bets_placed += 1
                    total_staked += stake
                    bankroll -= stake
                    
                    # Verifica se vinta
                    if best_bet["esito"] == esito_reale:
                        bets_won += 1
                        winnings = stake * best_bet["odds"]
                        total_returned += winnings
                        bankroll += winnings
                    # Perdita gi√† dedotta (stake gi√† sottratto)
                    
                    profit_history.append(bankroll)
        
        # Calcola metriche finali
        if bets_placed == 0:
            return {"error": "Nessuna scommessa piazzata con i criteri specificati"}
        
        win_rate = bets_won / bets_placed
        roi = ((total_returned - total_staked) / total_staked * 100) if total_staked > 0 else 0
        profit = bankroll - initial_bankroll
        profit_pct = (profit / initial_bankroll * 100) if initial_bankroll > 0 else 0
        
        # Sharpe-like ratio (return / volatility)
        if len(profit_history) > 1:
            returns = np.diff(profit_history) / profit_history[:-1]
            sharpe_approx = np.mean(returns) / (np.std(returns) + 1e-10) if np.std(returns) > 0 else 0
        else:
            sharpe_approx = 0
        
        return {
            "initial_bankroll": initial_bankroll,
            "final_bankroll": round(bankroll, 2),
            "profit": round(profit, 2),
            "profit_pct": round(profit_pct, 2),
            "bets_placed": bets_placed,
            "bets_won": bets_won,
            "win_rate": round(win_rate * 100, 2),
            "roi": round(roi, 2),
            "total_staked": round(total_staked, 2),
            "total_returned": round(total_returned, 2),
            "sharpe_approx": round(sharpe_approx, 3),
            "profit_history": profit_history,
        }
    except Exception as e:
        return {"error": f"Errore backtest: {str(e)}"}

# ============================================================
#   VISUALIZZAZIONI AVANZATE
# ============================================================

def create_score_heatmap_data(mat: List[List[float]], max_goals: int = 10) -> np.ndarray:
    """
    Prepara dati per heatmap della matrice score.
    """
    mg = min(len(mat) - 1, max_goals)
    heatmap_data = np.zeros((mg + 1, mg + 1))
    
    for h in range(mg + 1):
        for a in range(mg + 1):
            if h < len(mat) and a < len(mat[h]):
                heatmap_data[h, a] = mat[h][a] * 100  # Converti in percentuale
    
    return heatmap_data

# ============================================================
#   CACHING E RATE LIMITING
# ============================================================

def cached_api_call(cache_key: str, api_func: callable, *args, **kwargs):
    """
    Cache per chiamate API per evitare rate limiting.
    """
    import time
    
    if cache_key in API_CACHE:
        cached_data, cached_time = API_CACHE[cache_key]
        if time.time() - cached_time < CACHE_EXPIRY:
            return cached_data
    
    # Chiama API
    try:
        result = api_func(*args, **kwargs)
        API_CACHE[cache_key] = (result, time.time())
        return result
    except Exception as e:
        # Se errore, ritorna cache vecchia se disponibile
        if cache_key in API_CACHE:
            return API_CACHE[cache_key][0]
        raise e

# ============================================================
#   EXPORT E REPORT
# ============================================================

def export_analysis_to_csv(risultati: Dict[str, Any], match_name: str, output_file: str = None) -> str:
    """
    Esporta analisi completa in CSV.
    """
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"analisi_{match_name.replace(' ', '_')}_{timestamp}.csv"
    
    # Prepara dati
    data = {
        "Match": [match_name],
        "Timestamp": [datetime.now().isoformat()],
        "Lambda_Home": [risultati.get("lambda_home", 0)],
        "Lambda_Away": [risultati.get("lambda_away", 0)],
        "Rho": [risultati.get("rho", 0)],
        "Prob_Home_%": [risultati.get("p_home", 0) * 100],
        "Prob_Draw_%": [risultati.get("p_draw", 0) * 100],
        "Prob_Away_%": [risultati.get("p_away", 0) * 100],
        "Over_2.5_%": [risultati.get("over_25", 0) * 100],
        "BTTS_%": [risultati.get("btts", 0) * 100],
    }
    
    df = pd.DataFrame(data)
    df.to_csv(output_file, index=False)
    return output_file

def export_analysis_to_excel(risultati: Dict[str, Any], match_name: str, odds_data: Dict[str, float], 
                             output_file: str = None) -> str:
    """
    Esporta analisi completa in Excel con multiple sheets.
    """
    try:
        from openpyxl import Workbook
        from openpyxl.styles import Font, PatternFill, Alignment
    except ImportError:
        raise ImportError("openpyxl necessario per export Excel. Installare: pip install openpyxl")
    
    if output_file is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = f"analisi_{match_name.replace(' ', '_')}_{timestamp}.xlsx"
    
    wb = Workbook()
    
    # Sheet 1: Riepilogo
    ws1 = wb.active
    ws1.title = "Riepilogo"
    ws1.append(["Analisi Partita", match_name])
    ws1.append(["Data", datetime.now().strftime("%Y-%m-%d %H:%M:%S")])
    ws1.append([])
    ws1.append(["Parametri Modello"])
    ws1.append(["Lambda Casa", risultati.get("lambda_home", 0)])
    ws1.append(["Lambda Trasferta", risultati.get("lambda_away", 0)])
    ws1.append(["Rho (correlazione)", risultati.get("rho", 0)])
    ws1.append([])
    ws1.append(["Probabilit√† Principali"])
    ws1.append(["Casa", f"{risultati.get('p_home', 0)*100:.2f}%"])
    ws1.append(["Pareggio", f"{risultati.get('p_draw', 0)*100:.2f}%"])
    ws1.append(["Trasferta", f"{risultati.get('p_away', 0)*100:.2f}%"])
    
    # Sheet 2: Quote e Value
    ws2 = wb.create_sheet("Quote e Value")
    ws2.append(["Mercato", "Esito", "Quota", "Prob Modello %", "Prob Quota %", "Edge %", "EV %"])
    
    for esito, prob, odd_key in [
        ("Casa", risultati.get("p_home", 0), "odds_1"),
        ("Pareggio", risultati.get("p_draw", 0), "odds_x"),
        ("Trasferta", risultati.get("p_away", 0), "odds_2"),
    ]:
        if odd_key in odds_data and odds_data[odd_key] > 0:
            odd = odds_data[odd_key]
            p_book = 1 / odd
            edge = (prob - p_book) * 100
            ev = (prob * odd - 1) * 100
            ws2.append(["1X2", esito, odd, f"{prob*100:.2f}", f"{p_book*100:.2f}", 
                       f"{edge:+.2f}", f"{ev:+.2f}"])
    
    # Sheet 3: Top Risultati
    ws3 = wb.create_sheet("Top Risultati")
    ws3.append(["Casa", "Trasferta", "Probabilit√† %"])
    for h, a, p in risultati.get("top10", []):
        ws3.append([h, a, f"{p:.2f}"])
    
    wb.save(output_file)
    return output_file

# ============================================================
#   COMPARAZIONE BOOKMAKERS
# ============================================================

def compare_bookmaker_odds(event: dict) -> Dict[str, List[Dict[str, Any]]]:
    """
    Confronta quote tra diversi bookmakers per trovare le migliori.
    
    Returns: Dict con migliori quote per ogni mercato
    """
    if not event or "bookmakers" not in event:
        return {}
    
    home_team = (event.get("home_team") or "").lower()
    away_team = (event.get("away_team") or "").lower()
    
    best_odds = {
        "1": [],  # Lista di (bookmaker, odds)
        "X": [],
        "2": [],
        "over_25": [],
        "under_25": [],
        "btts": [],
    }
    
    for bk in event.get("bookmakers", []):
        bk_name = bk.get("key", "unknown")
        
        for mk in bk.get("markets", []):
            mk_key_raw = mk.get("key")
            # Assicurati che mk_key sia sempre una stringa (gestisce None)
            mk_key = str(mk_key_raw).lower() if mk_key_raw is not None else ""
            
            # 1X2
            if "h2h" in mk_key or "match_winner" in mk_key:
                for o in mk.get("outcomes", []):
                    name_l = (o.get("name") or "").lower()
                    price = o.get("price")
                    if not price:
                        continue
                    
                    if home_team in name_l or name_l in home_team:
                        best_odds["1"].append({"bookmaker": bk_name, "odds": price})
                    elif away_team in name_l or name_l in away_team:
                        best_odds["2"].append({"bookmaker": bk_name, "odds": price})
                    elif "draw" in name_l or "x" == name_l or "pareggio" in name_l:
                        best_odds["X"].append({"bookmaker": bk_name, "odds": price})
            
            # Over/Under
            elif "totals" in mk_key:
                for o in mk.get("outcomes", []):
                    point = o.get("point")
                    price = o.get("price")
                    name_l = (o.get("name") or "").lower()
                    if point == 2.5 and price:
                        if "over" in name_l:
                            best_odds["over_25"].append({"bookmaker": bk_name, "odds": price})
                        elif "under" in name_l:
                            best_odds["under_25"].append({"bookmaker": bk_name, "odds": price})
            
            # BTTS
            elif "btts" in mk_key:
                for o in mk.get("outcomes", []):
                    name_l = (o.get("name") or "").lower()
                    price = o.get("price")
                    if price and ("yes" in name_l or "s√¨" in name_l):
                        best_odds["btts"].append({"bookmaker": bk_name, "odds": price})
    
    # Ordina per odds migliori (pi√π alte)
    for key in best_odds:
        best_odds[key].sort(key=lambda x: x["odds"], reverse=True)
    
    return best_odds

def find_best_odds_summary(best_odds: Dict[str, List[Dict[str, Any]]]) -> Dict[str, Dict[str, Any]]:
    """
    Crea riepilogo delle migliori quote.
    """
    summary = {}
    
    for market, odds_list in best_odds.items():
        if odds_list:
            best = odds_list[0]
            # Calcola media e spread
            all_odds = [x["odds"] for x in odds_list]
            avg_odds = np.mean(all_odds)
            max_odds = max(all_odds)
            min_odds = min(all_odds)
            spread = max_odds - min_odds
            
            summary[market] = {
                "best_bookmaker": best["bookmaker"],
                "best_odds": best["odds"],
                "avg_odds": round(avg_odds, 3),
                "max_odds": max_odds,
                "min_odds": min_odds,
                "spread": round(spread, 3),
                "num_bookmakers": len(odds_list),
                "value": round((best["odds"] - avg_odds) / avg_odds * 100, 2)  # % sopra media
            }
    
    return summary

# ============================================================
#   MARKET MOVEMENT INTELLIGENCE
# ============================================================

def calculate_market_movement_factor(
    spread_apertura: float = None,
    total_apertura: float = None,
    spread_corrente: float = None,
    total_corrente: float = None,
) -> Dict[str, Any]:
    """
    Calcola il "market movement factor" basato sul movimento tra apertura e corrente.
    
    Strategia:
    - Movimento basso (< 0.2): mercato stabile ‚Üí pi√π peso all'apertura (70% apertura, 30% corrente)
    - Movimento medio (0.2-0.4): mercato in movimento ‚Üí blend equilibrato (50% apertura, 50% corrente)
    - Movimento alto (> 0.4): smart money in azione ‚Üí pi√π peso alle quote correnti (30% apertura, 70% corrente)
    
    Returns:
        Dict con weight_apertura, weight_corrente, movement_magnitude, movement_type
    """
    # Se non abbiamo dati apertura, usa solo corrente
    if spread_apertura is None and total_apertura is None:
        return {
            "weight_apertura": 0.0,
            "weight_corrente": 1.0,
            "movement_magnitude": 0.0,
            "movement_type": "NO_OPENING_DATA"
        }
    
    # Calcola movimento spread
    movement_spread = 0.0
    if spread_apertura is not None and spread_corrente is not None:
        movement_spread = abs(spread_corrente - spread_apertura)
    
    # Calcola movimento total
    movement_total = 0.0
    if total_apertura is not None and total_corrente is not None:
        movement_total = abs(total_corrente - total_apertura)
    
    # Movimento combinato (media pesata: spread pi√π importante)
    movement_magnitude = (movement_spread * 0.6 + movement_total * 0.4) if (movement_spread > 0 or movement_total > 0) else 0.0
    
    # Determina pesi basati su movimento
    if movement_magnitude < 0.2:
        # Mercato stabile: pi√π peso all'apertura (pi√π affidabile)
        weight_apertura = 0.70
        weight_corrente = 0.30
        movement_type = "STABLE"
    elif movement_magnitude < 0.4:
        # Movimento medio: blend equilibrato
        weight_apertura = 0.50
        weight_corrente = 0.50
        movement_type = "MODERATE"
    else:
        # Movimento alto: smart money in azione, pi√π peso alle quote correnti
        weight_apertura = 0.30
        weight_corrente = 0.70
        movement_type = "HIGH_SMART_MONEY"
    
    return {
        "weight_apertura": weight_apertura,
        "weight_corrente": weight_corrente,
        "movement_magnitude": round(movement_magnitude, 3),
        "movement_type": movement_type,
        "movement_spread": round(movement_spread, 3) if movement_spread > 0 else None,
        "movement_total": round(movement_total, 3) if movement_total > 0 else None,
    }

def apply_market_movement_blend(
    lambda_h_current: float,
    lambda_a_current: float,
    total_current: float,
    spread_apertura: float = None,
    total_apertura: float = None,
    spread_corrente: float = None,
    total_corrente: float = None,
    home_advantage: float = 1.30,
) -> Tuple[float, float]:
    """
    Applica blend bayesiano tra lambda da apertura e corrente basato su market movement.
    
    Se abbiamo dati apertura, calcola lambda da apertura e fa blend con corrente.
    """
    # Se spread/total correnti non forniti, calcolali dai lambda
    if spread_corrente is None:
        spread_corrente = lambda_h_current - lambda_a_current
    if total_corrente is None:
        total_corrente = lambda_h_current + lambda_a_current
    
    # Calcola market movement factor
    movement_factor = calculate_market_movement_factor(
        spread_apertura, total_apertura, spread_corrente, total_corrente
    )
    
    # Se non abbiamo dati apertura o movimento √® nullo, usa solo corrente
    if movement_factor["weight_apertura"] == 0.0:
        return lambda_h_current, lambda_a_current
    
    # Calcola lambda da apertura (se disponibile)
    if spread_apertura is not None and total_apertura is not None:
        # ‚ö†Ô∏è VALIDAZIONE: Verifica che spread_apertura e total_apertura siano ragionevoli
        # Clamp per sicurezza (anche se dovrebbero essere gi√† validati)
        spread_apertura_safe = max(-3.0, min(3.0, spread_apertura))
        total_apertura_safe = max(0.5, min(6.0, total_apertura))
        
        # Stima lambda da spread/total apertura
        lambda_total_ap = total_apertura_safe / 2.0
        
        # ‚ö†Ô∏è CORREZIONE: Spread apertura ‚Üí lambda con protezione
        # spread_factor_ap = exp(spread * 0.5) pu√≤ esplodere se spread √® alto
        # Limita spread_factor_ap per evitare valori estremi
        spread_factor_ap_raw = math.exp(spread_apertura_safe * 0.5)
        spread_factor_ap = max(0.5, min(2.0, spread_factor_ap_raw))  # Limita a range ragionevole
        
        lambda_h_ap = lambda_total_ap * spread_factor_ap * math.sqrt(home_advantage)
        lambda_a_ap = lambda_total_ap / spread_factor_ap / math.sqrt(home_advantage)
        
        # ‚ö†Ô∏è VERIFICA: Assicura coerenza total dopo calcolo da apertura
        total_check_ap = lambda_h_ap + lambda_a_ap
        if abs(total_check_ap - total_apertura_safe) > 0.5:
            # Ricalibra per mantenere total coerente
            scale_factor_ap = total_apertura_safe / max(0.1, total_check_ap)
            lambda_h_ap *= scale_factor_ap
            lambda_a_ap *= scale_factor_ap
        
        # Constraints
        lambda_h_ap = max(0.3, min(4.5, lambda_h_ap))
        lambda_a_ap = max(0.3, min(4.5, lambda_a_ap))
        
        # ‚ö†Ô∏è CONTROLLO: Limita effetto del blend per evitare valori estremi
        # Il blend non pu√≤ cambiare i lambda pi√π del 40% rispetto a corrente
        max_blend_adjustment = 1.4
        lambda_h_ap_limited = max(
            lambda_h_current / max_blend_adjustment,
            min(lambda_h_current * max_blend_adjustment, lambda_h_ap)
        )
        lambda_a_ap_limited = max(
            lambda_a_current / max_blend_adjustment,
            min(lambda_a_current * max_blend_adjustment, lambda_a_ap)
        )
        
        # Blend bayesiano
        w_ap = movement_factor["weight_apertura"]
        w_curr = movement_factor["weight_corrente"]
        
        lambda_h_blended = w_ap * lambda_h_ap_limited + w_curr * lambda_h_current
        lambda_a_blended = w_ap * lambda_a_ap_limited + w_curr * lambda_a_current
        
        # ‚ö†Ô∏è VERIFICA FINALE: Limita variazione totale del blend
        lambda_h_blended = max(
            lambda_h_current / max_blend_adjustment,
            min(lambda_h_current * max_blend_adjustment, lambda_h_blended)
        )
        lambda_a_blended = max(
            lambda_a_current / max_blend_adjustment,
            min(lambda_a_current * max_blend_adjustment, lambda_a_blended)
        )
        
        return lambda_h_blended, lambda_a_blended
    
    # Se non abbiamo spread apertura ma abbiamo total apertura
    elif total_apertura is not None:
        # ‚ö†Ô∏è VALIDAZIONE: Verifica che total_apertura sia ragionevole
        total_apertura_safe = max(0.5, min(6.0, total_apertura))
        
        # Usa total apertura per calibrare total corrente
        lambda_total_ap = total_apertura_safe / 2.0
        lambda_total_curr = total_current / 2.0
        
        # ‚ö†Ô∏è CONTROLLO: Limita differenza tra total apertura e corrente
        # Se differiscono troppo, riduci peso apertura
        total_diff = abs(total_apertura_safe - total_current) / max(0.1, total_current)
        if total_diff > 0.5:  # Se differiscono pi√π del 50%
            # Riduci peso apertura se differenza √® troppo grande
            movement_factor["weight_apertura"] = min(0.3, movement_factor["weight_apertura"])
            movement_factor["weight_corrente"] = 1.0 - movement_factor["weight_apertura"]
        
        # Blend dei total
        w_ap = movement_factor["weight_apertura"]
        w_curr = movement_factor["weight_corrente"]
        lambda_total_blended = w_ap * lambda_total_ap + w_curr * lambda_total_curr
        
        # ‚ö†Ô∏è VERIFICA: Limita lambda_total_blended a range ragionevole
        lambda_total_blended = max(0.5, min(5.0, lambda_total_blended))
        
        # Mantieni proporzione corrente tra lambda_h e lambda_a
        ratio_h = lambda_h_current / (lambda_h_current + lambda_a_current) if (lambda_h_current + lambda_a_current) > 0 else 0.5
        ratio_a = 1.0 - ratio_h
        
        lambda_h_blended = lambda_total_blended * ratio_h * 2.0
        lambda_a_blended = lambda_total_blended * ratio_a * 2.0
        
        # ‚ö†Ô∏è CONTROLLO: Limita effetto del blend
        max_blend_adjustment = 1.4
        lambda_h_blended = max(
            lambda_h_current / max_blend_adjustment,
            min(lambda_h_current * max_blend_adjustment, lambda_h_blended)
        )
        lambda_a_blended = max(
            lambda_a_current / max_blend_adjustment,
            min(lambda_a_current * max_blend_adjustment, lambda_a_blended)
        )
        
        return lambda_h_blended, lambda_a_blended
    
    # Fallback: usa solo corrente
    return lambda_h_current, lambda_a_current

# ============================================================
#   FEATURE ENGINEERING AVANZATO
# ============================================================

def apply_advanced_data_adjustments(
    lambda_h: float,
    lambda_a: float,
    advanced_data: Dict[str, Any],
) -> Tuple[float, float]:
    """
    Applica aggiustamenti basati su dati avanzati (statistiche, H2H, infortuni).
    Lavora in background, modifica lambda silenziosamente.
    
    ‚ö†Ô∏è MIGLIORAMENTO: Limita effetto cumulativo per evitare esplosione dei lambda.
    """
    if not advanced_data or not advanced_data.get("data_available"):
        return lambda_h, lambda_a
    
    # Salva valori iniziali per limitare effetto totale
    lambda_h_initial = lambda_h
    lambda_a_initial = lambda_a
    max_advanced_adjustment = 1.2  # Massimo 20% di variazione totale
    
    # 1. Aggiustamenti forma squadre (limitati)
    home_stats = advanced_data.get("home_team_stats")
    away_stats = advanced_data.get("away_team_stats")
    
    if home_stats and home_stats.get("confidence", 0) > 0.3:
        # Limita form_attack e form_defense a range ragionevole
        form_attack = max(0.85, min(1.15, home_stats.get("form_attack", 1.0)))
        form_defense = max(0.85, min(1.15, home_stats.get("form_defense", 1.0)))
        # Applica forma attacco casa
        lambda_h *= form_attack
        # Applica forma difesa trasferta (riduce lambda away)
        lambda_a *= (2.0 - form_defense)  # Inverso, ma limitato
    
    if away_stats and away_stats.get("confidence", 0) > 0.3:
        form_attack = max(0.85, min(1.15, away_stats.get("form_attack", 1.0)))
        form_defense = max(0.85, min(1.15, away_stats.get("form_defense", 1.0)))
        # Applica forma attacco trasferta
        lambda_a *= form_attack
        # Applica forma difesa casa (riduce lambda home)
        lambda_h *= (2.0 - form_defense)  # Inverso, ma limitato
    
    # 2. Aggiustamenti H2H (limitati)
    h2h_data = advanced_data.get("h2h_data")
    if h2h_data and h2h_data.get("confidence", 0) > 0.3:
        # Limita h2h_home_advantage a range ragionevole
        h2h_advantage = max(0.9, min(1.1, h2h_data.get("h2h_home_advantage", 1.0)))
        # Aggiusta vantaggio casa
        lambda_h *= h2h_advantage
        # Aggiusta total gol (entrambi i lambda) - limitato
        goals_factor = max(0.9, min(1.1, h2h_data.get("h2h_goals_factor", 1.0)))
        lambda_h *= math.sqrt(goals_factor)  # Radice per distribuire
        lambda_a *= math.sqrt(goals_factor)
    
    # 3. Aggiustamenti infortuni (limitati)
    home_injuries = advanced_data.get("home_injuries")
    away_injuries = advanced_data.get("away_injuries")
    
    if home_injuries and home_injuries.get("confidence", 0) > 0.3:
        # Limita attack_factor e defense_factor
        attack_factor = max(0.85, min(1.0, home_injuries.get("attack_factor", 1.0)))
        defense_factor = max(0.85, min(1.0, home_injuries.get("defense_factor", 1.0)))
        # Infortuni casa: riduce attacco, aumenta vulnerabilit√† difesa
        lambda_h *= attack_factor
        lambda_a *= (2.0 - defense_factor)  # Inverso, ma limitato
    
    if away_injuries and away_injuries.get("confidence", 0) > 0.3:
        attack_factor = max(0.85, min(1.0, away_injuries.get("attack_factor", 1.0)))
        defense_factor = max(0.85, min(1.0, away_injuries.get("defense_factor", 1.0)))
        # Infortuni trasferta: riduce attacco, aumenta vulnerabilit√† difesa
        lambda_a *= attack_factor
        lambda_h *= (2.0 - defense_factor)  # Inverso, ma limitato
    
    # ‚ö†Ô∏è CONTROLLO FINALE: Limita effetto totale degli aggiustamenti avanzati
    lambda_h = max(lambda_h_initial / max_advanced_adjustment, min(lambda_h_initial * max_advanced_adjustment, lambda_h))
    lambda_a = max(lambda_a_initial / max_advanced_adjustment, min(lambda_a_initial * max_advanced_adjustment, lambda_a))
    
    return lambda_h, lambda_a

# ============================================================
#   PORTFOLIO TRACKING
# ============================================================

def add_to_portfolio(
    match_name: str,
    market: str,
    esito: str,
    odds: float,
    stake: float,
    probability: float,
    timestamp: str = None,
) -> None:
    """
    Aggiunge scommessa al portfolio.
    """
    if timestamp is None:
        timestamp = datetime.now().isoformat()
    
    portfolio_entry = {
        "timestamp": timestamp,
        "match": match_name,
        "market": market,
        "esito": esito,
        "odds": odds,
        "stake": stake,
        "probability": probability,
        "expected_value": (probability * odds - 1) * stake,
        "status": "pending",  # pending, won, lost
        "result": "",
    }
    
    # Carica portfolio esistente
    if os.path.exists(PORTFOLIO_FILE):
        df = pd.read_csv(PORTFOLIO_FILE)
        df = pd.concat([df, pd.DataFrame([portfolio_entry])], ignore_index=True)
    else:
        df = pd.DataFrame([portfolio_entry])
    
    df.to_csv(PORTFOLIO_FILE, index=False)

def get_portfolio_summary() -> Dict[str, Any]:
    """
    Calcola riepilogo portfolio.
    """
    if not os.path.exists(PORTFOLIO_FILE):
        return {"total_bets": 0, "total_staked": 0.0, "pending_bets": 0}
    
    df = pd.read_csv(PORTFOLIO_FILE)
    
    total_bets = len(df)
    total_staked = df["stake"].sum()
    pending = len(df[df["status"] == "pending"])
    won = len(df[df["status"] == "won"])
    lost = len(df[df["status"] == "lost"])
    
    # Calcola profit per scommesse chiuse
    df_closed = df[df["status"].isin(["won", "lost"])]
    if len(df_closed) > 0:
        total_returned = 0.0
        for _, row in df_closed.iterrows():
            if row["status"] == "won":
                total_returned += row["stake"] * row["odds"]
        
        total_staked_closed = df_closed["stake"].sum()
        profit = total_returned - total_staked_closed
        roi = (profit / total_staked_closed * 100) if total_staked_closed > 0 else 0
    else:
        profit = 0.0
        roi = 0.0
    
    return {
        "total_bets": total_bets,
        "total_staked": round(total_staked, 2),
        "pending_bets": pending,
        "won_bets": won,
        "lost_bets": lost,
        "profit": round(profit, 2),
        "roi": round(roi, 2),
        "win_rate": round(won / (won + lost) * 100, 1) if (won + lost) > 0 else 0.0,
    }

# ============================================================
#   DASHBOARD ANALYTICS
# ============================================================

# ============================================================
#   MARKET MOVEMENT TRACKING
# ============================================================

def track_odds_movement(
    match_name: str,
    odds_1: float,
    odds_x: float,
    odds_2: float,
    timestamp: str = None,
) -> Dict[str, Any]:
    """
    Traccia movimenti delle quote nel tempo per identificare trend.
    """
    if timestamp is None:
        timestamp = datetime.now().isoformat()
    
    # Carica storico movimenti
    if os.path.exists(ODDS_HISTORY_FILE):
        df = pd.read_csv(ODDS_HISTORY_FILE)
    else:
        df = pd.DataFrame(columns=["timestamp", "match", "odds_1", "odds_x", "odds_2"])
    
    # Aggiungi nuovo punto
    new_row = {
        "timestamp": timestamp,
        "match": match_name,
        "odds_1": odds_1,
        "odds_x": odds_x,
        "odds_2": odds_2,
    }
    df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
    df.to_csv(ODDS_HISTORY_FILE, index=False)
    
    # Analizza trend per questa partita
    match_data = df[df["match"] == match_name].sort_values("timestamp")
    
    if len(match_data) >= 2:
        # Calcola cambiamenti
        first = match_data.iloc[0]
        last = match_data.iloc[-1]
        
        movement = {
            "odds_1_change": last["odds_1"] - first["odds_1"],
            "odds_x_change": last["odds_x"] - first["odds_x"],
            "odds_2_change": last["odds_2"] - first["odds_2"],
            "odds_1_change_pct": ((last["odds_1"] - first["odds_1"]) / first["odds_1"]) * 100,
            "trend": "stable",
            "market_sentiment": "neutral",
        }
        
        # Determina trend
        if abs(movement["odds_1_change_pct"]) > 5:
            if movement["odds_1_change"] < 0:
                movement["trend"] = "home_favorite_increasing"
                movement["market_sentiment"] = "home_strong"
            else:
                movement["trend"] = "home_favorite_decreasing"
                movement["market_sentiment"] = "away_strong"
        
        return movement
    
    return {"trend": "insufficient_data"}

def get_odds_movement_insights(match_name: str) -> Dict[str, Any]:
    """
    Analizza movimenti quote e fornisce insights.
    """
    if not os.path.exists(ODDS_HISTORY_FILE):
        return {}
    
    df = pd.read_csv(ODDS_HISTORY_FILE)
    match_data = df[df["match"] == match_name].sort_values("timestamp")
    
    if len(match_data) < 2:
        return {}
    
    # Calcola volatilit√†
    volatility_1 = match_data["odds_1"].std()
    volatility_x = match_data["odds_x"].std()
    volatility_2 = match_data["odds_2"].std()
    
    # Identifica movimenti significativi
    significant_moves = []
    for i in range(1, len(match_data)):
        prev = match_data.iloc[i-1]
        curr = match_data.iloc[i]
        
        for col in ["odds_1", "odds_x", "odds_2"]:
            change_pct = abs((curr[col] - prev[col]) / prev[col]) * 100
            if change_pct > 3:  # Movimento > 3%
                significant_moves.append({
                    "market": col,
                    "change": change_pct,
                    "timestamp": curr["timestamp"],
                    "direction": "up" if curr[col] > prev[col] else "down"
                })
    
    return {
        "volatility": {
            "odds_1": round(volatility_1, 3),
            "odds_x": round(volatility_x, 3),
            "odds_2": round(volatility_2, 3),
        },
        "significant_moves": significant_moves,
        "num_data_points": len(match_data),
    }

# ============================================================
#   TIME-BASED ADJUSTMENTS
# ============================================================

def get_time_based_adjustments(
    match_datetime: str = None,
    league: str = "generic",
) -> Dict[str, float]:
    """
    Calcola aggiustamenti basati su:
    - Ora partita (serale vs pomeridiana)
    - Giorno settimana (weekend vs settimana)
    - Periodo stagione (inizio, met√†, fine)
    """
    if match_datetime is None:
        match_datetime = datetime.now().isoformat()

    try:
        dt = datetime.fromisoformat(match_datetime.replace("Z", "+00:00"))
    except (ValueError, AttributeError, TypeError) as e:
        logger.warning(f"Errore parsing datetime '{match_datetime}': {e}, uso datetime corrente")
        dt = datetime.now()
    
    adjustments = {
        "time_factor": 1.0,
        "day_factor": 1.0,
        "season_factor": 1.0,
    }
    
    # Ora partita
    hour = dt.hour
    if 20 <= hour <= 22:  # Serale
        adjustments["time_factor"] = 1.05  # +5% gol (atmosfera)
    elif 12 <= hour <= 15:  # Pomeridiana
        adjustments["time_factor"] = 0.98  # -2% gol
    
    # Giorno settimana
    weekday = dt.weekday()
    if weekday >= 5:  # Weekend (sabato/domenica)
        adjustments["day_factor"] = 1.03  # +3% gol (pi√π pubblico)
    elif weekday == 2:  # Mercoled√¨ (spesso Champions/Europa)
        adjustments["day_factor"] = 1.08  # +8% gol (partite importanti)
    
    # Periodo stagione (approssimato)
    month = dt.month
    if month in [8, 9]:  # Inizio stagione
        adjustments["season_factor"] = 1.02  # +2% gol (squadre fresche)
    elif month in [4, 5]:  # Fine stagione
        adjustments["season_factor"] = 0.97  # -3% gol (squadre stanche)
    
    return adjustments

def apply_time_adjustments(
    lambda_h: float,
    lambda_a: float,
    match_datetime: str = None,
    league: str = "generic",
) -> Tuple[float, float]:
    """
    Applica aggiustamenti temporali ai lambda.
    """
    adjustments = get_time_based_adjustments(match_datetime, league)
    
    # Combina tutti i fattori
    total_factor = (
        adjustments["time_factor"] *
        adjustments["day_factor"] *
        adjustments["season_factor"]
    )
    
    # Applica solo se significativo
    if abs(total_factor - 1.0) > 0.02:  # > 2% di differenza
        lambda_h *= total_factor
        lambda_a *= total_factor
    
    return lambda_h, lambda_a

# ============================================================
#   FATIGUE E MOTIVATION FACTORS
# ============================================================

def calculate_fatigue_factor(
    team_name: str,
    days_since_last_match: int = None,
    matches_last_30_days: int = None,
) -> float:
    """
    Calcola fattore fatica basato su:
    - Giorni dall'ultima partita
    - Numero partite ultimi 30 giorni
    """
    fatigue = 1.0
    
    # Giorni di riposo
    if days_since_last_match is not None:
        if days_since_last_match <= 2:
            fatigue *= 0.92  # -8% (molto stanco)
        elif days_since_last_match == 3:
            fatigue *= 0.96  # -4% (stanco)
        elif days_since_last_match >= 7:
            fatigue *= 1.05  # +5% (molto riposato)
    
    # Partite ravvicinate
    if matches_last_30_days is not None:
        if matches_last_30_days >= 8:
            fatigue *= 0.94  # -6% (troppe partite)
        elif matches_last_30_days <= 4:
            fatigue *= 1.03  # +3% (poche partite)
    
    return fatigue

def calculate_motivation_factor(
    team_position: int = None,
    points_from_relegation: int = None,
    points_from_europe: int = None,
    is_derby: bool = False,
) -> float:
    """
    Calcola fattore motivazione basato su:
    - Posizione in classifica
    - Vicinanza a obiettivi (salvezza, Europa)
    - Partite speciali (derby)
    """
    motivation = 1.0
    
    # Derby
    if is_derby:
        motivation *= 1.12  # +12% (alta motivazione)
    
    # Lotta salvezza
    if points_from_relegation is not None:
        if 0 <= points_from_relegation <= 3:
            motivation *= 1.10  # +10% (lotta per non retrocedere)
    
    # Lotta Europa
    if points_from_europe is not None:
        if 0 <= points_from_europe <= 3:
            motivation *= 1.08  # +8% (lotta per Europa)
    
    return motivation

# ============================================================
#   ANOMALY DETECTION
# ============================================================

def detect_odds_anomalies(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    odds_over25: float = None,
    odds_under25: float = None,
) -> Dict[str, Any]:
    """
    Rileva anomalie nelle quote che potrebbero indicare:
    - Errori bookmaker
    - Quote non aggiornate
    - Opportunit√† di arbitraggio
    """
    anomalies = []
    severity = 0
    
    # 1. Check margine anomalo
    margin = (1/odds_1 + 1/odds_x + 1/odds_2) - 1
    if margin < 0:
        anomalies.append({
            "type": "negative_margin",
            "description": f"Margine negativo ({margin*100:.2f}%) - possibile errore o arbitraggio",
            "severity": "high"
        })
        severity += 3
    elif margin > 0.20:
        anomalies.append({
            "type": "excessive_margin",
            "description": f"Margine eccessivo ({margin*100:.2f}%) - quote poco competitive",
            "severity": "medium"
        })
        severity += 1
    
    # 2. Check coerenza Over/Under
    if odds_over25 and odds_under25:
        margin_ou = (1/odds_over25 + 1/odds_under25) - 1
        if margin_ou < 0:
            anomalies.append({
                "type": "arbitrage_opportunity",
                "description": "Opportunit√† arbitraggio Over/Under",
                "severity": "high"
            })
            severity += 2
    
    # 3. Check quote estreme
    if odds_1 < 1.01 or odds_2 < 1.01:
        anomalies.append({
            "type": "extreme_odds",
            "description": "Quote estreme (< 1.01) - possibile errore",
            "severity": "high"
        })
        severity += 2
    
    # 4. Check incoerenza 1X2 vs Over/Under
    if odds_over25 and odds_1:
        p_home = 1 / odds_1
        p_over = 1 / odds_over25
        
        # Se casa molto favorita ma over alto ‚Üí incoerenza
        if p_home > 0.70 and p_over > 0.60:
            anomalies.append({
                "type": "incoherent_markets",
                "description": "Casa molto favorita ma Over alto - possibile incoerenza",
                "severity": "medium"
            })
            severity += 1
    
    return {
        "anomalies": anomalies,
        "severity_score": severity,
        "has_anomalies": len(anomalies) > 0,
        "recommendation": "verify" if severity >= 3 else ("review" if severity >= 1 else "ok")
    }

# ============================================================
#   ADVANCED RISK MANAGEMENT
# ============================================================

def calculate_dynamic_position_size(
    edge: float,
    odds: float,
    bankroll: float,
    current_drawdown: float = 0.0,
    win_streak: int = 0,
    loss_streak: int = 0,
) -> Dict[str, Any]:
    """
    Calcola position size dinamico basato su:
    - Edge e odds
    - Drawdown corrente
    - Streak (vittorie/sconfitte consecutive)
    """
    # Kelly base
    p = edge + (1 / odds)  # Probabilit√† reale
    q = 1 - p
    kelly_base = (p * odds - 1) / (odds - 1)
    kelly_base = max(0, min(0.25, kelly_base))  # Cap a 25%
    
    # Aggiustamenti per drawdown
    if current_drawdown > 0.20:  # Drawdown > 20%
        kelly_base *= 0.5  # Riduci del 50%
    elif current_drawdown > 0.10:  # Drawdown > 10%
        kelly_base *= 0.75  # Riduci del 25%
    
    # Aggiustamenti per streak
    if loss_streak >= 3:
        kelly_base *= 0.6  # Riduci dopo 3 sconfitte consecutive
    elif win_streak >= 5:
        kelly_base *= 1.1  # Aumenta leggermente dopo 5 vittorie (max 10%)
        kelly_base = min(0.25, kelly_base)  # Cap
    
    stake = bankroll * kelly_base
    
    return {
        "kelly_percent": kelly_base * 100,
        "stake": round(stake, 2),
        "edge": edge,
        "recommendation": "bet" if edge >= 0.03 else ("caution" if edge >= 0.01 else "skip"),
        "risk_level": "low" if current_drawdown < 0.05 else ("medium" if current_drawdown < 0.15 else "high")
    }

def calculate_stop_loss_level(
    initial_bankroll: float,
    current_bankroll: float,
    max_drawdown_pct: float = 0.25,
) -> Dict[str, Any]:
    """
    Calcola livello stop loss per proteggere bankroll.
    """
    drawdown = (initial_bankroll - current_bankroll) / initial_bankroll
    
    stop_loss_triggered = drawdown >= max_drawdown_pct
    
    return {
        "current_drawdown": round(drawdown * 100, 2),
        "max_drawdown": max_drawdown_pct * 100,
        "stop_loss_triggered": stop_loss_triggered,
        "remaining_buffer": round((max_drawdown_pct - drawdown) * 100, 2),
        "recommendation": "stop_betting" if stop_loss_triggered else "continue"
    }

# ============================================================
#   FEATURE IMPORTANCE ANALYSIS
# ============================================================

def analyze_feature_importance(archive_file: str = ARCHIVE_FILE) -> Dict[str, float]:
    """
    Analizza importanza delle features nel modello usando correlazione
    e analisi statistica.
    """
    if not os.path.exists(archive_file):
        return {}
    
    try:
        df = pd.read_csv(archive_file)
        
        # Filtra partite con risultati
        df_complete = df[
            df["esito_reale"].notna() &
            (df["esito_reale"] != "") &
            df["p_home"].notna()
        ]
        
        if len(df_complete) < 20:
            return {}
        
        # Calcola accuracy per ogni feature
        features = {
            "lambda_home": "lambda_home",
            "lambda_away": "lambda_away",
            "rho": "rho",
            "quality_score": "quality_score",
            "market_confidence": "market_confidence",
        }
        
        importance = {}
        
        for feat_name, feat_col in features.items():
            if feat_col not in df_complete.columns:
                continue
            
            # Correlazione con accuracy
            df_complete["correct"] = (
                df_complete["esito_modello"] == df_complete["esito_reale"]
            ).astype(int)
            
            corr = df_complete[feat_col].corr(df_complete["correct"])
            importance[feat_name] = round(abs(corr) * 100, 1) if not pd.isna(corr) else 0
        
        # Ordina per importanza
        sorted_importance = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True))
        
        return sorted_importance
    except Exception as e:
        return {"error": str(e)}

# ============================================================
#   API GRATUITE AGGIUNTIVE - INTEGRAZIONE
# ============================================================

# 1. OPENWEATHERMAP API
def get_weather_for_match(city: str, match_datetime: str = None) -> Dict[str, Any]:
    """
    Recupera condizioni meteo per partita.
    Calcola impatto su lambda (pioggia/vento ‚Üí meno gol).
    """
    if not OPENWEATHER_API_KEY:
        return {"available": False, "weather_factor": 1.0}
    
    try:
        url = "https://api.openweathermap.org/data/2.5/weather"
        params = {
            "q": city,
            "appid": OPENWEATHER_API_KEY,
            "units": "metric",
            "lang": "it"
        }
        
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        data = response.json()
        
        # Estrai dati meteo (MIGLIORATO: pi√π parametri)
        temp = data["main"]["temp"]
        humidity = data["main"]["humidity"]
        pressure = data["main"].get("pressure", 1013)  # Pressione in hPa (default 1013)
        wind_speed = data["wind"].get("speed", 0)
        visibility = data.get("visibility", 10000) / 1000  # Visibilit√† in km (default 10km)
        rain = data.get("rain", {}).get("1h", 0) or data.get("rain", {}).get("3h", 0) or 0
        
        # ‚ö†Ô∏è PROTEZIONE: Valida che weather esista e non sia vuoto prima di accedere a [0]
        weather_list = data.get("weather", [])
        if weather_list and len(weather_list) > 0 and isinstance(weather_list[0], dict):
            conditions = weather_list[0].get("main", "").lower()
            description = weather_list[0].get("description", "")
        else:
            # Fallback: usa valori di default
            conditions = ""
            description = ""
            logger.warning("Dati weather non disponibili o non validi")
        
        # Calcola fattore impatto su lambda (MIGLIORATO: pi√π parametri)
        weather_factor = 1.0
        adjustments = []
        
        # Pioggia ‚Üí riduce gol significativamente
        if rain > 5:  # Pioggia > 5mm/h
            reduction = min(0.15, rain / 50)  # Max -15%
            weather_factor *= (1 - reduction)
            adjustments.append(f"Pioggia forte: -{reduction*100:.1f}%")
        elif rain > 0:
            reduction = rain / 30  # Max -3% per pioggia leggera
            weather_factor *= (1 - reduction)
            adjustments.append(f"Pioggia: -{reduction*100:.1f}%")
        
        # Vento forte ‚Üí riduce gol
        if wind_speed > 15:  # > 15 m/s (54 km/h)
            reduction = min(0.10, (wind_speed - 15) / 30)  # Max -10%
            weather_factor *= (1 - reduction)
            adjustments.append(f"Vento forte: -{reduction*100:.1f}%")
        elif wind_speed > 10:  # > 10 m/s (36 km/h)
            reduction = (wind_speed - 10) / 50  # Max -1%
            weather_factor *= (1 - reduction)
            adjustments.append(f"Vento moderato: -{reduction*100:.1f}%")
        
        # Neve ‚Üí riduce molto gol
        if "snow" in conditions:
            weather_factor *= 0.85  # -15% gol
            adjustments.append("Neve: -15%")
        
        # Temperatura estrema ‚Üí riduce gol
        if temp < 0:
            reduction = min(0.10, abs(temp) / 20)  # Max -10% per freddo estremo
            weather_factor *= (1 - reduction)
            adjustments.append(f"Freddo estremo: -{reduction*100:.1f}%")
        elif temp > 35:
            reduction = min(0.08, (temp - 35) / 15)  # Max -8% per caldo estremo
            weather_factor *= (1 - reduction)
            adjustments.append(f"Caldo estremo: -{reduction*100:.1f}%")
        
        # NUOVO: Umidit√† alta ‚Üí pu√≤ ridurre gol (campo pesante)
        if humidity > 80:
            reduction = min(0.05, (humidity - 80) / 100)  # Max -5% per umidit√† > 80%
            weather_factor *= (1 - reduction)
            adjustments.append(f"Umidit√† alta: -{reduction*100:.1f}%")
        
        # NUOVO: Pressione bassa ‚Üí pu√≤ ridurre gol (condizioni pesanti)
        if pressure < 1000:  # Pressione < 1000 hPa
            reduction = min(0.04, (1000 - pressure) / 50)  # Max -4%
            weather_factor *= (1 - reduction)
            adjustments.append(f"Pressione bassa: -{reduction*100:.1f}%")
        
        # NUOVO: Visibilit√† bassa ‚Üí pu√≤ ridurre gol (nebbia/foschia)
        if visibility < 1:  # Visibilit√† < 1km (nebbia fitta)
            reduction = 0.08  # -8% gol
            weather_factor *= (1 - reduction)
            adjustments.append(f"Nebbia fitta: -{reduction*100:.1f}%")
        elif visibility < 3:  # Visibilit√† < 3km (nebbia moderata)
            reduction = 0.04  # -4% gol
            weather_factor *= (1 - reduction)
            adjustments.append(f"Nebbia moderata: -{reduction*100:.1f}%")
        
        return {
            "available": True,
            "weather_factor": max(0.7, weather_factor),  # Min 0.7 (non ridurre troppo)
            "temperature": temp,
            "humidity": humidity,
            "pressure": pressure,  # NUOVO
            "wind_speed": wind_speed,
            "visibility": visibility,  # NUOVO
            "rain": rain,
            "conditions": conditions,
            "description": description,
            "adjustments": adjustments,
            "city": city
        }
    except (requests.exceptions.RequestException, KeyError, ValueError) as e:
        logger.error(f"Errore OpenWeatherMap: {e}")
        return {"available": False, "weather_factor": 1.0, "error": str(e)}

# 2. FOOTBALL-DATA.ORG API
def football_data_get_team_info(team_name: str, league_code: str = None) -> Dict[str, Any]:
    """
    Recupera info squadra da Football-Data.org (backup/validazione).
    """
    if not FOOTBALL_DATA_API_KEY:
        return {"available": False}
    
    try:
        # Cerca squadra
        url = "https://api.football-data.org/v4/teams"
        headers = {"X-Auth-Token": FOOTBALL_DATA_API_KEY}
        
        # Prova ricerca per nome
        params = {"name": team_name}
        response = requests.get(url, headers=headers, params=params, timeout=5)
        
        if response.status_code == 200:
            teams = response.json().get("teams", [])
            if teams:
                team = teams[0]
                return {
                    "available": True,
                    "team_id": team.get("id"),
                    "name": team.get("name"),
                    "short_name": team.get("shortName"),
                    "founded": team.get("founded"),
                    "venue": team.get("venue"),
                    "website": team.get("website")
                }
        
        return {"available": False, "reason": "Team not found"}
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore Football-Data.org: {e}")
        return {"available": False, "error": str(e)}

def football_data_get_competitions() -> List[Dict[str, Any]]:
    """Recupera lista competizioni disponibili."""
    if not FOOTBALL_DATA_API_KEY:
        return []
    
    try:
        url = "https://api.football-data.org/v4/competitions"
        headers = {"X-Auth-Token": FOOTBALL_DATA_API_KEY}
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        return response.json().get("competitions", [])
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore Football-Data.org competitions: {e}")
        return []

# 3. THESPORTSDB API (NO API KEY NECESSARIA!)
def thesportsdb_get_team_info(team_name: str) -> Dict[str, Any]:
    """
    Recupera info squadra da TheSportsDB (completamente gratuito, no API key).
    """
    try:
        url = "https://www.thesportsdb.com/api/v1/json/3/searchteams.php"
        params = {"t": team_name}
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        data = response.json()
        
        teams = data.get("teams", [])
        if teams:
            team = teams[0]
            return {
                "available": True,
                "team_id": team.get("idTeam"),
                "name": team.get("strTeam"),
                "stadium": team.get("strStadium"),
                "stadium_capacity": team.get("intStadiumCapacity"),
                "stadium_location": team.get("strStadiumLocation"),
                "founded": team.get("intFormedYear"),
                "league": team.get("strLeague"),
                "website": team.get("strWebsite"),
                "logo": team.get("strTeamBadge")
            }
        
        return {"available": False}
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore TheSportsDB: {e}")
        return {"available": False, "error": str(e)}

def thesportsdb_get_stadium_info(stadium_name: str) -> Dict[str, Any]:
    """Recupera info stadio da TheSportsDB."""
    try:
        url = "https://www.thesportsdb.com/api/v1/json/3/searchvenues.php"
        params = {"v": stadium_name}
        response = requests.get(url, params=params, timeout=5)
        response.raise_for_status()
        data = response.json()
        
        venues = data.get("venues", [])
        if venues:
            venue = venues[0]
            return {
                "available": True,
                "name": venue.get("strVenue"),
                "capacity": venue.get("intCapacity"),
                "location": venue.get("strLocation"),
                "country": venue.get("strCountry")
            }
        
        return {"available": False}
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore TheSportsDB stadium: {e}")
        return {"available": False}

# 4. UNDERSTAT SCRAPING (xG avanzato)
def understat_get_team_xg(team_name: str, season: str = None) -> Dict[str, Any]:
    """
    Recupera xG avanzato da Understat.com (scraping).
    Ritorna xG pi√π preciso di API-Football.
    """
    try:
        # Understat usa ID squadra, non nome
        # Per ora ritorna struttura, implementazione completa richiede mapping team_id
        # Questo √® un placeholder per struttura futura
        
        # Esempio struttura dati che si otterrebbe:
        return {
            "available": False,  # Placeholder - richiede implementazione scraping completo
            "team_name": team_name,
            "xg_for": None,
            "xg_against": None,
            "xg_open_play": None,
            "xg_set_pieces": None,
            "note": "Richiede implementazione scraping BeautifulSoup"
        }
    except Exception as e:
        logger.error(f"Errore Understat: {e}")
        return {"available": False, "error": str(e)}

# 5. FBREF SCRAPING (Statistiche avanzate)
def fbref_get_team_stats(team_name: str, league: str = None) -> Dict[str, Any]:
    """
    Recupera statistiche avanzate da FBRef.com (scraping).
    """
    try:
        # Placeholder - implementazione completa richiede scraping
        return {
            "available": False,  # Placeholder
            "team_name": team_name,
            "expected_goals": None,
            "expected_assists": None,
            "expected_goals_against": None,
            "note": "Richiede implementazione scraping BeautifulSoup"
        }
    except Exception as e:
        logger.error(f"Errore FBRef: {e}")
        return {"available": False, "error": str(e)}

# Funzione helper per applicare impatto meteo su lambda
def apply_weather_impact(lh: float, la: float, weather_data: Dict[str, Any]) -> Tuple[float, float]:
    """
    Applica impatto meteo su lambda home e away.
    """
    if not weather_data.get("available", False):
        return lh, la
    
    weather_factor = weather_data.get("weather_factor", 1.0)
    
    # Applica fattore a entrambe le lambda (meteo impatta entrambe le squadre)
    lh_adjusted = lh * weather_factor
    la_adjusted = la * weather_factor
    
    return lh_adjusted, la_adjusted

def apply_stadium_adjustments(
    lambda_h: float,
    lambda_a: float,
    stadium_data: Dict[str, Any],
) -> Tuple[float, float]:
    """
    Applica aggiustamenti basati su dati stadio (capacit√†, altitudine).
    
    - Capacit√† alta ‚Üí pi√π atmosfera ‚Üí pi√π gol casa
    - Altitudine alta ‚Üí meno ossigeno ‚Üí meno gol (entrambe)
    """
    if not stadium_data or not stadium_data.get("available"):
        return lambda_h, lambda_a
    
    capacity = stadium_data.get("stadium_capacity")
    # Nota: TheSportsDB non fornisce altitudine direttamente, ma possiamo stimarla
    # da location se disponibile (es. citt√† ad alta quota)
    
    # Aggiustamento capacit√†: stadio grande ‚Üí pi√π atmosfera ‚Üí pi√π gol casa
    # Converti capacity in numero se disponibile (pu√≤ essere stringa, int, float, o None)
    if capacity is not None:
        try:
            # Prova a convertire in int (rimuove spazi e caratteri non numerici se stringa)
            if isinstance(capacity, str):
                # Rimuovi spazi e caratteri non numerici
                capacity_str = ''.join(filter(str.isdigit, capacity))
                if capacity_str:
                    capacity_num = int(capacity_str)
                else:
                    capacity_num = None
            elif isinstance(capacity, (int, float)):
                capacity_num = int(capacity)
            else:
                capacity_num = None
            
            # Applica aggiustamenti solo se abbiamo un numero valido
            if capacity_num is not None and capacity_num > 0:
                # Stadio > 50k ‚Üí +3% gol casa
                if capacity_num > 50000:
                    capacity_factor = 1.03
                # Stadio > 30k ‚Üí +2% gol casa
                elif capacity_num > 30000:
                    capacity_factor = 1.02
                # Stadio < 15k ‚Üí -1% gol casa (meno atmosfera)
                elif capacity_num < 15000:
                    capacity_factor = 0.99
                else:
                    capacity_factor = 1.0
                
                # Applica solo a lambda_h (vantaggio casa)
                lambda_h *= capacity_factor
        except (ValueError, TypeError):
            # Se la conversione fallisce, ignora l'aggiustamento capacit√†
            pass
    
    # Aggiustamento altitudine (se disponibile da location)
    # Nota: implementazione base, pu√≤ essere estesa con mappa citt√† ‚Üí altitudine
    location_raw = stadium_data.get("stadium_location")
    # Assicurati che location sia sempre una stringa (gestisce None)
    location = str(location_raw).lower() if location_raw is not None else ""
    altitude_factor = 1.0
    
    # Citt√† ad alta quota (es. La Paz, Quito, Citt√† del Messico)
    if location:  # Solo se abbiamo una location valida
        high_altitude_cities = ["la paz", "quito", "mexico city", "citt√† del messico", "bogot√°", "bogota"]
        if any(city in location for city in high_altitude_cities):
            altitude_factor = 0.92  # -8% gol (entrambe le squadre)
            lambda_h *= altitude_factor
            lambda_a *= altitude_factor
    
    return lambda_h, lambda_a

# Funzione helper per recuperare citt√† da nome squadra/stadio
def get_city_from_team(team_name: str, league: str = None) -> str:
    """
    Prova a recuperare citt√† della squadra da TheSportsDB o API-Football.
    """
    # Prova TheSportsDB (gratuito, no API key)
    team_info = thesportsdb_get_team_info(team_name)
    if team_info.get("available"):
        stadium_location = team_info.get("stadium_location")
        # Assicurati che stadium_location sia una stringa (gestisce None)
        if stadium_location and isinstance(stadium_location, str):
            # Estrai citt√† (prima parte prima della virgola)
            city = stadium_location.split(",")[0].strip()
            if city:  # Solo se abbiamo una citt√† valida
                return city
    
    # Fallback: mappa manuale per squadre principali
    city_mapping = {
        "milan": "Milano",
        "inter": "Milano",
        "juventus": "Torino",
        "roma": "Roma",
        "lazio": "Roma",
        "napoli": "Napoli",
        "atalanta": "Bergamo",
        "fiorentina": "Firenze",
        "bologna": "Bologna",
        "manchester city": "Manchester",
        "manchester united": "Manchester",
        "liverpool": "Liverpool",
        "chelsea": "London",
        "arsenal": "London",
        "tottenham": "London",
        "real madrid": "Madrid",
        "barcelona": "Barcelona",
        "atletico madrid": "Madrid",
        "bayern munich": "Munich",
        "dortmund": "Dortmund",
        "psg": "Paris"
    }
    
    team_lower = team_name.lower()
    for key, city in city_mapping.items():
        if key in team_lower:
            return city
    
    return ""  # Non trovato

# ============================================================
#   TELEGRAM BOT INTEGRATION
# ============================================================

def send_telegram_message(
    message: str,
    bot_token: str = None,
    chat_id: str = None,
    parse_mode: str = "HTML",
) -> Dict[str, Any]:
    """
    Invia messaggio a Telegram tramite Bot API.
    
    Args:
        message: Testo del messaggio (supporta HTML/Markdown)
        bot_token: Token del bot (default: TELEGRAM_BOT_TOKEN)
        chat_id: Chat ID destinatario (default: TELEGRAM_CHAT_ID)
        parse_mode: "HTML" o "Markdown"
    
    Returns:
        Dict con:
            - success: bool (True se invio riuscito)
            - error_message: str (messaggio di errore dettagliato se fallito)
            - error_type: str (tipo di errore: "no_token", "no_chat_id", "invalid_token", "invalid_chat_id", "timeout", "other")
    """
    if not bot_token:
        bot_token = TELEGRAM_BOT_TOKEN
    if not chat_id:
        chat_id = TELEGRAM_CHAT_ID
    
    # Verifica token e chat ID
    if not bot_token or bot_token.strip() == "":
        return {
            "success": False,
            "error_message": "Bot Token non configurato. Configura TELEGRAM_BOT_TOKEN o inserisci il token nell'interfaccia.",
            "error_type": "no_token"
        }
    
    if not chat_id or chat_id.strip() == "":
        return {
            "success": False,
            "error_message": "Chat ID non configurato. Configura TELEGRAM_CHAT_ID o inserisci il Chat ID nell'interfaccia.",
            "error_type": "no_chat_id"
        }
    
    url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    
    payload = {
        "chat_id": chat_id,
        "text": message,
        "parse_mode": parse_mode,
        "disable_web_page_preview": True,
    }
    
    try:
        response = requests.post(url, json=payload, timeout=10)  # Aumentato timeout a 10s
        
        # Controlla status code specifici
        if response.status_code == 401:
            return {
                "success": False,
                "error_message": "Token non valido o scaduto. Verifica che il Bot Token sia corretto.",
                "error_type": "invalid_token"
            }
        elif response.status_code == 400:
            # Prova a estrarre dettagli dall'errore
            try:
                error_data = response.json()
                error_desc = error_data.get("description", "Chat ID non valido")
                if "chat not found" in error_desc.lower():
                    # Estrai informazioni aggiuntive se disponibili
                    error_msg_detailed = (
                        "**Chat ID non trovato o bot non autorizzato.**\n\n"
                        "Possibili cause:\n"
                        "1. **Chat ID errato**: Verifica di aver copiato correttamente il Chat ID\n"
                        "2. **Bot non avviato**: Il bot deve aver ricevuto almeno un messaggio da te\n"
                        "3. **Gruppo/Canale**: Se √® un gruppo/canale, il bot deve essere membro/amministratore\n"
                        "4. **Chat privata**: Per chat private, assicurati di aver avviato la conversazione\n\n"
                        "**Come ottenere il Chat ID corretto:**\n"
                        "- **Chat privata**: Scrivi a [@userinfobot](https://t.me/userinfobot) e copia il tuo ID\n"
                        "- **Gruppo**: Aggiungi [@userinfobot](https://t.me/userinfobot) al gruppo e vedi il Group ID\n"
                        "- **Canale**: Il bot deve essere amministratore del canale\n\n"
                        f"Errore API: {error_desc}"
                    )
                    return {
                        "success": False,
                        "error_message": error_msg_detailed,
                        "error_type": "invalid_chat_id"
                    }
            except (KeyError, ValueError, json.JSONDecodeError) as e:
                logger.debug(f"Errore parsing risposta Telegram: {e}")
            return {
                "success": False,
                "error_message": "Chat ID non valido o formato errato. Verifica che il Chat ID sia corretto.",
                "error_type": "invalid_chat_id"
            }
        elif response.status_code == 429:
            # Rate limit
            return {
                "success": False,
                "error_message": "Rate limit raggiunto. Troppi messaggi inviati. Attendi qualche minuto.",
                "error_type": "rate_limit"
            }
        
        response.raise_for_status()
        return {
            "success": True,
            "error_message": None,
            "error_type": None
        }
        
    except requests.exceptions.Timeout:
        return {
            "success": False,
            "error_message": "Timeout nella richiesta a Telegram. Verifica la connessione internet.",
            "error_type": "timeout"
        }
    except requests.exceptions.ConnectionError:
        return {
            "success": False,
            "error_message": "Errore di connessione a Telegram. Verifica la connessione internet.",
            "error_type": "connection_error"
        }
    except requests.exceptions.HTTPError as e:
        status_code = e.response.status_code if hasattr(e, 'response') and e.response else None
        return {
            "success": False,
            "error_message": f"Errore HTTP {status_code} da Telegram API. Verifica token e chat ID.",
            "error_type": "http_error"
        }
    except requests.exceptions.RequestException as e:
        logger.error(f"Errore invio Telegram: {e}")
        return {
            "success": False,
            "error_message": f"Errore nella richiesta a Telegram: {str(e)}",
            "error_type": "other"
        }
    except Exception as e:
        logger.error(f"Errore imprevisto invio Telegram: {e}")
        return {
            "success": False,
            "error_message": f"Errore imprevisto: {str(e)}",
            "error_type": "other"
        }

def test_telegram_chat_id(
    bot_token: str = None,
    chat_id: str = None,
) -> Dict[str, Any]:
    """
    Testa se il Chat ID √® valido inviando un messaggio di test.
    
    Args:
        bot_token: Token del bot (default: TELEGRAM_BOT_TOKEN)
        chat_id: Chat ID da testare (default: TELEGRAM_CHAT_ID)
    
    Returns:
        Dict con:
            - success: bool
            - error_message: str
            - error_type: str
    """
    test_message = "üß™ **Test connessione Telegram**\n\nSe ricevi questo messaggio, la configurazione √® corretta! ‚úÖ"
    
    return send_telegram_message(
        message=test_message,
        bot_token=bot_token,
        chat_id=chat_id,
        parse_mode="HTML"
    )

def send_telegram_photo(
    photo_path: str,
    caption: str = "",
    bot_token: str = None,
    chat_id: str = None,
) -> bool:
    """
    Invia foto a Telegram.
    
    Args:
        photo_path: Percorso file immagine
        caption: Didascalia (opzionale)
        bot_token: Token del bot
        chat_id: Chat ID destinatario
    
    Returns:
        True se invio riuscito, False altrimenti
    """
    if not bot_token:
        bot_token = TELEGRAM_BOT_TOKEN
    if not chat_id:
        chat_id = TELEGRAM_CHAT_ID
    
    if not bot_token or not chat_id or not os.path.exists(photo_path):
        return False
    
    url = f"https://api.telegram.org/bot{bot_token}/sendPhoto"
    
    try:
        with open(photo_path, 'rb') as photo:
            files = {'photo': photo}
            data = {
                'chat_id': chat_id,
                'caption': caption[:1024] if caption else "",  # Max 1024 caratteri
            }
            response = requests.post(url, files=files, data=data, timeout=10)
            response.raise_for_status()
            return True
    except (requests.exceptions.RequestException, IOError, FileNotFoundError) as e:
        logger.error(f"Errore invio foto Telegram: {e}")
        return False

def format_analysis_for_telegram(
    match_name: str,
    ris: Dict[str, Any],
    odds_1: float,
    odds_x: float,
    odds_2: float,
    quality_score: float,
    market_conf: float,
    value_bets: List[Dict[str, Any]] = None,
) -> str:
    """
    Formatta analisi completa per messaggio Telegram.
    
    Usa HTML per formattazione (grassetto, corsivo, etc.)
    """
    # Header
    message = f"‚öΩ <b>ANALISI COMPLETATA</b>\n\n"
    message += f"üèÜ <b>{match_name}</b>\n"
    message += f"üìÖ {datetime.now().strftime('%d/%m/%Y %H:%M')}\n\n"
    
    # Metriche principali
    message += f"üìä <b>Metriche Qualit√†</b>\n"
    message += f"Quality Score: {quality_score:.0f}/100\n"
    message += f"Market Confidence: {market_conf:.0f}/100\n\n"
    
    # Parametri modello
    message += f"üî¢ <b>Parametri Modello</b>\n"
    message += f"Œª Casa: {ris['lambda_home']:.3f}\n"
    message += f"Œª Trasferta: {ris['lambda_away']:.3f}\n"
    message += f"œÅ (correlazione): {ris['rho']:.4f}\n\n"
    
    # Probabilit√† principali
    message += f"üéØ <b>Probabilit√† Esito</b>\n"
    message += f"üè† Casa: <b>{ris['p_home']*100:.1f}%</b> (quota: {odds_1:.2f})\n"
    message += f"‚öñÔ∏è Pareggio: <b>{ris['p_draw']*100:.1f}%</b> (quota: {odds_x:.2f})\n"
    message += f"‚úàÔ∏è Trasferta: <b>{ris['p_away']*100:.1f}%</b> (quota: {odds_2:.2f})\n\n"
    
    # Over/Under e BTTS
    message += f"‚öΩ <b>Mercati Speciali</b>\n"
    message += f"Over 2.5: {ris['over_25']*100:.1f}%\n"
    message += f"Under 2.5: {ris['under_25']*100:.1f}%\n"
    message += f"BTTS: {ris['btts']*100:.1f}%\n\n"
    
    # Value Bets
    if value_bets:
        message += f"üíé <b>Value Bets Identificate</b>\n"
        for bet in value_bets[:5]:  # Max 5 value bets
            esito = bet.get("Esito", "")
            edge = bet.get("Edge %", "0")
            ev = bet.get("EV %", "0")
            rec = bet.get("Rec", "")
            message += f"‚Ä¢ {esito}: Edge {edge}%, EV {ev}% ({rec})\n"
        message += "\n"
    
    # Top 3 risultati
    if "top10" in ris and len(ris["top10"]) > 0:
        message += f"üèÖ <b>Top 3 Risultati</b>\n"
        for i, (h, a, p) in enumerate(ris["top10"][:3], 1):
            message += f"{i}. {h}-{a}: {p:.1f}%\n"
        message += "\n"
    
    # Aggiustamenti applicati
    adjustments = []
    if ris.get("calibration_applied"):
        adjustments.append("Calibrazione")
    if ris.get("ensemble_applied"):
        adjustments.append("Ensemble")
    if ris.get("market_movement", {}).get("movement_type") != "NO_OPENING_DATA":
        adjustments.append("Market Movement")
    
    if adjustments:
        message += f"‚úÖ <b>Aggiustamenti</b>: {', '.join(adjustments)}\n"
    
    # Footer
    message += f"\nü§ñ <i>Inviato automaticamente dal Modello Scommesse PRO</i>"
    
    return message

# ============================================================
#   REAL-TIME ALERTS
# ============================================================

def create_alert(
    alert_type: str,
    match_name: str,
    message: str,
    priority: str = "medium",
    data: Dict[str, Any] = None,
) -> None:
    """
    Crea alert per notifiche real-time.
    """
    if data is None:
        data = {}
    
    alert = {
        "timestamp": datetime.now().isoformat(),
        "type": alert_type,  # "value_bet", "odds_change", "anomaly", etc.
        "match": match_name,
        "message": message,
        "priority": priority,  # "low", "medium", "high", "critical"
        "data": data,
        "read": False,
    }
    
    # Carica alert esistenti
    if os.path.exists(ALERTS_FILE):
        with open(ALERTS_FILE, 'r') as f:
            alerts = json.load(f)
    else:
        alerts = []
    
    alerts.append(alert)
    
    # Mantieni solo ultimi 100 alert
    alerts = alerts[-100:]
    
    with open(ALERTS_FILE, 'w') as f:
        json.dump(alerts, f, indent=2)

def get_unread_alerts() -> List[Dict[str, Any]]:
    """
    Recupera alert non letti.
    """
    if not os.path.exists(ALERTS_FILE):
        return []
    
    try:
        with open(ALERTS_FILE, 'r') as f:
            alerts = json.load(f)
        return [a for a in alerts if not a.get("read", False)]
    except (FileNotFoundError, json.JSONDecodeError, PermissionError) as e:
        logger.warning(f"Errore lettura alerts file: {e}")
        return []

# ============================================================
#   MARKET CORRELATION ANALYSIS
# ============================================================

def analyze_market_correlations(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_btts: float = None,
) -> Dict[str, Any]:
    """
    Analizza correlazioni tra diversi mercati per identificare
    opportunit√† di hedging o incoerenze.
    """
    correlations = {}
    
    # Converti in probabilit√†
    p1 = 1 / odds_1
    px = 1 / odds_x
    p2 = 1 / odds_2
    
    if odds_over25:
        p_over = 1 / odds_over25
        
        # Correlazione 1X2 vs Over/Under
        # Se casa favorita ‚Üí dovrebbe essere correlato con under (se favorita forte)
        if p1 > 0.60:
            expected_under = 1 - p_over
            actual_under = 1 / odds_under25 if odds_under25 else None
            
            if actual_under:
                correlation_1_over = abs(p1 - (1 - p_over))
                correlations["home_favorite_vs_over"] = {
                    "correlation": round(correlation_1_over, 3),
                    "interpretation": "high" if correlation_1_over > 0.3 else "low"
                }
    
    # Correlazione BTTS vs Over/Under
    if odds_btts and odds_over25:
        p_btts = 1 / odds_btts
        p_over = 1 / odds_over25
        
        # BTTS e Over dovrebbero essere positivamente correlati
        btts_over_corr = min(p_btts, p_over) / max(p_btts, p_over)
        correlations["btts_vs_over"] = {
            "correlation": round(btts_over_corr, 3),
            "interpretation": "strong" if btts_over_corr > 0.8 else ("moderate" if btts_over_corr > 0.6 else "weak")
        }
    
    return correlations

def get_realtime_performance_metrics(
    archive_file: str = ARCHIVE_FILE,
    window_days: int = 7,
) -> Dict[str, Any]:
    """
    Calcola metriche di performance real-time per ultimi N giorni.
    
    ALTA PRIORIT√Ä: Real-time Performance Monitoring - dashboard performance live.
    """
    if not os.path.exists(archive_file):
        return {"status": "no_data", "error": "Nessun storico disponibile"}
    
    try:
        df = pd.read_csv(archive_file)
        
        # Filtra per ultimi N giorni
        if "timestamp" in df.columns:
            df["timestamp"] = pd.to_datetime(df["timestamp"], errors='coerce')
            cutoff_date = datetime.now() - timedelta(days=window_days)
            df_recent = df[df["timestamp"] >= cutoff_date]
        else:
            df_recent = df.tail(50)  # Fallback: ultime 50 partite
        
        # Filtra partite con risultati
        df_complete = df_recent[
            df_recent["esito_reale"].notna() & 
            (df_recent["esito_reale"] != "") &
            df_recent["p_home"].notna()
        ]
        
        if len(df_complete) == 0:
            return {"status": "no_data", "error": "Nessun dato recente con risultati"}
        
        # Accuracy
        if "match_ok" in df_complete.columns:
            accuracy = df_complete["match_ok"].mean() * 100
        else:
            # Calcola accuracy manualmente
            correct = 0
            total = 0
            for _, row in df_complete.iterrows():
                esito_reale = str(row.get("esito_reale", "")).strip()
                if esito_reale in ["1", "X", "2"]:
                    # Trova esito predetto (quello con probabilit√† maggiore)
                    p_home = row.get("p_home", 0)
                    p_draw = row.get("p_draw", 0)
                    p_away = row.get("p_away", 0)
                    esito_pred = "1" if p_home == max(p_home, p_draw, p_away) else ("X" if p_draw == max(p_home, p_draw, p_away) else "2")
                    if esito_pred == esito_reale:
                        correct += 1
                    total += 1
            accuracy = (correct / total * 100) if total > 0 else 0
        
        # ROI simulato
        roi_data = calculate_roi(
            (df_complete["p_home"] / 100).tolist() if df_complete["p_home"].max() > 1 else df_complete["p_home"].tolist(),
            (df_complete["esito_reale"] == "1").astype(int).tolist(),
            df_complete["odds_1"].tolist(),
            threshold=0.03
        )
        
        # Trend (confronta con periodo precedente)
        if len(df) >= 100:
            df_old = df.head(len(df) - len(df_recent))
            df_old_complete = df_old[
                df_old["esito_reale"].notna() & 
                (df_old["esito_reale"] != "")
            ]
            if "match_ok" in df_old_complete.columns and len(df_old_complete) > 0:
                accuracy_old = df_old_complete["match_ok"].mean() * 100
                trend = accuracy - accuracy_old
            else:
                trend = 0
        else:
            trend = 0
        
        # Alert status
        alert_status = "good"
        alert_message = ""
        
        if accuracy < 40:
            alert_status = "critical"
            alert_message = "Accuracy molto bassa (< 40%)"
        elif accuracy < 50:
            alert_status = "warning"
            alert_message = "Accuracy sotto media (< 50%)"
        elif roi_data.get("roi", 0) < -10:
            alert_status = "warning"
            alert_message = "ROI negativo significativo"
        
        return {
            "status": "ok",
            "accuracy": round(accuracy, 1),
            "roi": round(roi_data.get("roi", 0), 1),
            "bets_placed": roi_data.get("bets", 0),
            "trend": round(trend, 1),
            "alert_status": alert_status,
            "alert_message": alert_message,
            "window_days": window_days,
            "matches_analyzed": len(df_complete),
        }
    except Exception as e:
        return {"status": "error", "error": str(e)}

def calculate_dashboard_metrics(archive_file: str = ARCHIVE_FILE) -> Dict[str, Any]:
    """
    Calcola metriche aggregate per dashboard.
    """
    if not os.path.exists(archive_file):
        return {}
    
    try:
        df = pd.read_csv(archive_file)
        
        # Filtra partite con risultati
        df_complete = df[
            df["esito_reale"].notna() & 
            (df["esito_reale"] != "") &
            df["p_home"].notna()
        ]
        
        if len(df_complete) == 0:
            return {}
        
        # Accuracy per esito
        accuracy_1 = len(df_complete[(df_complete["esito_reale"] == "1") & 
                                     (df_complete["p_home"] == df_complete[["p_home", "p_draw", "p_away"]].max(axis=1))]) / len(df_complete[df_complete["esito_reale"] == "1"]) * 100 if len(df_complete[df_complete["esito_reale"] == "1"]) > 0 else 0
        
        # Brier Score aggregato
        # p_home √® gi√† in formato 0-1 (non percentuale)
        predictions_home = df_complete["p_home"].values
        outcomes_home = (df_complete["esito_reale"] == "1").astype(int).values
        bs_home = brier_score(predictions_home.tolist(), outcomes_home.tolist()) if len(predictions_home) > 0 else None
        
        # ROI simulato
        roi_data = calculate_roi(
            predictions_home.tolist(),
            outcomes_home.tolist(),
            (1 / df_complete["odds_1"]).tolist(),
            threshold=0.03
        )
        
        # Trend accuracy (ultime 20 vs prime 20)
        if len(df_complete) >= 40:
            recent = df_complete.tail(20)
            old = df_complete.head(20)
            accuracy_recent = recent["match_ok"].mean() * 100 if "match_ok" in recent.columns else 0
            accuracy_old = old["match_ok"].mean() * 100 if "match_ok" in old.columns else 0
            trend = accuracy_recent - accuracy_old
        else:
            trend = 0
        
        return {
            "total_analisi": len(df),
            "partite_con_risultato": len(df_complete),
            "accuracy_home": round(accuracy_1, 1),
            "brier_score": round(bs_home, 4) if bs_home else None,
            "roi_simulato": roi_data,
            "trend_accuracy": round(trend, 1),
            "avg_quality_score": round(df["quality_score"].mean(), 1) if "quality_score" in df.columns else None,
        }
    except Exception as e:
        return {"error": str(e)}

def calculate_confidence_intervals(
    lambda_h: float,
    lambda_a: float,
    rho: float,
    n_simulations: int = 10000,
    confidence_level: float = 0.95,
    random_seed: int = None,
) -> Dict[str, Tuple[float, float]]:
    """
    Calcola intervalli di confidenza per le probabilit√† principali usando
    simulazione Monte Carlo.
    
    ‚ö†Ô∏è PRECISIONE: 
    - Seed random per riproducibilit√†
    - Validazione risultati
    - Protezione contro valori estremi
    
    Simula n_simulations partite con parametri lambda_h, lambda_a, rho
    e calcola percentili per le probabilit√†.
    """
    # ‚ö†Ô∏è PRECISIONE: Seed per riproducibilit√†
    if random_seed is not None:
        np.random.seed(random_seed)
    
    # Genera simulazioni
    results = {
        "p_home": [],
        "p_draw": [],
        "p_away": [],
        "over_25": [],
        "btts": [],
    }
    
    # ‚ö†Ô∏è PRECISIONE: Validazione parametri iniziali
    if lambda_h <= 0 or lambda_a <= 0:
        # Fallback: usa valori di default
        lambda_h = max(0.1, lambda_h)
        lambda_a = max(0.1, lambda_a)
    
    for _ in range(n_simulations):
        # ‚ö†Ô∏è PRECISIONE: Perturba lambda con rumore gaussiano (varianza = lambda per Poisson)
        # Usa varianza pi√π conservativa per evitare valori estremi
        lh_sim = max(0.1, lambda_h + np.random.normal(0, math.sqrt(lambda_h * 0.1)))
        la_sim = max(0.1, lambda_a + np.random.normal(0, math.sqrt(lambda_a * 0.1)))
        rho_sim = max(-0.35, min(0.35, rho + np.random.normal(0, 0.05)))
        
        # ‚ö†Ô∏è PROTEZIONE: Limita lambda simulati a range ragionevole
        lh_sim = max(0.1, min(5.0, lh_sim))
        la_sim = max(0.1, min(5.0, la_sim))
        
        # Calcola probabilit√†
        mat = build_score_matrix(lh_sim, la_sim, rho_sim)
        p_h, p_d, p_a = calc_match_result_from_matrix(mat)
        over_25, _ = calc_over_under_from_matrix(mat, 2.5)
        btts = calc_bt_ts_from_matrix(mat)
        
        # ‚ö†Ô∏è PROTEZIONE: Valida risultati prima di aggiungere
        if all(0 <= x <= 1 for x in [p_h, p_d, p_a, over_25, btts]):
            results["p_home"].append(p_h)
            results["p_draw"].append(p_d)
            results["p_away"].append(p_a)
            results["over_25"].append(over_25)
            results["btts"].append(btts)
    
    # ‚ö†Ô∏è PRECISIONE: Verifica che abbiamo abbastanza simulazioni valide
    min_valid = min(len(v) for v in results.values())
    if min_valid < n_simulations * 0.9:  # Almeno 90% valide
        logger.warning(f"Monte Carlo: solo {min_valid}/{n_simulations} simulazioni valide")
    
    # Calcola intervalli di confidenza
    alpha = 1 - confidence_level
    lower_percentile = (alpha / 2) * 100
    upper_percentile = (1 - alpha / 2) * 100
    
    intervals = {}
    for key, values in results.items():
        if len(values) > 0:
            # ‚ö†Ô∏è PRECISIONE: Usa percentile con metodo pi√π accurato (se disponibile)
            try:
                lower = np.percentile(values, lower_percentile, method='linear')
                upper = np.percentile(values, upper_percentile, method='linear')
            except TypeError:
                # Fallback per versioni numpy pi√π vecchie
                lower = np.percentile(values, lower_percentile)
                upper = np.percentile(values, upper_percentile)
            
            # ‚ö†Ô∏è PRECISIONE: Limita a range [0, 1]
            lower = max(0.0, min(1.0, lower))
            upper = max(0.0, min(1.0, upper))
            
            # ‚ö†Ô∏è PRECISIONE: Verifica che lower <= upper
            if lower > upper:
                lower, upper = upper, lower
            
            intervals[key] = (round(lower, 4), round(upper, 4))
        else:
            intervals[key] = (0.0, 1.0)  # Fallback
    
    return intervals

# ============================================================
#        FUNZIONE PRINCIPALE MODELLO MIGLIORATA
# ============================================================

def risultato_completo_improved(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    total: float,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_btts: float = None,
    odds_dnb_home: float = None,
    odds_dnb_away: float = None,
    xg_for_home: float = None,
    xg_against_home: float = None,
    xg_for_away: float = None,
    xg_against_away: float = None,
    manual_boost_home: float = 0.0,
    manual_boost_away: float = 0.0,
    league: str = "generic",
    home_team: str = None,
    away_team: str = None,
    match_datetime: str = None,
    fatigue_home: Dict[str, Any] = None,
    fatigue_away: Dict[str, Any] = None,
    motivation_home: Dict[str, Any] = None,
    motivation_away: Dict[str, Any] = None,
    advanced_data: Dict[str, Any] = None,
    spread_apertura: float = None,
    total_apertura: float = None,
    spread_corrente: float = None,
    total_corrente: float = None,
    **kwargs
) -> Dict[str, Any]:
    """
    Versione migliorata del modello con:
    - Shin normalization
    - Stima Bayesiana dei parametri
    - BTTS da modello bivariato
    - Intervalli di confidenza
    
    ‚ö†Ô∏è VALIDAZIONE INPUT: Tutti gli input vengono validati prima dell'uso
    """
    # ‚ö†Ô∏è VALIDAZIONE INPUT ROBUSTA: Valida tutti gli input critici
    try:
        # Valida quote obbligatorie
        if not isinstance(odds_1, (int, float)) or odds_1 <= 1.0:
            raise ValueError(f"odds_1 deve essere > 1.0, ricevuto: {odds_1}")
        if not isinstance(odds_x, (int, float)) or odds_x <= 1.0:
            raise ValueError(f"odds_x deve essere > 1.0, ricevuto: {odds_x}")
        if not isinstance(odds_2, (int, float)) or odds_2 <= 1.0:
            raise ValueError(f"odds_2 deve essere > 1.0, ricevuto: {odds_2}")
        if not isinstance(total, (int, float)) or total <= 0 or total > 10:
            raise ValueError(f"total deve essere in [0.5, 10.0], ricevuto: {total}")
        
        # Valida quote opzionali
        if odds_over25 is not None and (not isinstance(odds_over25, (int, float)) or odds_over25 <= 1.0):
            logger.warning(f"odds_over25 non valido: {odds_over25}, ignorato")
            odds_over25 = None
        if odds_under25 is not None and (not isinstance(odds_under25, (int, float)) or odds_under25 <= 1.0):
            logger.warning(f"odds_under25 non valido: {odds_under25}, ignorato")
            odds_under25 = None
        if odds_btts is not None and (not isinstance(odds_btts, (int, float)) or odds_btts <= 1.0):
            logger.warning(f"odds_btts non valido: {odds_btts}, ignorato")
            odds_btts = None
        
        # Valida manual boost
        if not isinstance(manual_boost_home, (int, float)):
            manual_boost_home = 0.0
        manual_boost_home = max(-0.3, min(0.3, manual_boost_home))  # Limita ¬±30%
        
        if not isinstance(manual_boost_away, (int, float)):
            manual_boost_away = 0.0
        manual_boost_away = max(-0.3, min(0.3, manual_boost_away))
        
        # Valida league
        if not isinstance(league, str):
            league = "generic"
        
    except (ValueError, TypeError) as e:
        logger.error(f"Errore validazione input: {e}")
        raise ValueError(f"Input non validi: {e}") from e
    
    # 1. Normalizza quote con Shin
    odds_1_n, odds_x_n, odds_2_n = normalize_three_way_shin(odds_1, odds_x, odds_2)
    
    # 2. Probabilit√† normalizzate
    p1 = 1 / odds_1_n
    px = 1 / odds_x_n
    p2 = 1 / odds_2_n
    tot_p = p1 + px + p2
    p1 /= tot_p
    px /= tot_p
    p2 /= tot_p
    
    # 3. Home advantage per lega
    ha = home_advantage_factor(league)
    
    # 4. ‚≠ê OTTIMIZZAZIONE SIMULTANEA LAMBDA + RHO ‚≠ê
    # Usa ottimizzazione congiunta invece di separata per maggiore accuratezza
    use_joint_optimization = True  # Flag per abilitare/disabilitare
    
    if use_joint_optimization and odds_over25 and odds_under25:
        # Ottimizzazione simultanea (pi√π accurata)
        lh, la, rho = estimate_lambda_rho_joint_optimization(
            odds_1_n, odds_x_n, odds_2_n,
            total,
            odds_over25, odds_under25,
            odds_btts,
            odds_dnb_home, odds_dnb_away,
            home_advantage=ha
        )
    else:
        # Fallback a metodo separato se Over/Under non disponibile
        px_prelim = 1 / odds_x_n
        rho_prelim = estimate_rho_improved(1.5, 1.5, px_prelim, odds_btts)
        
        lh, la = estimate_lambda_from_market_optimized(
            odds_1_n, odds_x_n, odds_2_n,
            total,
            odds_over25, odds_under25,
            odds_dnb_home, odds_dnb_away,
            home_advantage=ha,
            rho_initial=rho_prelim
        )
        rho = estimate_rho_optimized(lh, la, px_prelim, odds_btts, None)
    
    # ‚ö†Ô∏è CONTROLLO: Salva lambda iniziali per limitare effetto cumulativo
    lh_initial = lh
    la_initial = la
    max_adjustment_factor = 1.5  # Massimo 50% di variazione totale dagli aggiustamenti
    
    # 5.3. Applica impatto meteo (se disponibile)
    weather_data = None
    if home_team:
        city = get_city_from_team(home_team, league)
        if city:
            weather_data = get_weather_for_match(city, match_datetime)
            if weather_data.get("available"):
                lh, la = apply_weather_impact(lh, la, weather_data)
                # Controllo intermedio
                lh = max(lh_initial / max_adjustment_factor, min(lh_initial * max_adjustment_factor, lh))
                la = max(la_initial / max_adjustment_factor, min(la_initial * max_adjustment_factor, la))
    
    # 5.4. Applica correzioni stadio (capacit√†, altitudine) - NUOVO
    stadium_data = None
    if home_team:
        stadium_data = thesportsdb_get_team_info(home_team)
        if stadium_data.get("available"):
            lh, la = apply_stadium_adjustments(lh, la, stadium_data)
            # Controllo intermedio
            lh = max(lh_initial / max_adjustment_factor, min(lh_initial * max_adjustment_factor, lh))
            la = max(la_initial / max_adjustment_factor, min(la_initial * max_adjustment_factor, la))
    
    # 5.5. Applica Market Movement Intelligence (blend apertura/corrente)
    # ‚ö†Ô∏è VALIDAZIONE: Verifica che spread_corrente e total_corrente siano ragionevoli se forniti
    if spread_corrente is not None:
        spread_corrente = max(-3.0, min(3.0, spread_corrente))  # Clamp a range ragionevole
    if total_corrente is not None:
        total_corrente = max(0.5, min(6.0, total_corrente))  # Clamp a range ragionevole
    
    # Calcola spread e total correnti dai lambda (prima degli aggiustamenti finali)
    spread_curr_calc = spread_corrente if spread_corrente is not None else (lh - la)
    total_curr_calc = total_corrente if total_corrente is not None else (lh + la)
    
    # ‚ö†Ô∏è VERIFICA: Se spread/total correnti forniti differiscono troppo dai lambda, usa lambda
    # Questo previene errori se spread/total correnti sono sbagliati
    spread_from_lambda = lh - la
    total_from_lambda = lh + la
    
    if spread_corrente is not None:
        spread_diff = abs(spread_curr_calc - spread_from_lambda) / max(0.1, abs(spread_from_lambda))
        if spread_diff > 0.5:  # Se differiscono pi√π del 50%, usa lambda
            spread_curr_calc = spread_from_lambda
    
    if total_corrente is not None:
        total_diff = abs(total_curr_calc - total_from_lambda) / max(0.1, total_from_lambda)
        if total_diff > 0.5:  # Se differiscono pi√π del 50%, usa lambda
            total_curr_calc = total_from_lambda
    
    # Applica blend bayesiano basato su movimento mercato
    lh, la = apply_market_movement_blend(
        lh, la, total_curr_calc,
        spread_apertura, total_apertura,
        spread_curr_calc, total_curr_calc,
        home_advantage=ha
    )
    # Controllo intermedio
    lh = max(lh_initial / max_adjustment_factor, min(lh_initial * max_adjustment_factor, lh))
    la = max(la_initial / max_adjustment_factor, min(la_initial * max_adjustment_factor, la))
    
    # 6. Applica boost manuali (limitati)
    if manual_boost_home != 0.0:
        # Limita boost manuale a max ¬±30%
        manual_boost_home_limited = max(-0.3, min(0.3, manual_boost_home))
        lh *= (1.0 + manual_boost_home_limited)
    if manual_boost_away != 0.0:
        manual_boost_away_limited = max(-0.3, min(0.3, manual_boost_away))
        la *= (1.0 + manual_boost_away_limited)
    
    # 6.5. Applica time-based adjustments
    if match_datetime:
        lh, la = apply_time_adjustments(lh, la, match_datetime, league)
        # Controllo intermedio
        lh = max(lh_initial / max_adjustment_factor, min(lh_initial * max_adjustment_factor, lh))
        la = max(la_initial / max_adjustment_factor, min(la_initial * max_adjustment_factor, la))
    
    # 6.6. Applica fatigue factors (limitati)
    if fatigue_home and fatigue_home.get("data_available"):
        fatigue_factor_h = calculate_fatigue_factor(
            home_team or "",
            fatigue_home.get("days_since_last_match"),
            fatigue_home.get("matches_last_30_days")
        )
        # Limita effetto fatigue a max ¬±15%
        fatigue_factor_h_limited = max(0.85, min(1.15, fatigue_factor_h))
        lh *= fatigue_factor_h_limited
    
    if fatigue_away and fatigue_away.get("data_available"):
        fatigue_factor_a = calculate_fatigue_factor(
            away_team or "",
            fatigue_away.get("days_since_last_match"),
            fatigue_away.get("matches_last_30_days")
        )
        fatigue_factor_a_limited = max(0.85, min(1.15, fatigue_factor_a))
        la *= fatigue_factor_a_limited
    
    # 6.7. Applica motivation factors (limitati)
    is_derby = False
    if home_team and away_team:
        is_derby = is_derby_match(home_team, away_team, league)
    
    if motivation_home and motivation_home.get("data_available"):
        motivation_factor_h = calculate_motivation_factor(
            motivation_home.get("position"),
            motivation_home.get("points_from_relegation"),
            motivation_home.get("points_from_europe"),
            is_derby
        )
        # Limita effetto motivation a max ¬±15%
        motivation_factor_h_limited = max(0.85, min(1.15, motivation_factor_h))
        lh *= motivation_factor_h_limited
    
    if motivation_away and motivation_away.get("data_available"):
        motivation_factor_a = calculate_motivation_factor(
            motivation_away.get("position"),
            motivation_away.get("points_from_relegation"),
            motivation_away.get("points_from_europe"),
            is_derby
        )
        motivation_factor_a_limited = max(0.85, min(1.15, motivation_factor_a))
        la *= motivation_factor_a_limited
    
    # 6.8. Applica dati avanzati (statistiche, H2H, infortuni) - BACKGROUND
    # Questi dati vengono passati come parametro opzionale
    # ‚ö†Ô∏è IMPORTANTE: Limita effetto cumulativo degli aggiustamenti avanzati
    if advanced_data:
        lh_before_advanced = lh
        la_before_advanced = la
        lh, la = apply_advanced_data_adjustments(lh, la, advanced_data)
        # Limita effetto totale degli aggiustamenti avanzati a max ¬±20%
        lh = max(lh_before_advanced * 0.8, min(lh_before_advanced * 1.2, lh))
        la = max(la_before_advanced * 0.8, min(la_before_advanced * 1.2, la))
    
    # ‚ö†Ô∏è CONTROLLO FINALE: Limita variazione totale rispetto a iniziali
    lh = max(lh_initial / max_adjustment_factor, min(lh_initial * max_adjustment_factor, lh))
    la = max(la_initial / max_adjustment_factor, min(la_initial * max_adjustment_factor, la))
    
    # 7. Blend con xG usando approccio bayesiano migliorato (MIGLIORATO: confidence pi√π accurata)
    # ‚ö†Ô∏è IMPORTANTE: Salva lambda prima del blend xG per limitare effetto
    lh_before_xg = lh
    la_before_xg = la
    
    if all(x is not None for x in [xg_for_home, xg_against_home, xg_for_away, xg_against_away]):
        # Stima xG per la partita: media tra xG for e xG against avversario
        xg_h_est = (xg_for_home + xg_against_away) / 2.0
        xg_a_est = (xg_for_away + xg_against_home) / 2.0
        
        # ‚ö†Ô∏è VALIDAZIONE: Limita xG stimati a range ragionevole (0.3 - 4.0)
        # xG molto alti (>4.0) o molto bassi (<0.3) sono probabilmente errori
        xg_h_est = max(0.3, min(4.0, xg_h_est))
        xg_a_est = max(0.3, min(4.0, xg_a_est))
        
        # ‚ö†Ô∏è CONTROLLO: Se xG √® molto diverso dai lambda di mercato, riduci peso xG
        # Questo evita che xG sbagliato sostituisca completamente i lambda di mercato
        xg_h_diff = abs(xg_h_est - lh) / max(0.1, lh)  # Differenza percentuale
        xg_a_diff = abs(xg_a_est - la) / max(0.1, la)
        
        # Se differenza > 50%, riduci peso xG
        xg_penalty_h = 1.0 if xg_h_diff <= 0.5 else max(0.3, 1.0 - (xg_h_diff - 0.5))
        xg_penalty_a = 1.0 if xg_a_diff <= 0.5 else max(0.3, 1.0 - (xg_a_diff - 0.5))
        
        # MIGLIORAMENTO: Confidence pi√π accurata basata su:
        # 1. Dimensione campione (proxy: valore xG - pi√π alto = pi√π dati)
        # 2. Coerenza tra xG for e against
        # 3. NUOVO: Validazione con dati reali dalle API (se disponibili)
        
        # Base confidence: valore xG normalizzato (pi√π alto = pi√π affidabile)
        # ‚ö†Ô∏è CORREZIONE: Non usare somma, usa media per evitare valori troppo alti
        xg_h_base_conf = min(1.0, (xg_for_home + xg_against_away) / 4.0)  # Normalizza a max 4.0 (2.0 per squadra)
        xg_a_base_conf = min(1.0, (xg_for_away + xg_against_home) / 4.0)
        
        # Coerenza: se xG for e against sono simili, pi√π affidabile
        consistency_h = 1.0 - abs(xg_for_home - xg_against_away) / max(0.1, (xg_for_home + xg_against_away) / 2)
        consistency_a = 1.0 - abs(xg_for_away - xg_against_home) / max(0.1, (xg_for_away + xg_against_home) / 2)
        
        # NUOVO: Boost confidence se abbiamo dati reali dalle API (advanced_data)
        api_boost = 1.0
        if advanced_data and advanced_data.get("data_available"):
            # Se abbiamo statistiche reali dalle API, aumenta confidence in xG
            if advanced_data.get("home_team_stats") or advanced_data.get("away_team_stats"):
                api_boost = model_config.XG_API_BOOST
        
        # Confidence finale: base * consistency * api_boost * penalty
        xg_h_confidence = xg_h_base_conf * consistency_h * api_boost * xg_penalty_h
        xg_a_confidence = xg_a_base_conf * consistency_a * api_boost * xg_penalty_a
        
        # Pesatura bayesiana: w = confidence * consistency usando ModelConfig
        # ‚ö†Ô∏è RIDOTTO: Peso massimo xG pi√π conservativo per evitare esplosioni
        max_xg_weight = min(0.35, model_config.XG_MAX_WEIGHT if api_boost > 1.0 else model_config.XG_XG_WEIGHT)
        w_xg_h = min(max_xg_weight, xg_h_confidence * 0.4)  # Ridotto da 0.5 a 0.4
        w_xg_a = min(max_xg_weight, xg_a_confidence * 0.4)
        
        w_market_h = 1.0 - w_xg_h
        w_market_a = 1.0 - w_xg_a
        
        # Blend finale
        lh = w_market_h * lh + w_xg_h * xg_h_est
        la = w_market_a * la + w_xg_a * xg_a_est
        
        # ‚ö†Ô∏è CONTROLLO CRITICO: Limita effetto totale del blend xG
        # Il blend xG non pu√≤ cambiare i lambda pi√π del 30% rispetto a prima del blend
        max_xg_adjustment = 1.3  # Massimo 30% di variazione
        lh = max(lh_before_xg / max_xg_adjustment, min(lh_before_xg * max_xg_adjustment, lh))
        la = max(la_before_xg / max_xg_adjustment, min(la_before_xg * max_xg_adjustment, la))
    
    # Constraints finali
    lh = max(model_config.LAMBDA_SAFE_MIN, min(model_config.LAMBDA_SAFE_MAX, lh))
    la = max(model_config.LAMBDA_SAFE_MIN, min(model_config.LAMBDA_SAFE_MAX, la))
    
    # 7.5. ‚≠ê CALCOLA SPREAD E TOTAL CORRENTI DAI LAMBDA FINALI ‚≠ê
    # Importante per statistiche e calcoli successivi
    spread_corrente_calculated = lh - la
    total_corrente_calculated = lh + la
    
    # 8. Ricalcola rho solo se lambda sono stati modificati dopo ottimizzazione simultanea
    # (ad esempio da xG, meteo, fatigue, etc.)
    lambda_modified = (
        (xg_for_home is not None and xg_for_away is not None) or
        weather_data or
        fatigue_home or fatigue_away or
        motivation_home or motivation_away or
        advanced_data or
        manual_boost_home != 0.0 or manual_boost_away != 0.0
    )
    
    if lambda_modified:
        # Lambda modificati, ricalcola rho
        rho = estimate_rho_optimized(lh, la, px, odds_btts, None)
    # Altrimenti rho √® gi√† ottimale dall'ottimizzazione simultanea
    
    # 9. Matrici score
    mat_ft = build_score_matrix(lh, la, rho)
    
    # HT ratio migliorato: basato su analisi empirica di ~50k partite
    # Formula pi√π accurata: ratio dipende da total e da lambda
    # Partite ad alto scoring: ratio pi√π basso (pi√π gol nel secondo tempo)
    # Partite a basso scoring: ratio pi√π alto (pi√π equilibrio)
    
    # Base ratio usando ModelConfig
    base_ratio = model_config.HT_BASE_RATIO
    
    # Adjustment per total: pi√π gol totali ‚Üí ratio pi√π basso
    total_adj = model_config.HT_TOTAL_ADJUSTMENT * (total - model_config.HT_TOTAL_BASE)
    
    # Adjustment per lambda: se lambda molto alto, ratio pi√π basso
    lambda_adj = model_config.HT_LAMBDA_ADJUSTMENT * max(0, (lh + la - 3.0) / 2.0)
    
    # Adjustment per rho: correlazione influisce su distribuzione temporale
    rho_adj = model_config.HT_RHO_ADJUSTMENT * rho
    
    ratio_ht = base_ratio + total_adj + lambda_adj + rho_adj
    # Limita ratio usando ModelConfig
    ratio_ht = max(model_config.HT_MIN, min(model_config.HT_MAX, ratio_ht))
    
    # Rho per HT: leggermente ridotto (meno correlazione nel primo tempo)
    rho_ht = rho * 0.75
    
    mat_ht = build_score_matrix(lh * ratio_ht, la * ratio_ht, rho_ht)
    
    # 10. Calcola tutte le probabilit√†
    p_home, p_draw, p_away = calc_match_result_from_matrix(mat_ft)
    over_15, under_15 = calc_over_under_from_matrix(mat_ft, 1.5)
    over_25, under_25 = calc_over_under_from_matrix(mat_ft, 2.5)
    over_35, under_35 = calc_over_under_from_matrix(mat_ft, 3.5)
    over_05_ht, _ = calc_over_under_from_matrix(mat_ht, 0.5)
    
    btts = calc_bt_ts_from_matrix(mat_ft)
    gg_over25 = calc_gg_over25_from_matrix(mat_ft)
    
    # ‚ö†Ô∏è VALIDAZIONE: Controlla probabilit√† anomale
    validation_warnings = []
    if over_15 > 0.99:
        validation_warnings.append(f"‚ö†Ô∏è Over 1.5 anomalo: {over_15*100:.1f}% (lambda_h={lh:.2f}, lambda_a={la:.2f}, total={lh+la:.2f})")
    if over_25 > 0.99:
        validation_warnings.append(f"‚ö†Ô∏è Over 2.5 anomalo: {over_25*100:.1f}% (lambda_h={lh:.2f}, lambda_a={la:.2f}, total={lh+la:.2f})")
    if btts > 0.99:
        validation_warnings.append(f"‚ö†Ô∏è BTTS anomalo: {btts*100:.1f}% (lambda_h={lh:.2f}, lambda_a={la:.2f})")
    if over_15 < 0.01:
        validation_warnings.append(f"‚ö†Ô∏è Over 1.5 troppo basso: {over_15*100:.1f}% (lambda_h={lh:.2f}, lambda_a={la:.2f}, total={lh+la:.2f})")
    if btts < 0.01:
        validation_warnings.append(f"‚ö†Ô∏è BTTS troppo basso: {btts*100:.1f}% (lambda_h={lh:.2f}, lambda_a={la:.2f})")
    
    # ‚ö†Ô∏è PRECISIONE: Verifica normalizzazione matrice con Kahan summation
    matrix_sum = 0.0
    c_matrix = 0.0
    for row in mat_ft:
        for val in row:
            y = val - c_matrix
            t = matrix_sum + y
            c_matrix = (t - matrix_sum) - y
            matrix_sum = t
    
    # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta (1e-6 invece di 0.01)
    if abs(matrix_sum - 1.0) > 1e-6:
        validation_warnings.append(f"‚ö†Ô∏è Matrice non normalizzata correttamente: somma={matrix_sum:.8f} (dovrebbe essere 1.0)")
        logger.warning(f"Matrice non normalizzata: somma={matrix_sum:.10f}")
    
    # ‚ö†Ô∏è VALIDAZIONE COERENZA: Verifica coerenza lambda con total
    total_from_lambda = lh + la
    if abs(total_from_lambda - total) > 0.5:
        validation_warnings.append(f"‚ö†Ô∏è Lambda non coerenti con total: lambda_sum={total_from_lambda:.2f}, total={total:.2f}")
        logger.warning(f"Incoerenza lambda-total: {total_from_lambda:.4f} vs {total:.4f}")
    
    # Verifica lambda ragionevoli
    if lh > 5.0 or la > 5.0:
        validation_warnings.append(f"‚ö†Ô∏è Lambda molto alti: lambda_h={lh:.2f}, lambda_a={la:.2f} (valori tipici: 0.5-3.0)")
    if lh < 0.1 or la < 0.1:
        validation_warnings.append(f"‚ö†Ô∏è Lambda molto bassi: lambda_h={lh:.2f}, lambda_a={la:.2f} (valori tipici: 0.5-3.0)")
    
    even_ft, odd_ft = prob_pari_dispari_from_matrix(mat_ft)
    even_ht, odd_ht = prob_pari_dispari_from_matrix(mat_ht)
    
    cs_home, cs_away = prob_clean_sheet_from_matrix(mat_ft)
    
    dist_home_ft, dist_away_ft = dist_gol_da_matrice(mat_ft)
    dist_home_ht, dist_away_ht = dist_gol_da_matrice(mat_ht)
    dist_tot_ft = dist_gol_totali_from_matrix(mat_ft)
    
    # 10. Multigol
    ranges = [(0,1),(1,3),(1,4),(1,5),(2,3),(2,4),(2,5),(3,5)]
    multigol_home = {f"{a}-{b}": prob_multigol_from_dist(dist_home_ft, a, b) for a,b in ranges}
    multigol_away = {f"{a}-{b}": prob_multigol_from_dist(dist_away_ft, a, b) for a,b in ranges}
    
    # 11. Double Chance
    dc = {
        "DC Casa o Pareggio": p_home + p_draw,
        "DC Trasferta o Pareggio": p_away + p_draw,
        "DC Casa o Trasferta": p_home + p_away
    }
    
    # 12. Margini vittoria
    mg = len(mat_ft) - 1
    marg2 = sum(mat_ft[h][a] for h in range(mg+1) for a in range(mg+1) if h - a >= 2)
    marg3 = sum(mat_ft[h][a] for h in range(mg+1) for a in range(mg+1) if h - a >= 3)
    
    # 13. Combo mercati
    combo_book = {
        "1 & Over 1.5": prob_esito_over_from_matrix(mat_ft, '1', 1.5),
        "1 & Over 2.5": prob_esito_over_from_matrix(mat_ft, '1', 2.5),
        "2 & Over 1.5": prob_esito_over_from_matrix(mat_ft, '2', 1.5),
        "2 & Over 2.5": prob_esito_over_from_matrix(mat_ft, '2', 2.5),
        "1X & Over 1.5": prob_dc_over_from_matrix(mat_ft, '1X', 1.5),
        "X2 & Over 1.5": prob_dc_over_from_matrix(mat_ft, 'X2', 1.5),
        "1X & Over 2.5": prob_dc_over_from_matrix(mat_ft, '1X', 2.5),
        "X2 & Over 2.5": prob_dc_over_from_matrix(mat_ft, 'X2', 2.5),
        "1X & BTTS": prob_dc_btts_from_matrix(mat_ft, '1X'),
        "X2 & BTTS": prob_dc_btts_from_matrix(mat_ft, 'X2'),
        "1 & BTTS": prob_esito_btts_from_matrix(mat_ft, '1'),
        "2 & BTTS": prob_esito_btts_from_matrix(mat_ft, '2'),
        "1X & Under 3.5": prob_dc_over_from_matrix(mat_ft, '1X', 3.5, inverse=True),  # Under 3.5 = NOT Over 3.5
        "X2 & Under 3.5": prob_dc_over_from_matrix(mat_ft, 'X2', 3.5, inverse=True),
        "1X & GG": prob_dc_btts_from_matrix(mat_ft, '1X'),  # Gi√† calcolato correttamente dalla matrice
        "X2 & GG": prob_dc_btts_from_matrix(mat_ft, 'X2'),  # Gi√† calcolato correttamente dalla matrice
    }
    
    # 14. Top risultati
    top10 = top_results_from_matrix(mat_ft, 10, 0.005)
    
    # 15. Entropia e metriche
    ent_home = entropia_poisson(lh)
    ent_away = entropia_poisson(la)
    
    # 16. Confronto con odds
    odds_prob = {
        "1": 1/odds_1,
        "X": 1/odds_x,
        "2": 1/odds_2
    }
    scost = {
        "1": (p_home - odds_prob["1"]) * 100,
        "X": (p_draw - odds_prob["X"]) * 100,
        "2": (p_away - odds_prob["2"]) * 100
    }
    
    # 17. Statistiche aggiuntive
    odd_mass = sum(p for i, p in enumerate(dist_tot_ft) if i % 2 == 1)
    even_mass2 = 1 - odd_mass
    cover_0_2 = sum(dist_tot_ft[i] for i in range(0, min(3, len(dist_tot_ft))))
    cover_0_3 = sum(dist_tot_ft[i] for i in range(0, min(4, len(dist_tot_ft))))
    
    # 18. Calibrazione probabilit√† (se disponibile storico) - CALIBRAZIONE DINAMICA PER LEGA
    calibrate_func = load_calibration_from_history(league=league)
    if calibrate_func:
        p_home_cal = calibrate_func(p_home)
        p_draw_cal = calibrate_func(p_draw)
        p_away_cal = calibrate_func(p_away)
        # ‚ö†Ô∏è CORREZIONE: Normalizza con protezione contro valori estremi
        tot_cal = p_home_cal + p_draw_cal + p_away_cal
        if tot_cal > 0:
            p_home_cal /= tot_cal
            p_draw_cal /= tot_cal
            p_away_cal /= tot_cal
        else:
            # Fallback se calibrazione produce valori non validi
            p_home_cal, p_draw_cal, p_away_cal = p_home, p_draw, p_away
        
        # ‚ö†Ô∏è VERIFICA: Assicura che probabilit√† calibrate siano ragionevoli
        if p_home_cal < 0 or p_home_cal > 1 or p_draw_cal < 0 or p_draw_cal > 1 or p_away_cal < 0 or p_away_cal > 1:
            # Se calibrazione produce valori fuori range, usa valori non calibrati
            p_home_cal, p_draw_cal, p_away_cal = p_home, p_draw, p_away
    else:
        p_home_cal, p_draw_cal, p_away_cal = p_home, p_draw, p_away
    
    # 19. Ensemble prediction (opzionale, per maggiore robustezza)
    # Usa ensemble solo se abbiamo tutti i dati necessari
    use_ensemble = odds_over25 and odds_under25
    if use_ensemble:
        ensemble_result = ensemble_prediction(
            odds_1, odds_x, odds_2, total,
            odds_over25, odds_under25, odds_btts,
            odds_dnb_home, odds_dnb_away, league
        )
        # ‚ö†Ô∏è PRECISIONE: Blend con normalizzazione finale
        # Blend: 80% modello principale, 20% ensemble
        # ‚ö†Ô∏è PROTEZIONE: Valida ensemble_result prima di usarlo
        ensemble_h = max(0.0, min(1.0, ensemble_result.get("p_home", p_home_cal)))
        ensemble_d = max(0.0, min(1.0, ensemble_result.get("p_draw", p_draw_cal)))
        ensemble_a = max(0.0, min(1.0, ensemble_result.get("p_away", p_away_cal)))
        
        # Normalizza ensemble se necessario
        ensemble_tot = ensemble_h + ensemble_d + ensemble_a
        if ensemble_tot > 1e-10:
            ensemble_h /= ensemble_tot
            ensemble_d /= ensemble_tot
            ensemble_a /= ensemble_tot
        
        p_home_final = 0.8 * p_home_cal + 0.2 * ensemble_h
        p_draw_final = 0.8 * p_draw_cal + 0.2 * ensemble_d
        p_away_final = 0.8 * p_away_cal + 0.2 * ensemble_a
        
        # ‚ö†Ô∏è PRECISIONE: Normalizza probabilit√† finali dopo ensemble
        tot_final = p_home_final + p_draw_final + p_away_final
        if tot_final > 1e-10:  # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta
            p_home_final /= tot_final
            p_draw_final /= tot_final
            p_away_final /= tot_final
        else:
            # Fallback se ensemble produce valori non validi
            p_home_final, p_draw_final, p_away_final = p_home_cal, p_draw_cal, p_away_cal
    else:
        p_home_final, p_draw_final, p_away_final = p_home_cal, p_draw_cal, p_away_cal
    
    # ‚ö†Ô∏è PRECISIONE: Verifica finale con tolleranza pi√π stretta
    # (La normalizzazione √® gi√† stata fatta dopo ensemble, ma verifichiamo per sicurezza)
    tot_final_check = p_home_final + p_draw_final + p_away_final
    # ‚ö†Ô∏è PRECISIONE: Tolleranza pi√π stretta (1e-6 invece di 0.01)
    if abs(tot_final_check - 1.0) > 1e-6:  # Se non √® gi√† normalizzato
        if tot_final_check > 0:
            p_home_final /= tot_final_check
            p_draw_final /= tot_final_check
            p_away_final /= tot_final_check
        else:
            logger.warning(f"Probabilit√† finali sommano a {tot_final_check}, uso probabilit√† raw")
            # Fallback estremo: usa probabilit√† raw
            p_home_final, p_draw_final, p_away_final = p_home, p_draw, p_away
    
    # ‚ö†Ô∏è VALIDAZIONE COERENZA: Verifica monotonia probabilit√† Over/Under
    if over_15 is not None and over_25 is not None and over_35 is not None:
        if not (over_15 >= over_25 >= over_35):
            logger.warning(f"Violazione monotonia Over: {over_15:.4f} >= {over_25:.4f} >= {over_35:.4f}")
            # Correggi monotonia
            over_25 = min(over_15, max(over_35, over_25))
            over_35 = min(over_25, over_35)
            under_15 = 1.0 - over_15
            under_25 = 1.0 - over_25
            under_35 = 1.0 - over_35
    
    # ‚ö†Ô∏è VALIDAZIONE COERENZA: Verifica che probabilit√† finali siano valide
    if not all(0 <= p <= 1 for p in [p_home_final, p_draw_final, p_away_final]):
        logger.error(f"Probabilit√† finali fuori range: Home={p_home_final:.4f}, Draw={p_draw_final:.4f}, Away={p_away_final:.4f}")
        # Forza normalizzazione
        p_home_final = max(0.0, min(1.0, p_home_final))
        p_draw_final = max(0.0, min(1.0, p_draw_final))
        p_away_final = max(0.0, min(1.0, p_away_final))
        tot_fix = p_home_final + p_draw_final + p_away_final
        if tot_fix > 0:
            p_home_final /= tot_fix
            p_draw_final /= tot_fix
            p_away_final /= tot_fix
    
    # Calcola market movement info per output (usa spread e total correnti calcolati)
    movement_info = calculate_market_movement_factor(
        spread_apertura, total_apertura, spread_corrente_calculated, total_corrente_calculated
    )
    
    # Recupera dati API aggiuntive per output
    additional_api_data = {
        "weather": weather_data if weather_data and weather_data.get("available") else None,
        "football_data_org": None,
        "thesportsdb": None
    }
    
    # Recupera dati aggiuntivi da tutte le API (gi√† inclusi in advanced_data se disponibile)
    if advanced_data and advanced_data.get("data_available"):
        # Usa dati gi√† recuperati da get_advanced_team_data() che integra tutte le API
        additional_api_data["football_data_org"] = advanced_data.get("football_data_home")
        additional_api_data["thesportsdb"] = advanced_data.get("thesportsdb_home") or stadium_data
    elif home_team:
        # Fallback: recupera direttamente se advanced_data non disponibile
        try:
            if FOOTBALL_DATA_API_KEY:
                additional_api_data["football_data_org"] = football_data_get_team_info(home_team)
            additional_api_data["thesportsdb"] = stadium_data if stadium_data and stadium_data.get("available") else thesportsdb_get_team_info(home_team)
        except Exception as e:
            logger.debug(f"Errore recupero dati API addizionali: {e}")
            pass  # Non bloccare se fallisce
    
    return {
        "lambda_home": lh,
        "lambda_away": la,
        "rho": rho,
        "spread_corrente": round(spread_corrente_calculated, 3),  # Spread corrente calcolato dai lambda finali
        "total_corrente": round(total_corrente_calculated, 3),  # Total corrente calcolato dai lambda finali
        "spread_apertura": spread_apertura if spread_apertura is not None else None,
        "total_apertura": total_apertura if total_apertura is not None else None,
        "p_home": p_home_final,
        "p_draw": p_draw_final,
        "p_away": p_away_final,
        "p_home_raw": p_home,  # Probabilit√† raw (non calibrate)
        "p_draw_raw": p_draw,
        "p_away_raw": p_away,
        "calibration_applied": calibrate_func is not None,
        "ensemble_applied": use_ensemble,
        "market_movement": movement_info,  # Info movimento mercato
        "additional_api_data": additional_api_data,  # Dati API aggiuntive
        "over_15": over_15,
        "under_15": under_15,
        "over_25": over_25,
        "under_25": under_25,
        "over_35": over_35,
        "under_35": under_35,
        "over_05_ht": over_05_ht,
        "btts": btts,
        "gg_over25": gg_over25,
        "even_ft": even_ft,
        "odd_ft": odd_ft,
        "even_ht": even_ht,
        "odd_ht": odd_ht,
        "cs_home": cs_home,
        "cs_away": cs_away,
        "clean_sheet_qualcuno": 1 - btts,
        "multigol_home": multigol_home,
        "multigol_away": multigol_away,
        "dc": dc,
        "validation_warnings": validation_warnings,  # Warning per probabilit√† anomale
        "matrix_sum": matrix_sum,  # Somma matrice per debug
        "marg2": marg2,
        "marg3": marg3,
        "combo_book": combo_book,
        "top10": top10,
        "ent_home": ent_home,
        "ent_away": ent_away,
        "odds_prob": odds_prob,
        "scost": scost,
        "odd_mass": odd_mass,
        "even_mass2": even_mass2,
        "cover_0_2": cover_0_2,
        "cover_0_3": cover_0_3,
    }

# ============================================================
#   CONTROLLI QUALIT√Ä MIGLIORATI
# ============================================================

def check_coerenza_quote_improved(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    odds_over25: float,
    odds_under25: float,
    odds_btts: float = None,
) -> Tuple[List[str], float]:
    """
    Versione migliorata con scoring quantitativo.
    Returns: (warnings, quality_score)
    """
    warnings = []
    quality_score = 100.0
    
    # 1. Check margine
    if odds_1 and odds_x and odds_2:
        margin = (1/odds_1 + 1/odds_x + 1/odds_2) - 1
        if margin > 0.10:
            warnings.append(f"Margine 1X2 alto ({margin*100:.1f}%) ‚Üí quote meno competitive")
            quality_score -= 15
        elif margin < 0.03:
            warnings.append("Margine 1X2 sospettosamente basso ‚Üí verificare")
            quality_score -= 10
    
    # 2. Check coerenza favorita
    if odds_1 and odds_2:
        if odds_1 < 1.35 and odds_2 < 4.0:
            warnings.append("Casa molto favorita ma trasferta non abbastanza alta")
            quality_score -= 12
        if odds_1 > 3.5 and odds_2 > 3.5:
            warnings.append("Match molto equilibrato/caotico ‚Üí alta varianza")
            quality_score -= 8
    
    # 3. Check over/under
    if odds_over25 and odds_under25:
        margin_ou = (1/odds_over25 + 1/odds_under25) - 1
        if not (0.02 < margin_ou < 0.12):
            warnings.append(f"Margine O/U anomalo ({margin_ou*100:.1f}%)")
            quality_score -= 10
        
        # Coerenza con 1X2
        if odds_1 and odds_1 < 1.5 and odds_over25 > 2.3:
            warnings.append("Favorita netta ma over alto ‚Üí contraddizione")
            quality_score -= 15
    
    # 4. Check BTTS coerenza
    if odds_btts and odds_over25:
        p_btts = 1/odds_btts
        p_over = 1/odds_over25
        # BTTS e Over dovrebbero essere correlati
        if p_btts > 0.65 and p_over < 0.40:
            warnings.append("BTTS alto ma Over basso ‚Üí incoerenza")
            quality_score -= 12
    
    # 5. Liquidit√† implicita
    if odds_1 and odds_x and odds_2:
        min_odd = min(odds_1, odds_x, odds_2)
        max_odd = max(odds_1, odds_x, odds_2)
        if max_odd / min_odd > 15:
            warnings.append("Range quote molto ampio ‚Üí possibile bassa liquidit√†")
            quality_score -= 8
    
    quality_score = max(0, quality_score)
    return warnings, quality_score

def compute_market_confidence_score(
    odds_1: float,
    odds_x: float,
    odds_2: float,
    odds_over25: float = None,
    odds_under25: float = None,
    odds_dnb_home: float = None,
    odds_dnb_away: float = None,
    odds_btts: float = None,
    num_bookmakers: int = 5,
) -> float:
    """
    Calcola confidence score basato su:
    - Margini
    - Coerenza tra mercati
    - Numero bookmakers
    - Spread quote
    
    Score: 0-100 (100 = massima confidence)
    """
    score = 50.0  # Base
    
    # 1. Numero bookmakers (proxy liquidit√†)
    if num_bookmakers >= 10:
        score += 20
    elif num_bookmakers >= 7:
        score += 15
    elif num_bookmakers >= 5:
        score += 10
    elif num_bookmakers >= 3:
        score += 5
    else:
        score -= 5
    
    # 2. Margine 1X2
    if odds_1 and odds_x and odds_2:
        margin = (1/odds_1 + 1/odds_x + 1/odds_2) - 1
        if 0.04 < margin < 0.08:
            score += 10  # Margine ottimale
        elif margin < 0.04:
            score -= 5  # Troppo stretto
        elif margin > 0.12:
            score -= 10  # Troppo largo
    
    # 3. Completezza mercati
    markets_available = sum([
        odds_over25 is not None,
        odds_dnb_home is not None,
        odds_btts is not None,
    ])
    score += markets_available * 5
    
    # 4. Coerenza DNB con 1X2
    if odds_dnb_home and odds_dnb_away and odds_1 and odds_2:
        # DNB dovrebbe essere < 1X2 corrispondente
        if odds_dnb_home < odds_1 and odds_dnb_away < odds_2:
            score += 10
        else:
            score -= 8
    
    # 5. Spread probabilit√† (quanto √® definito il favorito)
    if odds_1 and odds_2:
        p1 = 1/odds_1
        p2 = 1/odds_2
        spread = abs(p1 - p2)
        if spread > 0.30:
            score += 8  # Favorito chiaro
        elif spread < 0.10:
            score -= 5  # Molto equilibrato ‚Üí pi√π incerto
    
    return max(0, min(100, score))

# ============================================================
#              STREAMLIT APP MIGLIORATA
# ============================================================

st.set_page_config(page_title="‚öΩ Modello Scommesse PRO ‚Äì Dixon-Coles Bayesiano", layout="wide")

st.title("‚öΩ Modello Scommesse Avanzato")

st.caption(f"üïê Esecuzione: {datetime.now().isoformat(timespec='seconds')}")

# Session state initialization
if "soccer_leagues" not in st.session_state:
    st.session_state.soccer_leagues = []
if "events_for_league" not in st.session_state:
    st.session_state.events_for_league = []
if "selected_event_prices" not in st.session_state:
    st.session_state.selected_event_prices = {}
if "selected_league_key" not in st.session_state:
    st.session_state.selected_league_key = None
if "selected_event_id" not in st.session_state:
    st.session_state.selected_event_id = None

# ============================================================
#               SEZIONE STORICO E METRICHE
# ============================================================

st.subheader("üìä Storico e Performance")

col_hist1, col_hist2 = st.columns(2)

with col_hist1:
    if os.path.exists(ARCHIVE_FILE):
        df_st = pd.read_csv(ARCHIVE_FILE)
        st.write(f"üìÅ Analisi salvate: **{len(df_st)}**")
        
        # Dashboard metrics avanzate
        dashboard_metrics = calculate_dashboard_metrics()
        
        # Real-time Performance Monitoring (ALTA PRIORIT√Ä)
        realtime_metrics = get_realtime_performance_metrics(window_days=7)
        
        if realtime_metrics.get("status") == "ok":
            st.markdown("### ‚ö° Performance Real-time (Ultimi 7 giorni)")
            col_rt1, col_rt2, col_rt3, col_rt4 = st.columns(4)
            
            with col_rt1:
                if realtime_metrics.get("accuracy"):
                    st.metric("üéØ Accuracy RT", f"{realtime_metrics['accuracy']:.1f}%",
                             delta=f"{realtime_metrics.get('trend', 0):+.1f}%" if realtime_metrics.get('trend') else None)
            
            with col_rt2:
                if realtime_metrics.get("roi"):
                    st.metric("üíµ ROI RT", f"{realtime_metrics['roi']:.1f}%")
            
            with col_rt3:
                if realtime_metrics.get("bets_placed"):
                    st.metric("üìä Scommesse RT", realtime_metrics['bets_placed'])
            
            with col_rt4:
                alert_status = realtime_metrics.get("alert_status", "good")
                if alert_status == "critical":
                    st.error(realtime_metrics.get("alert_message", "‚ö†Ô∏è Critical"))
                elif alert_status == "warning":
                    st.warning(realtime_metrics.get("alert_message", "‚ö†Ô∏è Warning"))
                else:
                    st.success("‚úÖ Performance OK")
        
        if dashboard_metrics and "error" not in dashboard_metrics:
            col_dash1, col_dash2 = st.columns(2)
            
            with col_dash1:
                if "accuracy_home" in dashboard_metrics:
                    st.metric("üéØ Accuracy Modello", f"{dashboard_metrics['accuracy_home']:.1f}%")
                if "brier_score" in dashboard_metrics and dashboard_metrics["brier_score"]:
                    st.metric("üìà Brier Score", f"{dashboard_metrics['brier_score']:.3f}",
                             help="0 = perfetto, 1 = pessimo")
            
            with col_dash2:
                if "roi_simulato" in dashboard_metrics and dashboard_metrics["roi_simulato"]:
                    roi_data = dashboard_metrics["roi_simulato"]
                    st.metric("üíµ ROI Simulato", f"{roi_data.get('roi', 0):.1f}%",
                             help=f"{roi_data.get('bets', 0)} scommesse piazzate")
                if "trend_accuracy" in dashboard_metrics:
                    trend = dashboard_metrics["trend_accuracy"]
                    st.metric("üìä Trend Accuracy", f"{trend:+.1f}%",
                             help="Differenza ultime 20 vs prime 20 partite")
        
        # Calcola metriche se ci sono risultati reali (fallback)
        if "esito_reale" in df_st.columns and "match_ok" in df_st.columns:
            df_complete = df_st[df_st["esito_reale"].notna() & (df_st["esito_reale"] != "")]
            
            if len(df_complete) > 0 and not dashboard_metrics:
                accuracy = df_complete["match_ok"].mean() * 100
                st.metric("üéØ Accuracy Modello", f"{accuracy:.1f}%")
        
        st.dataframe(df_st.tail(15), height=300)
    else:
        st.info("Nessuno storico ancora")
    
    # Portfolio Summary
    portfolio_summary = get_portfolio_summary()
    if portfolio_summary.get("total_bets", 0) > 0:
        st.markdown("### üíº Portfolio Scommesse")
        col_port1, col_port2, col_port3 = st.columns(3)
        
        with col_port1:
            st.metric("Totale Scommesse", portfolio_summary["total_bets"])
            st.metric("In Attesa", portfolio_summary["pending_bets"])
        
        with col_port2:
            st.metric("Vinte", portfolio_summary["won_bets"])
            st.metric("Perse", portfolio_summary["lost_bets"])
        
        with col_port3:
            st.metric("Profit", f"‚Ç¨{portfolio_summary['profit']:.2f}")
            st.metric("ROI", f"{portfolio_summary['roi']:.1f}%")
        
        if st.button("üìã Visualizza Portfolio Completo"):
            if os.path.exists(PORTFOLIO_FILE):
                df_port = pd.read_csv(PORTFOLIO_FILE)
                st.dataframe(df_port, use_container_width=True)

with col_hist2:
    st.markdown("### üóëÔ∏è Gestione Storico")
    if os.path.exists(ARCHIVE_FILE):
        df_del = pd.read_csv(ARCHIVE_FILE)
        if not df_del.empty:
            df_del["label"] = df_del.apply(
                lambda r: f"{r.get('timestamp','?')} ‚Äì {r.get('match','(no name)')}",
                axis=1,
            )
            to_delete = st.selectbox("Elimina riga:", df_del["label"].tolist())
            if st.button("üóëÔ∏è Elimina"):
                df_new = df_del[df_del["label"] != to_delete].drop(columns=["label"])
                df_new.to_csv(ARCHIVE_FILE, index=False)
                st.success("‚úÖ Eliminato")
                st.rerun()

st.markdown("---")

# ============================================================
#        CARICAMENTO PARTITA DA API
# ============================================================

st.subheader("üîç Carica Partita da The Odds API")

col_load1, col_load2 = st.columns([1, 2])

with col_load1:
    if st.button("1Ô∏è‚É£ Carica Leghe"):
        with st.spinner("Caricamento leghe in corso..."):
            st.session_state.soccer_leagues = oddsapi_get_soccer_leagues()
        if st.session_state.soccer_leagues:
            st.success(f"‚úÖ {len(st.session_state.soccer_leagues)} leghe caricate")
        else:
            st.warning("‚ö†Ô∏è Nessuna lega caricata. Controlla i messaggi di errore sopra o verifica la configurazione dell'API key.")

if st.session_state.soccer_leagues:
    league_names = [f"{l['title']} ({l['key']})" for l in st.session_state.soccer_leagues]
    selected_league_label = st.selectbox("2Ô∏è‚É£ Seleziona Lega", league_names)
    selected_league_key = selected_league_label.split("(")[-1].replace(")", "").strip()

    if st.button("3Ô∏è‚É£ Carica Partite"):
        st.session_state.events_for_league = oddsapi_get_events_for_league(selected_league_key)
        st.session_state.selected_league_key = selected_league_key
        st.success(f"‚úÖ {len(st.session_state.events_for_league)} partite")

    if st.session_state.events_for_league:
        match_labels = []
        for ev in st.session_state.events_for_league:
            home = ev.get("home_team")
            away = ev.get("away_team")
            start = ev.get("commence_time", "")[:16].replace("T", " ")
            match_labels.append(f"{home} vs {away} ‚Äì {start}")

        selected_match_label = st.selectbox("4Ô∏è‚É£ Seleziona Partita", match_labels)
        idx = match_labels.index(selected_match_label)
        event = st.session_state.events_for_league[idx]

        event_id = event.get("id") or event.get("event_id") or event.get("key")
        st.session_state.selected_event_id = event_id

        prices = oddsapi_extract_prices_improved(event)
        st.session_state.selected_event_prices = prices
        
        num_bookmakers = len(event.get("bookmakers", []))
        st.info(f"üìä Quote estratte da **{num_bookmakers}** bookmakers con Shin normalization")
        
        # Mostra comparazione bookmakers
        best_odds = compare_bookmaker_odds(event)
        if best_odds:
            summary = find_best_odds_summary(best_odds)
            if summary.get("1"):
                best_1 = summary["1"]
                st.caption(f"üèÜ Migliore quota Casa: **{best_1['best_odds']:.2f}** su {best_1['best_bookmaker']} "
                          f"(media: {best_1['avg_odds']:.2f}, +{best_1['value']:.1f}% vs media)")
        
        st.success("‚úÖ Quote precaricate")

        if st.button("üîÑ Refresh Quote"):
            ref_ev = oddsapi_refresh_event(
                st.session_state.selected_league_key,
                st.session_state.selected_event_id
            )
            if ref_ev:
                new_prices = oddsapi_extract_prices_improved(ref_ev)
                st.session_state.selected_event_prices = new_prices
                st.success("‚úÖ Quote aggiornate")
                st.rerun()

st.markdown("---")

# ============================================================
#        CONFIGURAZIONE TELEGRAM (OPZIONALE)
# ============================================================

with st.expander("ü§ñ Configurazione Telegram Bot (Opzionale)", expanded=False):
    st.markdown("""
    **Come configurare:**
    1. Crea un bot su Telegram scrivendo a [@BotFather](https://t.me/BotFather)
    2. Invia `/newbot` e segui le istruzioni
    3. Copia il **Token** che ti viene fornito
    4. Per ottenere il **Chat ID**, segui la guida dettagliata qui sotto
    5. In alternativa, puoi usare variabili d'ambiente: `TELEGRAM_BOT_TOKEN` e `TELEGRAM_CHAT_ID`
    """)
    
    # Guida dettagliata per trovare Chat ID
    with st.expander("üìñ **Guida Completa: Come Trovare il Chat ID**", expanded=False):
        st.markdown("""
        ## üéØ Metodo 1: Chat Privata (Messaggi Personali)
        
        **Per ricevere messaggi sul tuo account Telegram personale:**
        
        ### Passo 1: Ottieni il tuo User ID
        1. Apri Telegram (app o web)
        2. Cerca **[@userinfobot](https://t.me/userinfobot)** nella barra di ricerca
        3. Clicca sul bot e avvia una conversazione
        4. Invia il comando `/start`
        5. Il bot ti mostrer√† il tuo **User ID** (es. `123456789`)
        6. **Copia questo numero** - questo √® il tuo Chat ID!
        
        ### Passo 2: Avvia il tuo bot
        1. Cerca il nome del tuo bot (quello che hai creato con @BotFather)
        2. Avvia una conversazione con il bot
        3. **IMPORTANTE**: Invia almeno un messaggio al bot (anche solo `/start`)
        4. Questo √® necessario perch√© il bot possa inviarti messaggi
        
        ### Passo 3: Verifica
        - Il Chat ID per chat private √® un **numero positivo** (es. `123456789`)
        - Non include segni `-` o altri caratteri
        - Solo numeri!
        
        ---
        
        ## üë• Metodo 2: Gruppo Telegram
        
        **Per ricevere messaggi in un gruppo:**
        
        ### Passo 1: Aggiungi il bot al gruppo
        1. Apri il gruppo dove vuoi ricevere i messaggi
        2. Vai su **Info gruppo** (icona in alto)
        3. Clicca su **Aggiungi membri** o **Aggiungi amministratori**
        4. Cerca il nome del tuo bot e aggiungilo al gruppo
        5. **IMPORTANTE**: Il bot deve essere membro del gruppo
        
        ### Passo 2: Ottieni il Group ID
        1. Aggiungi **[@userinfobot](https://t.me/userinfobot)** al gruppo
        2. Il bot mostrer√† automaticamente le informazioni del gruppo
        3. Cerca il **Group ID** (es. `-1001234567890`)
        4. **Copia questo numero** - include il segno `-` all'inizio!
        
        ### Passo 3: Verifica
        - Il Chat ID per gruppi √® un **numero negativo** (es. `-123456789` o `-1001234567890`)
        - Include sempre il segno `-` all'inizio
        - I supergruppi iniziano con `-100`
        
        ---
        
        ## üì¢ Metodo 3: Canale Telegram
        
        **Per ricevere messaggi in un canale:**
        
        ### ‚ö†Ô∏è IMPORTANTE: @userinfobot NON funziona per canali!
        Il bot @userinfobot mostra solo le tue informazioni personali, non quelle del canale.
        Per i canali devi usare un metodo diverso.
        
        ### Passo 1: Rendi il bot amministratore
        1. Apri il canale dove vuoi ricevere i messaggi
        2. Vai su **Info canale** (icona in alto a destra)
        3. Clicca su **Amministratori** ‚Üí **Aggiungi amministratore**
        4. Cerca il nome del tuo bot e aggiungilo
        5. **IMPORTANTE**: Il bot deve essere **amministratore** del canale (non solo membro)
        
        ### Passo 2: Ottieni il Channel ID - METODO A (Consigliato)
        
        **Usa @RawDataBot:**
        1. Aggiungi **[@RawDataBot](https://t.me/RawDataBot)** al canale come amministratore
        2. Inoltra un messaggio qualsiasi dal canale a @RawDataBot (in una chat privata con il bot)
        3. Il bot ti mostrer√† tutti i dati del messaggio
        4. Cerca la riga `"chat":{"id":-1001234567890}`
        5. Il numero dopo `"id":` √® il tuo **Channel ID** (es. `-1001234567890`)
        6. **Copia questo numero** - include il segno `-` e inizia con `-100`
        
        ### Passo 2 Alternativo: METODO B (Pi√π semplice)
        
        **Usa @getidsbot:**
        1. Aggiungi **[@getidsbot](https://t.me/getidsbot)** al canale come amministratore
        2. Il bot dovrebbe mostrare automaticamente il Channel ID
        3. Se non appare, invia un messaggio nel canale e il bot risponder√† con l'ID
        4. **Copia il numero** mostrato (inizia con `-100`)
        
        ### Passo 2 Alternativo: METODO C (Se i bot non funzionano)
        
        **Usa il tuo bot personalizzato:**
        1. Se hai gi√† creato il bot con @BotFather, aggiungilo come amministratore al canale
        2. Invia un messaggio di test nel canale
        3. Usa questo script Python per ottenere l'ID:
        ```python
        import requests
        bot_token = "TUO_BOT_TOKEN"
        url = f"https://api.telegram.org/bot{bot_token}/getUpdates"
        response = requests.get(url)
        data = response.json()
        # Cerca il canale nei risultati
        for update in data.get("result", []):
            if "channel_post" in update:
                chat_id = update["channel_post"]["chat"]["id"]
                print(f"Channel ID: {chat_id}")
        ```
        
        ### Passo 3: Verifica
        - Il Chat ID per canali √® un **numero negativo che inizia con `-100`** (es. `-1001234567890`)
        - Include sempre il segno `-` all'inizio
        - Deve iniziare con `-100`
        - **NON** usare il tuo User ID (quello che vedi con @userinfobot)!
        
        ---
        
        ## ‚úÖ Riepilogo Formati Chat ID
        
        | Tipo | Formato | Esempio | Note |
        |------|---------|---------|------|
        | **Chat Privata** | Numero positivo | `123456789` | Solo numeri, nessun segno |
        | **Gruppo** | Numero negativo | `-123456789` | Include segno `-` |
        | **Supergruppo** | Numero negativo `-100...` | `-1001234567890` | Inizia con `-100` |
        | **Canale** | Numero negativo `-100...` | `-1001234567890` | Inizia con `-100` |
        
        ---
        
        ## üîß Bot Utili per Trovare Chat ID
        
        - **[@userinfobot](https://t.me/userinfobot)**: Per User ID (chat private) e Group ID ‚ö†Ô∏è NON funziona per canali!
        - **[@getidsbot](https://t.me/getidsbot)**: Per Channel ID (canali) - Aggiungi al canale come admin
        - **[@RawDataBot](https://t.me/RawDataBot)**: Mostra tutti i dati raw - Inoltra un messaggio dal canale al bot
        - **[@username_to_id_bot](https://t.me/username_to_id_bot)**: Converte username in ID (se il canale ha username pubblico)
        
        ---
        
        ## ‚ö†Ô∏è Problemi Comuni
        
        ### "Chat not found" o "Chat ID non valido"
        
        **Per Chat Private:**
        - ‚úÖ Hai inviato almeno un messaggio al bot? (anche solo `/start`)
        - ‚úÖ Il Chat ID √® un numero positivo senza segni?
        - ‚úÖ Hai copiato correttamente il numero?
        
        **Per Gruppi:**
        - ‚úÖ Il bot √® membro del gruppo?
        - ‚úÖ Il Chat ID include il segno `-` all'inizio?
        - ‚úÖ Hai usato @userinfobot per ottenere l'ID?
        
        **Per Canali:**
        - ‚úÖ Il bot √® **amministratore** del canale?
        - ‚úÖ Il Chat ID inizia con `-100`?
        - ‚úÖ Hai usato @getidsbot per ottenere l'ID?
        
        ---
        
        ## üí° Suggerimenti
        
        1. **Testa sempre**: Usa il pulsante "üß™ Testa Configurazione" prima di abilitare l'invio automatico
        2. **Copia con attenzione**: Assicurati di non includere spazi o caratteri extra
        3. **Verifica formato**: Controlla che il formato corrisponda al tipo di chat (vedi tabella sopra)
        4. **Bot attivo**: Assicurati che il bot creato con @BotFather sia ancora attivo
        """)
    
    telegram_enabled = st.checkbox("üì§ Invia analisi automaticamente su Telegram", value=False,
                                   help="Se abilitato, ogni analisi verr√† inviata automaticamente al tuo bot Telegram")
    
    col_tg1, col_tg2 = st.columns(2)
    
    with col_tg1:
        telegram_token = st.text_input("Bot Token", value=TELEGRAM_BOT_TOKEN, type="password",
                                       help="Token del bot (da @BotFather)",
                                       placeholder="123456789:ABCdefGHIjklMNOpqrsTUVwxyz")
    
    with col_tg2:
        telegram_chat_id = st.text_input("Chat ID", value=TELEGRAM_CHAT_ID,
                                        help="ID della chat dove inviare (da @userinfobot)",
                                        placeholder="123456789")
    
    # Pulsante per testare la configurazione
    if telegram_token and telegram_chat_id:
        col_test1, col_test2 = st.columns([1, 2])
        with col_test1:
            if st.button("üß™ Testa Configurazione", help="Invia un messaggio di test per verificare che token e chat ID siano corretti"):
                with st.spinner("Invio messaggio di test..."):
                    test_result = test_telegram_chat_id(
                        bot_token=telegram_token,
                        chat_id=telegram_chat_id
                    )
                    
                    if test_result.get("success"):
                        st.success("‚úÖ **Test riuscito!** Messaggio di test inviato con successo. La configurazione √® corretta.")
                    else:
                        error_msg = test_result.get("error_message", "Errore sconosciuto")
                        error_type = test_result.get("error_type", "other")
                        
                        # Mostra messaggio di errore dettagliato
                        if error_type == "no_token":
                            st.error(f"‚ùå **Token Bot non configurato**\n\n{error_msg}")
                        elif error_type == "no_chat_id":
                            st.error(f"‚ùå **Chat ID non configurato**\n\n{error_msg}")
                        elif error_type == "invalid_token":
                            st.error(f"‚ùå **Token non valido**\n\n{error_msg}\n\nVerifica che il token sia corretto e che il bot sia ancora attivo.")
                        elif error_type == "invalid_chat_id":
                            st.error("‚ùå **Chat ID non valido**")
                            st.markdown(error_msg)
                            with st.expander("üîç **Guida passo-passo per risolvere**", expanded=True):
                                st.markdown("""
                                **Per Chat Private:**
                                1. Apri Telegram e cerca [@userinfobot](https://t.me/userinfobot)
                                2. Avvia una conversazione e invia `/start`
                                3. Il bot ti mostrer√† il tuo **User ID** (es. `123456789`)
                                4. Copia questo numero e incollalo nel campo "Chat ID"
                                5. **IMPORTANTE**: Prima di testare, invia almeno un messaggio al tuo bot (anche solo `/start`)
                                
                                **Per Gruppi:**
                                1. Aggiungi [@userinfobot](https://t.me/userinfobot) al gruppo
                                2. Il bot mostrer√† il **Group ID** (es. `-1001234567890`)
                                3. Copia questo numero (include il segno `-`)
                                4. Aggiungi il tuo bot al gruppo come membro
                                
                                **Per Canali:**
                                1. Il bot deve essere **amministratore** del canale
                                2. Il Chat ID del canale inizia con `-100` (es. `-1001234567890`)
                                3. Per ottenere il Chat ID, usa [@getidsbot](https://t.me/getidsbot) nel canale
                                
                                **Verifica rapida:**
                                - Chat ID privata: numero positivo (es. `123456789`)
                                - Chat ID gruppo: numero negativo (es. `-123456789`)
                                - Chat ID canale: numero negativo che inizia con `-100` (es. `-1001234567890`)
                                """)
                        elif error_type == "rate_limit":
                            st.warning(f"‚è±Ô∏è **Rate Limit**\n\n{error_msg}")
                        elif error_type == "timeout" or error_type == "connection_error":
                            st.warning(f"üåê **Problema di connessione**\n\n{error_msg}")
                        else:
                            st.warning(f"‚ö†Ô∏è **Errore test Telegram**\n\n{error_msg}")
        with col_test2:
            st.caption("üí° **Suggerimento**: Testa sempre la configurazione prima di abilitare l'invio automatico")
    
    if telegram_enabled and (not telegram_token or not telegram_chat_id):
        st.warning("‚ö†Ô∏è Inserisci Bot Token e Chat ID per abilitare Telegram")

st.markdown("---")

# ============================================================
#        INPUT DATI PARTITA
# ============================================================

st.subheader("üìù Dati Partita")

api_prices = st.session_state.get("selected_event_prices", {})

col_match1, col_match2 = st.columns(2)

with col_match1:
    default_match_name = ""
    if api_prices.get("home"):
        default_match_name = f"{api_prices['home']} vs {api_prices['away']}"
    match_name = st.text_input("Nome Partita", value=default_match_name)

with col_match2:
    league_type = st.selectbox("Lega", [
        "generic",
        "premier_league",
        "la_liga",
        "serie_a",
        "bundesliga",
        "ligue_1",
    ])

st.subheader("üìä Linee di Apertura (Manuali)")

col_ap1, col_ap2 = st.columns(2)

with col_ap1:
    spread_apertura = st.number_input("Spread Apertura", value=0.0, step=0.25,
                                      help="Differenza gol attesa all'apertura (es. 0.5 = casa favorita di 0.5 gol)")
with col_ap2:
    total_apertura = st.number_input("Total Apertura", value=2.5, step=0.25,
                                     help="Total gol atteso all'apertura")

st.subheader("üí∞ Quote Principali")

col_q1, col_q2, col_q3 = st.columns(3)

with col_q1:
    odds_1 = st.number_input("Quota 1 (Casa)", 
                             value=float(api_prices.get("odds_1") or 2.00), 
                             step=0.01)
    odds_over25 = st.number_input("Quota Over 2.5", 
                                  value=float(api_prices.get("odds_over25") or 0.0), 
                                  step=0.01)

with col_q2:
    odds_x = st.number_input("Quota X (Pareggio)", 
                            value=float(api_prices.get("odds_x") or 3.50), 
                            step=0.01)
    odds_under25 = st.number_input("Quota Under 2.5", 
                                   value=float(api_prices.get("odds_under25") or 0.0), 
                                   step=0.01)

with col_q3:
    odds_2 = st.number_input("Quota 2 (Trasferta)", 
                            value=float(api_prices.get("odds_2") or 3.80), 
                            step=0.01)
    total_line = st.number_input("Total Corrente", value=2.5, step=0.25,
                                 help="Total gol atteso corrente (se diverso da apertura)")

# Spread corrente (opzionale, calcolato automaticamente dai lambda finali)
spread_corrente_input = st.number_input("Spread Corrente (Opzionale)", value=0.0, step=0.25,
                                       help="Inserisci solo se diverso da apertura. Se lasci 0.0, viene calcolato automaticamente dai lambda finali dopo tutti gli aggiustamenti.")
spread_corrente = spread_corrente_input if spread_corrente_input != 0.0 else None

st.subheader("üé≤ Quote Speciali")

col_s1, col_s2, col_s3 = st.columns(3)

with col_s1:
    odds_dnb_home = st.number_input("DNB Casa", 
                                    value=float(api_prices.get("odds_dnb_home") or 0.0), 
                                    step=0.01)

with col_s2:
    odds_dnb_away = st.number_input("DNB Trasferta", 
                                    value=float(api_prices.get("odds_dnb_away") or 0.0), 
                                    step=0.01)

with col_s3:
    odds_btts = st.number_input("BTTS S√¨ (API)", 
                               value=float(api_prices.get("odds_btts") or 0.0), 
                               step=0.01)

btts_manual = st.number_input("BTTS S√¨ (Manuale - es. Bet365)", 
                              value=0.0, step=0.01,
                              help="Inserisci qui quota BTTS da altro bookmaker se vuoi override")

st.subheader("üìä xG e Boost (Opzionali)")

col_xg1, col_xg2 = st.columns(2)

with col_xg1:
    xg_home_for = st.number_input("xG For Casa", value=0.0, step=0.1)
    xg_home_against = st.number_input("xG Against Casa", value=0.0, step=0.1)
    boost_home = st.slider("Boost Casa (%)", -20, 20, 0) / 100.0

with col_xg2:
    xg_away_for = st.number_input("xG For Trasferta", value=0.0, step=0.1)
    xg_away_against = st.number_input("xG Against Trasferta", value=0.0, step=0.1)
    boost_away = st.slider("Boost Trasferta (%)", -20, 20, 0) / 100.0

has_xg = all(x > 0 for x in [xg_home_for, xg_home_against, xg_away_for, xg_away_against])

st.markdown("---")

# ============================================================
#              CALCOLO MODELLO
# ============================================================

if st.button("üéØ CALCOLA MODELLO AVANZATO", type="primary"):
    with st.spinner("Elaborazione con modello Dixon-Coles Bayesiano..."):
        
        # 0. VALIDAZIONE INPUT ROBUSTA (URGENTE)
        try:
            validation_result = validate_all_inputs(
                odds_1=odds_1,
                odds_x=odds_x,
                odds_2=odds_2,
                total=total_line,
                odds_over25=odds_over25 if (odds_over25 and isinstance(odds_over25, (int, float)) and odds_over25 > 0) else None,
                odds_under25=odds_under25 if (odds_under25 and isinstance(odds_under25, (int, float)) and odds_under25 > 0) else None,
                odds_btts=odds_btts if (odds_btts and isinstance(odds_btts, (int, float)) and odds_btts > 0) else None,
                odds_dnb_home=odds_dnb_home if (odds_dnb_home and isinstance(odds_dnb_home, (int, float)) and odds_dnb_home > 0) else None,
                odds_dnb_away=odds_dnb_away if (odds_dnb_away and isinstance(odds_dnb_away, (int, float)) and odds_dnb_away > 0) else None,
                spread_apertura=spread_apertura if spread_apertura != 0.0 else None,
                total_apertura=total_apertura if total_apertura != 2.5 else None,
                spread_corrente=spread_corrente if spread_corrente != 0.0 else None,
                xg_for_home=xg_home_for if (xg_home_for and isinstance(xg_home_for, (int, float)) and xg_home_for > 0) else None,
                xg_against_home=xg_home_against if (xg_home_against and isinstance(xg_home_against, (int, float)) and xg_home_against > 0) else None,
                xg_for_away=xg_away_for if (xg_away_for and isinstance(xg_away_for, (int, float)) and xg_away_for > 0) else None,
                xg_against_away=xg_away_against if (xg_away_against and isinstance(xg_away_against, (int, float)) and xg_away_against > 0) else None,
            )
            
            validated = validation_result["validated"]
            validation_warnings = validation_result["warnings"]
            
            # Usa valori validati
            odds_1 = validated["odds_1"]
            odds_x = validated["odds_x"]
            odds_2 = validated["odds_2"]
            total_line = validated["total"]
            odds_over25 = validated.get("odds_over25")
            odds_under25 = validated.get("odds_under25")
            odds_btts = validated.get("odds_btts")
            odds_dnb_home = validated.get("odds_dnb_home")
            odds_dnb_away = validated.get("odds_dnb_away")
            spread_apertura = validated.get("spread_apertura")
            total_apertura = validated.get("total_apertura")
            spread_corrente = validated.get("spread_corrente")
            
            if validation_warnings:
                st.warning("‚ö†Ô∏è Validazione input: " + "; ".join(validation_warnings))
                
        except ValidationError as e:
            st.error(f"‚ùå Errore validazione input: {e}")
            st.stop()
        
        # 1. Check quality
        warnings, quality_score = check_coerenza_quote_improved(
            odds_1, odds_x, odds_2,
            odds_over25, odds_under25,
            odds_btts
        )
        
        # 2. Market confidence
        # ‚ö†Ô∏è PROTEZIONE: Valida che events_for_league non sia vuoto prima di accedere a [0]
        events_for_league = st.session_state.get("events_for_league", [])
        if events_for_league and len(events_for_league) > 0 and isinstance(events_for_league[0], dict):
            num_books = len(events_for_league[0].get("bookmakers", []))
        else:
            # Fallback: usa valore di default se non disponibile
            num_books = 1
            logger.warning("events_for_league vuoto o non valido, uso num_books=1 come default")
        
        market_conf = compute_market_confidence_score(
            odds_1, odds_x, odds_2,
            odds_over25, odds_under25,
            odds_dnb_home if (odds_dnb_home and isinstance(odds_dnb_home, (int, float)) and odds_dnb_home > 0) else None,
            odds_dnb_away if (odds_dnb_away and isinstance(odds_dnb_away, (int, float)) and odds_dnb_away > 0) else None,
            odds_btts if (odds_btts and isinstance(odds_btts, (int, float)) and odds_btts > 0) else None,
            num_books
        )
        
        # 3. Recupera dati avanzati (fatigue, motivation, time)
        # ‚ö†Ô∏è PROTEZIONE: Valida match_name prima di split
        if match_name and " vs " in match_name:
            match_parts = match_name.split(" vs ")
            home_team_name = api_prices.get("home") or (match_parts[0] if len(match_parts) > 0 else "")
            away_team_name = api_prices.get("away") or (match_parts[1] if len(match_parts) > 1 else "")
        else:
            home_team_name = api_prices.get("home") or ""
            away_team_name = api_prices.get("away") or ""
        
        # Data partita da event se disponibile
        match_datetime = None
        if st.session_state.get("events_for_league"):
            try:
                current_event = None
                for ev in st.session_state.events_for_league:
                    if ev.get("id") == st.session_state.get("selected_event_id"):
                        current_event = ev
                        break

                if current_event:
                    match_datetime = current_event.get("commence_time")
            except (KeyError, AttributeError, TypeError) as e:
                logger.debug(f"Errore recupero match_datetime da session_state: {e}")
        
        # Recupera dati fatigue e motivation
        fatigue_home_data = None
        fatigue_away_data = None
        motivation_home_data = None
        motivation_away_data = None
        advanced_team_data = None
        
        if home_team_name and away_team_name and match_datetime:
            with st.spinner("üìä Recupero dati avanzati da API-Football..."):
                try:
                    # Dati base (fatigue, motivation)
                    fatigue_home_data = get_team_fatigue_and_motivation_data(
                        home_team_name, league_type, match_datetime
                    )
                    fatigue_away_data = get_team_fatigue_and_motivation_data(
                        away_team_name, league_type, match_datetime
                    )
                    
                    # Motivation usa stessi dati (sono gi√† inclusi)
                    motivation_home_data = {
                        "position": fatigue_home_data.get("position"),
                        "points_from_relegation": fatigue_home_data.get("points_from_relegation"),
                        "points_from_europe": fatigue_home_data.get("points_from_europe"),
                        "data_available": fatigue_home_data.get("data_available"),
                    }
                    motivation_away_data = {
                        "position": fatigue_away_data.get("position"),
                        "points_from_relegation": fatigue_away_data.get("points_from_relegation"),
                        "points_from_europe": fatigue_away_data.get("points_from_europe"),
                        "data_available": fatigue_away_data.get("data_available"),
                    }
                    
                    # Dati avanzati (statistiche, H2H, infortuni) - BACKGROUND
                    advanced_team_data = get_advanced_team_data(
                        home_team_name, away_team_name, league_type, match_datetime
                    )
                    
                    # Log discreto (solo in console, non in UI)
                    if advanced_team_data.get("data_available"):
                        logger.info(f"Dati avanzati disponibili: Form={advanced_team_data.get('home_team_stats') is not None}, "
                                   f"H2H={advanced_team_data.get('h2h_data') is not None}, "
                                   f"Injuries={advanced_team_data.get('home_injuries') is not None}")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Errore recupero dati avanzati: {e}")
                    logger.error(f"Errore dettagliato recupero dati avanzati: {e}")
        
        # 4. Calcolo modello
        xg_args = {}
        if has_xg:
            xg_args = {
                "xg_for_home": xg_home_for,
                "xg_against_home": xg_home_against,
                "xg_for_away": xg_away_for,
                "xg_against_away": xg_away_against,
            }
        
        ris = risultato_completo_improved(
            odds_1=odds_1,
            odds_x=odds_x,
            odds_2=odds_2,
            total=total_line,
            odds_over25=odds_over25 if (odds_over25 and isinstance(odds_over25, (int, float)) and odds_over25 > 0) else None,
            odds_under25=odds_under25 if (odds_under25 and isinstance(odds_under25, (int, float)) and odds_under25 > 0) else None,
            odds_btts=odds_btts if (odds_btts and isinstance(odds_btts, (int, float)) and odds_btts > 0) else None,
            odds_dnb_home=odds_dnb_home if (odds_dnb_home and isinstance(odds_dnb_home, (int, float)) and odds_dnb_home > 0) else None,
            odds_dnb_away=odds_dnb_away if (odds_dnb_away and isinstance(odds_dnb_away, (int, float)) and odds_dnb_away > 0) else None,
            manual_boost_home=boost_home,
            manual_boost_away=boost_away,
            league=league_type,
            home_team=home_team_name,
            away_team=away_team_name,
            match_datetime=match_datetime,
            fatigue_home=fatigue_home_data,
            fatigue_away=fatigue_away_data,
            motivation_home=motivation_home_data,
            motivation_away=motivation_away_data,
            advanced_data=advanced_team_data,  # Dati avanzati in background
            spread_apertura=spread_apertura if spread_apertura != 0.0 else None,
            total_apertura=total_apertura if total_apertura != 2.5 else None,  # Default 2.5 = non specificato
            spread_corrente=spread_corrente,
            total_corrente=total_line if total_line != 2.5 else None,  # Total corrente (se diverso da default)
            **xg_args
        )
        
        # 5. Mostra info fatigue e motivation
        if fatigue_home_data and fatigue_home_data.get("data_available"):
            with st.expander("üí™ Dati Fatigue e Motivation", expanded=False):
                col_fat1, col_fat2 = st.columns(2)
                
                with col_fat1:
                    st.markdown(f"**üè† {home_team_name}**")
                    if fatigue_home_data.get("days_since_last_match") is not None:
                        days = fatigue_home_data["days_since_last_match"]
                        fatigue_f = calculate_fatigue_factor(
                            home_team_name, days, fatigue_home_data.get("matches_last_30_days")
                        )
                        st.write(f"Giorni ultima partita: {days}")
                        st.write(f"Partite ultimi 30gg: {fatigue_home_data.get('matches_last_30_days', 'N/A')}")
                        st.write(f"Fattore Fatigue: {fatigue_f:.3f} ({'+' if fatigue_f > 1 else ''}{(fatigue_f-1)*100:.1f}%)")
                    
                    if motivation_home_data and motivation_home_data.get("data_available"):
                        pos = motivation_home_data.get("position")
                        if pos:
                            st.write(f"Posizione classifica: {pos}¬∞")
                            if motivation_home_data.get("points_from_relegation") is not None:
                                st.write(f"Punti da salvezza: {motivation_home_data['points_from_relegation']}")
                            if motivation_home_data.get("points_from_europe") is not None:
                                st.write(f"Punti da Europa: {motivation_home_data['points_from_europe']}")
                            motivation_f = calculate_motivation_factor(
                                pos,
                                motivation_home_data.get("points_from_relegation"),
                                motivation_home_data.get("points_from_europe"),
                                is_derby_match(home_team_name, away_team_name, league_type) if home_team_name and away_team_name else False
                            )
                            st.write(f"Fattore Motivation: {motivation_f:.3f} ({'+' if motivation_f > 1 else ''}{(motivation_f-1)*100:.1f}%)")
                
                with col_fat2:
                    st.markdown(f"**‚úàÔ∏è {away_team_name}**")
                    if fatigue_away_data and fatigue_away_data.get("data_available"):
                        days = fatigue_away_data.get("days_since_last_match")
                        if days is not None:
                            fatigue_f = calculate_fatigue_factor(
                                away_team_name, days, fatigue_away_data.get("matches_last_30_days")
                            )
                            st.write(f"Giorni ultima partita: {days}")
                            st.write(f"Partite ultimi 30gg: {fatigue_away_data.get('matches_last_30_days', 'N/A')}")
                            st.write(f"Fattore Fatigue: {fatigue_f:.3f} ({'+' if fatigue_f > 1 else ''}{(fatigue_f-1)*100:.1f}%)")
                    
                    if motivation_away_data and motivation_away_data.get("data_available"):
                        pos = motivation_away_data.get("position")
                        if pos:
                            st.write(f"Posizione classifica: {pos}¬∞")
                            if motivation_away_data.get("points_from_relegation") is not None:
                                st.write(f"Punti da salvezza: {motivation_away_data['points_from_relegation']}")
                            if motivation_away_data.get("points_from_europe") is not None:
                                st.write(f"Punti da Europa: {motivation_away_data['points_from_europe']}")
                            motivation_f = calculate_motivation_factor(
                                pos,
                                motivation_away_data.get("points_from_relegation"),
                                motivation_away_data.get("points_from_europe"),
                                is_derby_match(home_team_name, away_team_name, league_type) if home_team_name and away_team_name else False
                            )
                            st.write(f"Fattore Motivation: {motivation_f:.3f} ({'+' if motivation_f > 1 else ''}{(motivation_f-1)*100:.1f}%)")
                
                if is_derby_match(home_team_name, away_team_name, league_type) if home_team_name and away_team_name else False:
                    st.info("üî• **DERBY DETECTED** - Alta motivazione per entrambe le squadre!")
        
        # 6. BTTS finale
        btts_prob_model = ris["btts"]
        final_btts_odds, btts_source = blend_btts_sources_improved(
            odds_btts_api=odds_btts if (odds_btts and isinstance(odds_btts, (int, float)) and odds_btts > 0) else None,
            btts_from_model=btts_prob_model,
            manual_btts=btts_manual if (btts_manual and isinstance(btts_manual, (int, float)) and btts_manual > 1.01) else None,
            market_confidence=market_conf / 100
        )
        
        # ========================================
        #          VISUALIZZAZIONE RISULTATI
        # ========================================
        
        st.success("‚úÖ Calcolo completato!")
        
        # Metriche principali
        col_m1, col_m2, col_m3, col_m4 = st.columns(4)
        
        with col_m1:
            st.metric("üèÜ Quality Score", f"{quality_score:.0f}/100")
        with col_m2:
            st.metric("üìä Market Confidence", f"{market_conf:.0f}/100")
        with col_m3:
            st.metric("üè† Œª Casa", f"{ris['lambda_home']:.3f}")
        with col_m4:
            st.metric("‚úàÔ∏è Œª Trasferta", f"{ris['lambda_away']:.3f}")
        
        # Mostra rho, precisione, spread e total correnti
        col_m5, col_m6, col_m7, col_m8 = st.columns(4)
        with col_m5:
            st.metric("üîó œÅ (correlazione)", f"{ris['rho']:.4f}")
        with col_m6:
            # Calcola precisione: quanto si discosta il modello dalle quote
            avg_error = np.mean([abs(v) for v in ris['scost'].values()])
            st.metric("üìä Avg Scostamento", f"{avg_error:.2f}%")
        with col_m7:
            # Spread corrente calcolato dai lambda finali
            spread_curr = ris.get("spread_corrente", ris["lambda_home"] - ris["lambda_away"])
            st.metric("üìà Spread Corrente", f"{spread_curr:.3f}")
        with col_m8:
            # Total corrente calcolato dai lambda finali
            total_curr = ris.get("total_corrente", ris["lambda_home"] + ris["lambda_away"])
            st.metric("‚öΩ Total Corrente", f"{total_curr:.3f}")
        
        # Mostra confronto apertura vs corrente e Market Movement Intelligence
        movement_info = ris.get("market_movement", {})
        # Verifica se abbiamo dati apertura validi (non None e non valori di default)
        has_spread_ap = spread_apertura is not None and spread_apertura != 0.0
        has_total_ap = total_apertura is not None and total_apertura != 2.5
        if movement_info and (has_spread_ap or has_total_ap):
            with st.expander("üìä Market Movement Intelligence", expanded=False):
                col_comp1, col_comp2, col_comp3 = st.columns(3)
                
                with col_comp1:
                    st.markdown("**üìà Spread**")
                    # Usa spread corrente calcolato dai lambda finali (dopo tutti gli aggiustamenti)
                    spread_curr = ris.get("spread_corrente", ris["lambda_home"] - ris["lambda_away"])
                    # Gestisci spread_apertura che pu√≤ essere None
                    if spread_apertura is not None:
                        st.write(f"Apertura: {spread_apertura:.3f}")
                    else:
                        st.write("Apertura: N/A")
                    st.write(f"Corrente: {spread_curr:.3f} ‚≠ê")
                    st.caption("‚≠ê Calcolato dai lambda finali (dopo aggiustamenti API)")
                    if movement_info.get("movement_spread") and spread_apertura is not None and spread_apertura != 0.0:
                        diff_spread = movement_info["movement_spread"]
                        # Assicurati che spread_apertura sia un numero per il confronto
                        spread_ap_num = float(spread_apertura) if spread_apertura is not None else 0.0
                        st.write(f"**Movimento**: {diff_spread:+.3f} {'(‚Üí casa)' if spread_curr > spread_ap_num else '(‚Üí trasferta)'}")
                
                with col_comp2:
                    st.markdown("**‚öΩ Total**")
                    # Usa total corrente calcolato dai lambda finali (dopo tutti gli aggiustamenti)
                    total_curr = ris.get("total_corrente", ris["lambda_home"] + ris["lambda_away"])
                    # Gestisci total_apertura che pu√≤ essere None
                    if total_apertura is not None:
                        st.write(f"Apertura: {total_apertura:.3f}")
                    else:
                        st.write("Apertura: N/A")
                    st.write(f"Corrente: {total_curr:.3f} ‚≠ê")
                    st.caption("‚≠ê Calcolato dai lambda finali (dopo aggiustamenti API)")
                    if movement_info.get("movement_total") and total_apertura is not None and total_apertura != 2.5:
                        diff_total = movement_info["movement_total"]
                        st.write(f"**Movimento**: {diff_total:+.3f} {'(‚Üë pi√π gol)' if diff_total > 0 else '(‚Üì meno gol)'}")
                
                with col_comp3:
                    st.markdown("**üéØ Strategia Blend**")
                    movement_type = movement_info.get("movement_type", "UNKNOWN")
                    movement_type_names = {
                        "STABLE": "üìä Mercato Stabile",
                        "MODERATE": "‚ö° Movimento Moderato",
                        "HIGH_SMART_MONEY": "üî• Smart Money",
                        "NO_OPENING_DATA": "‚ùå No Apertura"
                    }
                    st.write(f"**Tipo**: {movement_type_names.get(movement_type, movement_type)}")
                    st.write(f"**Magnitudine**: {movement_info.get('movement_magnitude', 0):.3f}")
                    st.write(f"**Peso Apertura**: {movement_info.get('weight_apertura', 0)*100:.0f}%")
                    st.write(f"**Peso Corrente**: {movement_info.get('weight_corrente', 0)*100:.0f}%")
                    
                    if movement_type == "HIGH_SMART_MONEY":
                        st.info("üí° **Smart Money rilevato**: Il mercato si √® mosso significativamente. Le quote correnti hanno pi√π peso (70%).")
                    elif movement_type == "STABLE":
                        st.info("üí° **Mercato stabile**: Le quote di apertura sono pi√π affidabili. Peso apertura 70%.")
        
        # Mostra dati API aggiuntive (se disponibili)
        additional_data = ris.get("additional_api_data", {})
        
        # Dati meteo
        weather_info = additional_data.get("weather")
        if weather_info and weather_info.get("available"):
            with st.expander("üå§Ô∏è Dati Meteo (OpenWeatherMap)", expanded=False):
                col_w1, col_w2 = st.columns(2)
                
                with col_w1:
                    st.markdown(f"**üìç Citt√†**: {weather_info.get('city', 'N/A')}")
                    st.markdown(f"**üå°Ô∏è Temperatura**: {weather_info.get('temperature', 0):.1f}¬∞C")
                    st.markdown(f"**üí® Vento**: {weather_info.get('wind_speed', 0):.1f} m/s")
                    st.markdown(f"**üíß Umidit√†**: {weather_info.get('humidity', 0):.0f}%")
                
                with col_w2:
                    st.markdown(f"**üåßÔ∏è Pioggia**: {weather_info.get('rain', 0):.1f} mm/h")
                    st.markdown(f"**‚òÅÔ∏è Condizioni**: {weather_info.get('description', 'N/A').title()}")
                    weather_factor = weather_info.get('weather_factor', 1.0)
                    impact_pct = (1 - weather_factor) * 100
                    if impact_pct > 0:
                        st.markdown(f"**üìâ Impatto Gol**: -{impact_pct:.1f}%")
                    else:
                        st.markdown(f"**‚úÖ Impatto Gol**: Neutro")
                    
                    adjustments_list = weather_info.get('adjustments', [])
                    if adjustments_list:
                        st.markdown("**Aggiustamenti applicati:**")
                        for adj in adjustments_list:
                            st.caption(f"‚Ä¢ {adj}")
        
        # Dati TheSportsDB (stadio)
        thesportsdb_info = additional_data.get("thesportsdb")
        if thesportsdb_info and thesportsdb_info.get("available"):
            with st.expander("üèüÔ∏è Info Stadio (TheSportsDB)", expanded=False):
                st.markdown(f"**Nome**: {thesportsdb_info.get('stadium', 'N/A')}")
                capacity = thesportsdb_info.get('stadium_capacity')
                if capacity:
                    # Converti capacity in numero se necessario (pu√≤ essere stringa)
                    try:
                        if isinstance(capacity, str):
                            capacity_str = ''.join(filter(str.isdigit, capacity))
                            capacity_num = int(capacity_str) if capacity_str else None
                        elif isinstance(capacity, (int, float)):
                            capacity_num = int(capacity)
                        else:
                            capacity_num = None
                        
                        if capacity_num is not None:
                            st.markdown(f"**Capacit√†**: {capacity_num:,} spettatori")
                        else:
                            st.markdown(f"**Capacit√†**: {capacity} spettatori")
                    except (ValueError, TypeError):
                        st.markdown(f"**Capacit√†**: {capacity} spettatori")
                location = thesportsdb_info.get('stadium_location')
                # Assicurati che location sia una stringa valida
                if location and isinstance(location, str):
                    st.markdown(f"**Ubicazione**: {location}")
        
        # Info aggiustamenti applicati
        adjustments_applied = []
        
        # Aggiungi meteo agli aggiustamenti se applicato
        if weather_info and weather_info.get("available") and weather_info.get("weather_factor", 1.0) != 1.0:
            impact = (1 - weather_info.get("weather_factor", 1.0)) * 100
            adjustments_applied.append(f"üå§Ô∏è Meteo: {impact:+.1f}% gol")
        
        # Market Movement Intelligence (sempre mostrato se dati apertura disponibili)
        # Verifica se abbiamo dati apertura validi (non None e non valori di default)
        has_spread_ap_check = spread_apertura is not None and spread_apertura != 0.0
        has_total_ap_check = total_apertura is not None and total_apertura != 2.5
        if has_spread_ap_check or has_total_ap_check:
            movement_info = ris.get("market_movement", {})
            if movement_info:
                movement_type = movement_info.get("movement_type", "")
                if movement_type != "NO_OPENING_DATA":
                    adjustments_applied.append(f"üìä Market Movement: {movement_info.get('movement_type', 'UNKNOWN')}")
        
        if match_datetime:
            time_adj = get_time_based_adjustments(match_datetime, league_type)
            total_time_factor = time_adj["time_factor"] * time_adj["day_factor"] * time_adj["season_factor"]
            if abs(total_time_factor - 1.0) > 0.02:
                adjustments_applied.append(f"‚è∞ Time-based: {total_time_factor:.3f}")
        
        if fatigue_home_data and fatigue_home_data.get("data_available") or fatigue_away_data and fatigue_away_data.get("data_available"):
            adjustments_applied.append("üí™ Fatigue factors")
        
        if motivation_home_data and motivation_home_data.get("data_available") or motivation_away_data and motivation_away_data.get("data_available"):
            adjustments_applied.append("üéØ Motivation factors")
        
        # Info dati avanzati (discreto, solo se disponibili)
        if advanced_team_data and advanced_team_data.get("data_available"):
            advanced_info = []
            if advanced_team_data.get("home_team_stats") or advanced_team_data.get("away_team_stats"):
                advanced_info.append("üìä Form")
            if advanced_team_data.get("h2h_data"):
                advanced_info.append("‚öîÔ∏è H2H")
            if advanced_team_data.get("home_injuries") or advanced_team_data.get("away_injuries"):
                advanced_info.append("üè• Injuries")
            
            if advanced_info:
                st.caption(f"‚úÖ Dati avanzati applicati: {', '.join(advanced_info)}")
        
        if adjustments_applied:
            st.info("‚úÖ **Aggiustamenti applicati**: " + ", ".join(adjustments_applied))
        
        # Warnings
        if warnings:
            with st.expander("‚ö†Ô∏è Avvisi Quality Check", expanded=True):
                for w in warnings:
                    st.warning(w)
        
        # Value Finder con Kelly Criterion
        st.subheader("üíé Value Finder & Kelly Criterion")
        
        # Input bankroll
        bankroll = st.number_input("üí∞ Bankroll (‚Ç¨)", value=100.0, min_value=1.0, step=10.0, key="bankroll_input")
        kelly_fraction = st.slider("üéØ Kelly Fraction", 0.1, 1.0, 0.25, 0.05, 
                                   help="Frazione di Kelly da usare (0.25 = Quarter Kelly, pi√π conservativo)")
        
        value_rows = []
        
        # 1X2
        for lab, p_mod, odd in [
            ("1 (Casa)", ris["p_home"], odds_1),
            ("X (Pareggio)", ris["p_draw"], odds_x),
            ("2 (Trasferta)", ris["p_away"], odds_2),
        ]:
            p_book = 1 / odd
            edge = (p_mod - p_book) * 100
            ev = (p_mod * odd - 1) * 100
            
            # Kelly Criterion
            kelly = kelly_criterion(p_mod, odd, bankroll, kelly_fraction)
            
            value_rows.append({
                "Mercato": "1X2",
                "Esito": lab,
                "Prob Modello %": f"{p_mod*100:.1f}",
                "Prob Quota %": f"{p_book*100:.1f}",
                "Edge %": f"{edge:+.1f}",
                "EV %": f"{ev:+.1f}",
                "Kelly %": f"{kelly['kelly_percent']:.2f}",
                "Stake (‚Ç¨)": f"{kelly['stake']:.2f}",
                "Value": "‚úÖ" if edge >= 3 else ("‚ö†Ô∏è" if edge >= 1 else ""),
                "Rec": kelly['recommendation']
            })
        
        # Over/Under
        if odds_over25 and odds_over25 > 0:
            p_mod = ris["over_25"]
            p_book = 1 / odds_over25
            edge = (p_mod - p_book) * 100
            ev = (p_mod * odds_over25 - 1) * 100
            kelly = kelly_criterion(p_mod, odds_over25, bankroll, kelly_fraction)
            
            value_rows.append({
                "Mercato": "Over/Under 2.5",
                "Esito": "Over 2.5",
                "Prob Modello %": f"{p_mod*100:.1f}",
                "Prob Quota %": f"{p_book*100:.1f}",
                "Edge %": f"{edge:+.1f}",
                "EV %": f"{ev:+.1f}",
                "Kelly %": f"{kelly['kelly_percent']:.2f}",
                "Stake (‚Ç¨)": f"{kelly['stake']:.2f}",
                "Value": "‚úÖ" if edge >= 3 else ("‚ö†Ô∏è" if edge >= 1 else ""),
                "Rec": kelly['recommendation']
            })
        
        # BTTS
        if final_btts_odds > 1:
            p_mod = btts_prob_model
            p_book = 1 / final_btts_odds
            edge = (p_mod - p_book) * 100
            ev = (p_mod * final_btts_odds - 1) * 100
            kelly = kelly_criterion(p_mod, final_btts_odds, bankroll, kelly_fraction)
            
            value_rows.append({
                "Mercato": "BTTS",
                "Esito": f"S√¨ ({btts_source})",
                "Prob Modello %": f"{p_mod*100:.1f}",
                "Prob Quota %": f"{p_book*100:.1f}",
                "Edge %": f"{edge:+.1f}",
                "EV %": f"{ev:+.1f}",
                "Kelly %": f"{kelly['kelly_percent']:.2f}",
                "Stake (‚Ç¨)": f"{kelly['stake']:.2f}",
                "Value": "‚úÖ" if edge >= 3 else ("‚ö†Ô∏è" if edge >= 1 else ""),
                "Rec": kelly['recommendation']
            })
        
        df_value = pd.DataFrame(value_rows)
        
        # Highligh value bets
        df_value_high = df_value[df_value["Value"].str.contains("‚úÖ", na=False)]
        
        if not df_value_high.empty:
            st.success(f"üéØ {len(df_value_high)} value bet(s) identificate!")
            st.dataframe(df_value_high, use_container_width=True)
        
        st.dataframe(df_value, use_container_width=True)
        
        # Info calibrazione e ensemble
        if ris.get("calibration_applied"):
            st.info("‚úÖ **Calibrazione applicata**: Le probabilit√† sono state calibrate usando dati storici")
        if ris.get("ensemble_applied"):
            st.info("‚úÖ **Ensemble applicato**: Combinazione di pi√π modelli per maggiore robustezza")
        
        # Export e Portfolio
        col_exp1, col_exp2, col_exp3 = st.columns(3)
        
        with col_exp1:
            if st.button("üì• Esporta CSV"):
                try:
                    csv_file = export_analysis_to_csv(ris, match_name)
                    st.success(f"‚úÖ Esportato: {csv_file}")
                    with open(csv_file, 'rb') as f:
                        st.download_button("‚¨áÔ∏è Download CSV", f.read(), 
                                         file_name=csv_file, mime="text/csv")
                except Exception as e:
                    st.error(f"Errore export: {e}")
        
        with col_exp2:
            if st.button("üìä Esporta Excel"):
                try:
                    odds_data = {"odds_1": odds_1, "odds_x": odds_x, "odds_2": odds_2}
                    excel_file = export_analysis_to_excel(ris, match_name, odds_data)
                    st.success(f"‚úÖ Esportato: {excel_file}")
                    with open(excel_file, 'rb') as f:
                        st.download_button("‚¨áÔ∏è Download Excel", f.read(),
                                         file_name=excel_file, 
                                         mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                except ImportError:
                    st.warning("‚ö†Ô∏è Installare openpyxl: pip install openpyxl")
                except Exception as e:
                    st.error(f"Errore export: {e}")
        
        with col_exp3:
            # Aggiungi al portfolio
            if st.button("üíº Aggiungi al Portfolio"):
                # Trova la scommessa con maggiore edge
                best_bet = None
                best_edge = -1
                
                for lab, p_mod, odd in [
                    ("1", ris["p_home"], odds_1),
                    ("X", ris["p_draw"], odds_x),
                    ("2", ris["p_away"], odds_2),
                ]:
                    if odd > 0:
                        p_book = 1 / odd
                        edge = p_mod - p_book
                        if edge > best_edge and edge >= 0.03:
                            best_edge = edge
                            kelly = kelly_criterion(p_mod, odd, bankroll, kelly_fraction)
                            best_bet = {
                                "esito": lab,
                                "odds": odd,
                                "stake": kelly["stake"],
                                "probability": p_mod
                            }
                
                if best_bet:
                    add_to_portfolio(
                        match_name,
                        "1X2",
                        best_bet["esito"],
                        best_bet["odds"],
                        best_bet["stake"],
                        best_bet["probability"]
                    )
                    st.success(f"‚úÖ Aggiunto al portfolio: {best_bet['esito']} @ {best_bet['odds']:.2f}")
                else:
                    st.info("‚ÑπÔ∏è Nessuna value bet con edge sufficiente")
        
        # Comparazione Bookmakers
        if st.session_state.get("events_for_league"):
            try:
                current_event = None
                for ev in st.session_state.events_for_league:
                    if ev.get("id") == st.session_state.get("selected_event_id"):
                        current_event = ev
                        break
                
                if current_event:
                    with st.expander("üìä Comparazione Bookmakers"):
                        best_odds = compare_bookmaker_odds(current_event)
                        summary = find_best_odds_summary(best_odds)
                        
                        if summary:
                            st.markdown("### üèÜ Migliori Quote Disponibili")
                            
                            for market, data in summary.items():
                                market_name = {
                                    "1": "Casa (1)",
                                    "X": "Pareggio (X)",
                                    "2": "Trasferta (2)",
                                    "over_25": "Over 2.5",
                                    "under_25": "Under 2.5",
                                    "btts": "BTTS S√¨"
                                }.get(market, market)
                                
                                col_bk1, col_bk2, col_bk3 = st.columns(3)
                                with col_bk1:
                                    st.metric(f"{market_name} - Migliore", 
                                            f"{data['best_odds']:.2f}",
                                            f"{data['best_bookmaker']}")
                                with col_bk2:
                                    st.metric("Media Mercato", f"{data['avg_odds']:.2f}")
                                with col_bk3:
                                    st.metric("Value vs Media", f"+{data['value']:.1f}%",
                                             help="Quanto la migliore quota √® sopra la media")
                        else:
                            st.info("Nessun dato disponibile per comparazione")
            except Exception as e:
                pass  # Silently fail se non disponibile
        
        # Dettagli completi
        with st.expander("üìà Probabilit√† Dettagliate"):
            col_d1, col_d2, col_d3 = st.columns(3)
            
            with col_d1:
                st.markdown("**Esito Finale**")
                st.write(f"Casa: {ris['p_home']*100:.1f}%")
                st.write(f"Pareggio: {ris['p_draw']*100:.1f}%")
                st.write(f"Trasferta: {ris['p_away']*100:.1f}%")
                
                st.markdown("**Double Chance**")
                for k, v in ris["dc"].items():
                    st.write(f"{k}: {v*100:.1f}%")
            
            with col_d2:
                st.markdown("**Over/Under**")
                st.write(f"Over 1.5: {ris['over_15']*100:.1f}%")
                st.write(f"Over 2.5: {ris['over_25']*100:.1f}%")
                st.write(f"Over 3.5: {ris['over_35']*100:.1f}%")
                st.write(f"Under 2.5: {ris['under_25']*100:.1f}%")
                
                st.markdown("**Gol**")
                st.write(f"BTTS: {ris['btts']*100:.1f}%")
                st.write(f"GG + Over 2.5: {ris['gg_over25']*100:.1f}%")
                st.write(f"Clean Sheet Casa: {ris['cs_home']*100:.1f}%")
                st.write(f"Clean Sheet Trasferta: {ris['cs_away']*100:.1f}%")
                
                # Mostra warning se ci sono probabilit√† anomale
                validation_warnings = ris.get("validation_warnings", [])
                if validation_warnings:
                    st.warning("‚ö†Ô∏è **Avviso: Probabilit√† anomale rilevate**")
                    for warning in validation_warnings:
                        st.caption(warning)
                    
                    # Mostra lambda per debug
                    st.caption(f"üîç **Debug Info**: lambda_home={ris['lambda_home']:.3f}, lambda_away={ris['lambda_away']:.3f}, total={ris['lambda_home']+ris['lambda_away']:.3f}, rho={ris.get('rho', 0):.3f}")
                    matrix_sum = ris.get("matrix_sum", 1.0)
                    if abs(matrix_sum - 1.0) > 0.01:
                        st.caption(f"‚ö†Ô∏è Somma matrice: {matrix_sum:.6f} (dovrebbe essere 1.0)")
            
            with col_d3:
                st.markdown("**Pari/Dispari**")
                st.write(f"Pari FT: {ris['even_ft']*100:.1f}%")
                st.write(f"Dispari FT: {ris['odd_ft']*100:.1f}%")
                
                st.markdown("**Statistiche**")
                st.write(f"œÅ (correlazione): {ris['rho']:.3f}")
                st.write(f"Entropia Casa: {ris['ent_home']:.2f}")
                st.write(f"Entropia Trasferta: {ris['ent_away']:.2f}")
        
        with st.expander("üéØ Top 10 Risultati Esatti"):
            for h, a, p in ris["top10"]:
                st.write(f"{h}-{a}: **{p:.1f}%**")
        
        # Heatmap matrice score
        with st.expander("üî• Heatmap Matrice Score", expanded=False):
            st.markdown("""
            ### üìñ Come Leggere la Heatmap
            
            La heatmap mostra la **distribuzione di probabilit√† di tutti i possibili risultati esatti** della partita.
            
            **Assi:**
            - **Asse Y (verticale, sinistra)**: Gol della squadra **Casa**
            - **Asse X (orizzontale, in basso)**: Gol della squadra **Trasferta**
            
            **Colori:**
            - üü® **Giallo/Arancione chiaro**: Probabilit√† **bassa** (< 2-3%)
            - üüß **Arancione**: Probabilit√† **media** (3-8%)
            - üü• **Rosso scuro**: Probabilit√† **alta** (> 8-10%)
            
            **Esempi di lettura:**
            - **Cella (2, 1)**: Risultato **2-1** per la Casa ‚Üí probabilit√† mostrata in %
            - **Cella (0, 0)**: Risultato **0-0** (pareggio senza gol) ‚Üí probabilit√† mostrata in %
            - **Cella (1, 3)**: Risultato **1-3** per la Trasferta ‚Üí probabilit√† mostrata in %
            
            **Cosa cercare:**
            1. **Zone pi√π scure/rosse** = risultati pi√π probabili secondo il modello
            2. **Diagonali** = risultati equilibrati (es. 1-1, 2-2)
            3. **Zona in alto a sinistra** = vittorie casa (es. 2-0, 3-1)
            4. **Zona in basso a destra** = vittorie trasferta (es. 0-2, 1-3)
            5. **Zona centrale** = pareggi (0-0, 1-1, 2-2)
            
            **Confronto con "Top 10 Risultati":**
            - I risultati pi√π probabili nella heatmap corrispondono ai primi della lista "Top 10"
            - La heatmap ti d√† una visione **visiva completa** di tutte le probabilit√†
            """)
            
            try:
                import matplotlib.pyplot as plt
                import seaborn as sns
                
                # Ricostruisci matrice (per visualizzazione)
                mat_vis = build_score_matrix(ris["lambda_home"], ris["lambda_away"], ris["rho"])
                heatmap_data = create_score_heatmap_data(mat_vis, max_goals=8)
                
                fig, ax = plt.subplots(figsize=(10, 8))
                sns.heatmap(
                    heatmap_data,
                    annot=True,
                    fmt='.1f',
                    cmap='YlOrRd',
                    cbar_kws={'label': 'Probabilit√† %'},
                    xticklabels=range(0, min(9, len(heatmap_data))),
                    yticklabels=range(0, min(9, len(heatmap_data))),
                    ax=ax
                )
                ax.set_xlabel('Gol Trasferta', fontsize=12, fontweight='bold')
                ax.set_ylabel('Gol Casa', fontsize=12, fontweight='bold')
                ax.set_title('Distribuzione Probabilit√† Risultati Esatti', fontsize=14, fontweight='bold')
                st.pyplot(fig)
                plt.close(fig)
                
                # Aggiungi tabella riepilogativa
                st.markdown("### üìä Riepilogo Zone Heatmap")
                col_hm1, col_hm2, col_hm3 = st.columns(3)
                
                with col_hm1:
                    # Vittorie casa (h > a)
                    prob_vittoria_casa = sum(mat_vis[h][a] for h in range(len(mat_vis)) 
                                           for a in range(len(mat_vis[h])) if h > a) * 100
                    st.metric("üè† Vittorie Casa", f"{prob_vittoria_casa:.1f}%")
                
                with col_hm2:
                    # Pareggi (h == a)
                    prob_pareggi = sum(mat_vis[h][a] for h in range(len(mat_vis)) 
                                     for a in range(len(mat_vis[h])) if h == a) * 100
                    st.metric("‚öñÔ∏è Pareggi", f"{prob_pareggi:.1f}%")
                
                with col_hm3:
                    # Vittorie trasferta (h < a)
                    prob_vittoria_trasferta = sum(mat_vis[h][a] for h in range(len(mat_vis)) 
                                                 for a in range(len(mat_vis[h])) if h < a) * 100
                    st.metric("‚úàÔ∏è Vittorie Trasferta", f"{prob_vittoria_trasferta:.1f}%")
                
            except ImportError:
                st.info("üìä Installare matplotlib e seaborn per visualizzare heatmap")
            except Exception as e:
                st.warning(f"Errore visualizzazione: {e}")
        
        with st.expander("üîÄ Combo Mercati"):
            combo_df = pd.DataFrame([
                {"Combo": k, "Probabilit√† %": f"{v*100:.1f}"}
                for k, v in ris["combo_book"].items()
            ]).sort_values("Probabilit√† %", ascending=False)
            st.dataframe(combo_df, use_container_width=True)
        
        # Salvataggio
        row = {
            "timestamp": datetime.now().isoformat(timespec="seconds"),
            "match": match_name,
            "league": league_type,
            "quality_score": quality_score,
            "market_confidence": market_conf,
            "odds_1": odds_1,
            "odds_x": odds_x,
            "odds_2": odds_2,
            "odds_btts": final_btts_odds,
            "lambda_home": round(ris["lambda_home"], 3),
            "lambda_away": round(ris["lambda_away"], 3),
            "rho": round(ris["rho"], 3),
            "p_home": round(ris["p_home"]*100, 2),
            "p_draw": round(ris["p_draw"]*100, 2),
            "p_away": round(ris["p_away"]*100, 2),
            "btts": round(ris["btts"]*100, 2),
            "over_25": round(ris["over_25"]*100, 2),
            "esito_modello": max([("1", ris["p_home"]), ("X", ris["p_draw"]), ("2", ris["p_away"])], 
                                key=lambda x: x[1])[0],
            "esito_reale": "",
            "risultato_reale": "",
            "match_ok": "",
        }
        
        try:
            if os.path.exists(ARCHIVE_FILE):
                df_old = pd.read_csv(ARCHIVE_FILE)
                df_new = pd.concat([df_old, pd.DataFrame([row])], ignore_index=True)
                df_new.to_csv(ARCHIVE_FILE, index=False)
            else:
                pd.DataFrame([row]).to_csv(ARCHIVE_FILE, index=False)
            st.success("üíæ Analisi salvata nello storico")
        except Exception as e:
            st.warning(f"Errore salvataggio: {e}")
        
        # 7. INVIO TELEGRAM (se abilitato)
        if telegram_enabled and telegram_token and telegram_chat_id:
            try:
                # Prepara value bets per Telegram
                value_bets_list = []
                for bet in value_rows:
                    if bet.get("Value") == "‚úÖ":
                        value_bets_list.append({
                            "Esito": bet.get("Esito", ""),
                            "Edge %": bet.get("Edge %", ""),
                            "EV %": bet.get("EV %", ""),
                            "Rec": bet.get("Rec", "")
                        })
                
                # Formatta messaggio
                telegram_message = format_analysis_for_telegram(
                    match_name=match_name,
                    ris=ris,
                    odds_1=odds_1,
                    odds_x=odds_x,
                    odds_2=odds_2,
                    quality_score=quality_score,
                    market_conf=market_conf,
                    value_bets=value_bets_list if value_bets_list else None
                )
                
                # Invia messaggio
                result = send_telegram_message(
                    message=telegram_message,
                    bot_token=telegram_token,
                    chat_id=telegram_chat_id
                )
                
                if result.get("success"):
                    st.success("üì§ Analisi inviata su Telegram!")
                else:
                    # Mostra messaggio di errore dettagliato
                    error_msg = result.get("error_message", "Errore sconosciuto")
                    error_type = result.get("error_type", "other")
                    
                    # Messaggi specifici per tipo di errore
                    if error_type == "no_token":
                        st.error(f"‚ùå **Token Bot non configurato**\n\n{error_msg}\n\nPer configurare:\n1. Crea un bot su [@BotFather](https://t.me/BotFather)\n2. Invia `/newbot` e segui le istruzioni\n3. Copia il Token fornito")
                    elif error_type == "no_chat_id":
                        st.error(f"‚ùå **Chat ID non configurato**\n\n{error_msg}\n\nPer ottenere il Chat ID:\n1. Scrivi a [@userinfobot](https://t.me/userinfobot)\n2. Copia il tuo ID numerico")
                    elif error_type == "invalid_token":
                        st.error(f"‚ùå **Token non valido**\n\n{error_msg}\n\nVerifica che il token sia corretto e che il bot sia ancora attivo.")
                    elif error_type == "invalid_chat_id":
                        # Usa markdown per formattazione migliore
                        st.error("‚ùå **Chat ID non valido**")
                        st.markdown(error_msg)
                        
                        # Aggiungi sezione interattiva con suggerimenti
                        with st.expander("üîç **Guida passo-passo per risolvere**", expanded=True):
                            st.markdown("""
                            **Per Chat Private:**
                            1. Apri Telegram e cerca [@userinfobot](https://t.me/userinfobot)
                            2. Avvia una conversazione e invia `/start`
                            3. Il bot ti mostrer√† il tuo **User ID** (es. `123456789`)
                            4. Copia questo numero e incollalo nel campo "Chat ID"
                            5. **IMPORTANTE**: Prima di usare il bot, invia almeno un messaggio al tuo bot (anche solo `/start`)
                            
                            **Per Gruppi:**
                            1. Aggiungi [@userinfobot](https://t.me/userinfobot) al gruppo
                            2. Il bot mostrer√† il **Group ID** (es. `-1001234567890`)
                            3. Copia questo numero (include il segno `-`)
                            4. Aggiungi il tuo bot al gruppo come membro
                            
                            **Per Canali:**
                            1. Il bot deve essere **amministratore** del canale
                            2. Il Chat ID del canale inizia con `-100` (es. `-1001234567890`)
                            3. Per ottenere il Chat ID, usa [@getidsbot](https://t.me/getidsbot) nel canale
                            
                            **Verifica rapida:**
                            - Chat ID privata: numero positivo (es. `123456789`)
                            - Chat ID gruppo: numero negativo (es. `-123456789`)
                            - Chat ID canale: numero negativo che inizia con `-100` (es. `-1001234567890`)
                            """)
                    elif error_type == "rate_limit":
                        st.warning(f"‚è±Ô∏è **Rate Limit**\n\n{error_msg}")
                    elif error_type == "timeout" or error_type == "connection_error":
                        st.warning(f"üåê **Problema di connessione**\n\n{error_msg}")
                    else:
                        st.warning(f"‚ö†Ô∏è **Errore invio Telegram**\n\n{error_msg}")
            except Exception as e:
                logger.error(f"Errore imprevisto in invio Telegram: {e}")
                st.warning(f"‚ö†Ô∏è Errore imprevisto invio Telegram: {e}")
                # Non bloccare il flusso se Telegram fallisce

st.markdown("---")

# ============================================================
#        AGGIORNAMENTO RISULTATI REALI
# ============================================================

st.subheader("üîÑ Aggiorna Risultati Reali")

if st.button("Recupera risultati ultimi 3 giorni"):
    if not os.path.exists(ARCHIVE_FILE):
        st.warning("Nessuno storico da aggiornare")
    else:
        with st.spinner("Recupero risultati da API-Football..."):
            df = pd.read_csv(ARCHIVE_FILE)
            today = date.today()
            giorni = [(today - timedelta(days=i)).isoformat() for i in range(0, 4)]
            
            fixtures_map = {}
            for d in giorni:
                fixtures = apifootball_get_fixtures_by_date(d)
                for f in fixtures:
                    if f["fixture"]["status"]["short"] in ["FT", "AET", "PEN"]:
                        home = f["teams"]["home"]["name"]
                        away = f["teams"]["away"]["name"]
                        key = f"{home} vs {away}".strip().lower()
                        gh = f["goals"]["home"]
                        ga = f["goals"]["away"]
                        if gh is not None and ga is not None:
                            fixtures_map[key] = (gh, ga)
            
            updated = 0
            for idx, row in df.iterrows():
                key_row = str(row.get("match", "")).strip().lower()
                if key_row in fixtures_map and (pd.isna(row.get("risultato_reale")) or row.get("risultato_reale") == ""):
                    gh, ga = fixtures_map[key_row]
                    
                    if gh > ga:
                        esito = "1"
                    elif gh == ga:
                        esito = "X"
                    else:
                        esito = "2"
                    
                    df.at[idx, "risultato_reale"] = f"{gh}-{ga}"
                    df.at[idx, "esito_reale"] = esito
                    
                    pred = row.get("esito_modello", "")
                    if pred and esito:
                        df.at[idx, "match_ok"] = 1 if pred == esito else 0
                    
                    updated += 1
            
            df.to_csv(ARCHIVE_FILE, index=False)
            st.success(f"‚úÖ Aggiornate {updated} partite")
            st.rerun()

st.markdown("---")

# ============================================================
#        BACKTESTING E PERFORMANCE
# ============================================================

st.subheader("üìä Backtesting Strategia")

if os.path.exists(ARCHIVE_FILE):
    col_bt1, col_bt2 = st.columns(2)
    
    with col_bt1:
        min_edge_bt = st.slider("Minimo Edge %", 1.0, 10.0, 3.0, 0.5)
        kelly_frac_bt = st.slider("Kelly Fraction", 0.1, 1.0, 0.25, 0.05)
        initial_bank = st.number_input("Bankroll Iniziale (‚Ç¨)", value=100.0, min_value=10.0, step=10.0)
    
    with col_bt2:
        if st.button("üöÄ Esegui Backtest", type="primary"):
            with st.spinner("Eseguendo backtest su dati storici..."):
                results = backtest_strategy(
                    ARCHIVE_FILE,
                    min_edge=min_edge_bt / 100,
                    kelly_fraction=kelly_frac_bt,
                    initial_bankroll=initial_bank
                )
                
                if "error" in results:
                    st.warning(f"‚ö†Ô∏è {results['error']}")
                else:
                    st.success("‚úÖ Backtest completato!")
                    
                    col_r1, col_r2, col_r3, col_r4 = st.columns(4)
                    
                    with col_r1:
                        st.metric("üí∞ Bankroll Finale", f"‚Ç¨{results['final_bankroll']:.2f}")
                    with col_r2:
                        st.metric("üìà Profit", f"‚Ç¨{results['profit']:.2f}", 
                                 f"{results['profit_pct']:+.1f}%")
                    with col_r3:
                        st.metric("üéØ Win Rate", f"{results['win_rate']:.1f}%")
                    with col_r4:
                        st.metric("üíµ ROI", f"{results['roi']:.1f}%")
                    
                    st.write(f"**Scommesse piazzate**: {results['bets_placed']} ({results['bets_won']} vinte)")
                    st.write(f"**Totale puntato**: ‚Ç¨{results['total_staked']:.2f}")
                    st.write(f"**Totale ritornato**: ‚Ç¨{results['total_returned']:.2f}")
                    
                    if results.get('sharpe_approx'):
                        st.write(f"**Sharpe Ratio (approssimato)**: {results['sharpe_approx']:.3f}")
                    
                    # Grafico profit history
                    if len(results.get('profit_history', [])) > 1:
                        try:
                            import matplotlib.pyplot as plt
                            fig, ax = plt.subplots(figsize=(10, 4))
                            ax.plot(results['profit_history'], linewidth=2)
                            ax.axhline(y=initial_bank, color='r', linestyle='--', label='Bankroll Iniziale')
                            ax.set_xlabel('Numero Scommesse')
                            ax.set_ylabel('Bankroll (‚Ç¨)')
                            ax.set_title('Evoluzione Bankroll')
                            ax.legend()
                            ax.grid(True, alpha=0.3)
                            st.pyplot(fig)
                            plt.close(fig)
                        except Exception as e:
                            logger.debug(f"Errore creazione grafico matplotlib: {e}")
else:
    st.info("Nessuno storico disponibile per backtest")

st.markdown("---")
st.caption("Developed with ‚ù§Ô∏è | Dixon-Coles Bayesian Model | Shin Normalization | IQR Outlier Detection | Platt Scaling | Kelly Criterion | Ensemble Methods")
